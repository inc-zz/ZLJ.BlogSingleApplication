/*
 Navicat Premium Dump SQL

 Source Server         : localhost
 Source Server Type    : MySQL
 Source Server Version : 50732 (5.7.32-log)
 Source Host           : localhost:3306
 Source Schema         : blogs_single_application

 Target Server Type    : MySQL
 Target Server Version : 50732 (5.7.32-log)
 File Encoding         : 65001

 Date: 11/11/2025 23:35:06
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for blogs_article
-- ----------------------------
DROP TABLE IF EXISTS `blogs_article`;
CREATE TABLE `blogs_article`  (
  `Id` bigint(20) NOT NULL,
  `Title` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `Summary` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Content` longtext CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `CoverImage` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Status` int(11) NOT NULL DEFAULT 1,
  `Tags` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsTop` tinyint(1) NULL DEFAULT 0,
  `IsRecommend` tinyint(1) NULL DEFAULT 0,
  `ViewCount` int(11) NULL DEFAULT 0,
  `LikeCount` int(11) NOT NULL DEFAULT 0,
  `CommentCount` int(11) NULL DEFAULT NULL,
  `ShareCount` int(11) NULL DEFAULT NULL,
  `PublishTime` datetime NULL DEFAULT NULL,
  `AuthorId` bigint(20) NULL DEFAULT NULL,
  `CategoryId` bigint(20) NULL DEFAULT NULL,
  `CreatedAt` datetime NULL DEFAULT NULL,
  `CreatedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL DEFAULT 0,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blogs_article
-- ----------------------------
INSERT INTO `blogs_article` VALUES (1, 'dotNet程序员进阶', '如何从初级dotNet程序员变成中级dotNet程序员?', '<p>我们将采用经典的分层架构，结合DDD和CQRS模式。下面是一个可能的分层结构：\r\n\r\n领域层 (Domain Layer)\r\n\r\n实体 (Entities)\r\n\r\n值对象 (Value Objects)\r\n\r\n领域服务 (Domain Services)\r\n\r\n领域事件 (Domain Events)\r\n\r\n仓储接口 (Repository Interfaces)\r\n\r\n应用层 (Application Layer)\r\n\r\n命令 (Commands) 和 命令处理器 (Command Handlers)\r\n\r\n查询 (Queries) 和 查询处理器 (Query Handlers)\r\n\r\n应用服务 (Application Services)\r\n\r\n数据传输对象 (DTOs)\r\n\r\n验证器 (Validators) - 使用FluentValidation\r\n\r\n配置文件 (Profiles) - 使用AutoMapper\r\n\r\n基础设施层 (Infrastructure Layer)\r\n\r\n仓储实现 (Repository Implementations) - 使用SqlSugar操作MySql\r\n\r\n缓存实现 (Cache Implementations) - 使用Redis\r\n\r\n数据库上下文 (DbContext) - 使用SqlSugar\r\n\r\n其他基础设施服务（如身份认证、文件存储等）\r\n\r\n表现层 (Presentation Layer)\r\n\r\nWeb API 控制器 (Controllers)\r\n\r\n中间件 (Middleware)\r\n\r\n启动配置 (Startup Configuration)\r\n\r\n共享层 (Shared Layer)\r\n\r\n通用工具类 (Common Utilities)\r\n\r\n基类 (Base Classes)\r\n\r\n全局异常处理 (Global Exception Handling)\r\n\r\n日志记录 (Logging)\r\n\r\n现在，我们描述各层之间的依赖关系：\r\n\r\n表现层 (Presentation Layer) 依赖于应用层 (Application Layer) 和基础设施层 (Infrastructure Layer)（但通过依赖注入，实际上它只依赖于应用层和基础设施层的接口，具体实现由基础设施层提供）。\r\n\r\n应用层 (Application Layer) 依赖于领域层 (Domain Layer) 和基础设施层（通过接口，因为应用层需要调用仓储接口，而实现在基础设施层）。\r\n\r\n基础设施层 (Infrastructure Layer) 依赖于领域层（因为要实现领域层定义的仓储接口）和应用层（可能，如果应用层定义了某些接口需要基础设施层实现，但通常不会直接依赖应用层，而是通过依赖反转）。\r\n\r\n领域层 (Domain Layer) 是独立的，不依赖于其他层。\r\n\r\n共享层 (Shared Layer) 可以被所有层引用。\r\n\r\n在CQRS模式中，我们将命令和查询分离，使用MediatR来作为中介者，将命令和查询发送到相应的处理器。\r\n\r\n下面是一个简化的项目结构：\r\n\r\nsrc/\r\n\r\nDomain/\r\n\r\nEntities/\r\n\r\nValueObjects/\r\n\r\nServices/\r\n\r\nEvents/\r\n\r\nInterfaces/\r\n\r\nIRepository.cs\r\n\r\nApplication/\r\n\r\nCommands/\r\n\r\nCreateProductCommand.cs\r\n\r\nCreateProductCommandHandler.cs\r\n\r\nQueries/\r\n\r\nGetProductByIdQuery.cs\r\n\r\nGetProductByIdQueryHandler.cs\r\n\r\nDTOs/\r\n\r\nValidators/\r\n\r\nCreateProductCommandValidator.cs\r\n\r\nProfiles/\r\n\r\nAutoMapperProfile.cs\r\n\r\nInterfaces/ (可能有一些应用服务接口，但通常CQRS中命令和查询处理器已经足够)\r\n\r\nInfrastructure/\r\n\r\nRepositories/\r\n\r\nProductRepository.cs\r\n\r\nData/\r\n\r\nMyDbContext.cs (使用SqlSugar)\r\n\r\nCaching/\r\n\r\nRedisCacheService.cs\r\n\r\nServices/ (其他基础设施服务)\r\n\r\nPresentation/\r\n\r\nControllers/\r\n\r\nProductController.cs\r\n\r\nProgram.cs\r\n\r\nStartup.cs (或Program.cs中的配置)\r\n\r\nShared/\r\n\r\nExceptions/\r\n\r\nLogging/\r\n\r\nExtensions/\r\n\r\n注意：在实际项目中，我们可能会使用依赖注入来解耦各层。在Program.cs中，我们会注册MediatR、FluentValidation、SqlSugar、Redis等。\r\n\r\n由于我们使用MediatR，控制器中只需要注入IMediator，然后发送命令或查询。\r\n\r\n下面是一个简单的依赖关系图（文字表示）：\r\n\r\n表现层 (Presentation) -> 应用层 (Application) -> 领域层 (Domain)\r\n表现层 (Presentation) -> 基础设施层 (Infrastructure) [通过依赖注入]\r\n应用层 (Application) -> 基础设施层 (Infrastructure) [通过接口]\r\n基础设施层 (Infrastructure) -> 领域层 (Domain)\r\n\r\n共享层 (Shared) 被所有层引用。\r\n\r\n注意：在DDD中，我们通常希望领域层保持纯净，不依赖任何其他层。\r\n\r\n由于我们使用SqlSugar，它是一个轻量级的ORM，在基础设施层中，我们会实现领域层定义的仓储接口。\r\n\r\n缓存方面，我们使用Redis，在基础设施层中实现缓存服务，并可以在应用层或基础设施层的仓储中使用。\r\n\r\n验证器在应用层，使用FluentValidation，我们在MediatR的管道中注册验证行为，以便在命令和查询处理之前进行验证。\r\n\r\n以上就是一个大致的架构描述。由于无法直接画图，希望这个文字描述能帮助你理解这个架构。</p>', '1', 1, 'dotnet，进阶', 1, 1, 1, 199, 87, 3, NULL, 1, 1, '2025-10-11 06:43:08', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (2, 'Java 并发编程实战', '最新款部署方案', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', '1', 1, '并发编程', 1, 1, 2, 11, 45, 3, NULL, 1, 2, '2025-10-11 06:43:08', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (3, 'Unity3D 游戏开发入门', '即可将1领款人极乐空间网络科技网卡乐然金额为立卡', '保存到APP查看\r\n下载印象笔记\r\n微服务中间件-资源监控Prometheus\r\n微服务中间件-资源监控Prometheus\r\n1、资源监控相关概念\r\n  1.1、什么是资源监控\r\n\r\n  1.2、不同监控工具对比\r\n\r\n\r\n2、资源监控Prometheus环境部署\r\n  2.1、安装Prometheus\r\n\r\n  1）下载Prometheus资源文件，下载地址：https://prometheus.io/download/#memcached_exporter\r\n\r\n2）、windows版本直接解压，然后运行\r\nPS D:\\> cd D:\\devtools\\prometheus-3.5.0.windows-amd64\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> ls\r\n目录: D:\\devtools\\prometheus-3.5.0.windows-amd64\r\n\r\nMode                 LastWriteTime         Length Name\r\n----                 -------------         ------ ----\r\n-a----         2025/8/23      7:39          11357 LICENSE\r\n-a----         2025/8/23      7:39           3773 NOTICE\r\n-a----         2025/8/23      7:39      161348096 prometheus.exe\r\n-a----         2025/8/23      7:39           1093 prometheus.yml\r\n-a----         2025/8/23      7:39      152659456 promtool.exe\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> .\\prometheus.exe\r\n\r\n\r\n\r\n3）、访问Prometheus\r\n  访问地址：http://localhost:9090/\r\n\r\n\r\n4）编辑Prometheus配置文件\r\n  windows位置：\\prometheus-3.5.0.windows-amd64\\prometheus.yml\r\n# my global config\r\nglobal:\r\n  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\r\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\r\n  # scrape_timeout is set to the global default (10s).\r\n\r\n\r\n# Alertmanager configuration\r\nalerting:\r\n  alertmanagers:\r\n    - static_configs:\r\n        - targets:[\"http://localhost:5022/\"]  #配置需要监控的微服务地址\r\n          # - alertmanager:9093\r\n\r\n\r\n# Load rules once and periodically evaluate them according to the global \'evaluation_interval\'.\r\nrule_files:\r\n  # - \"first_rules.yml\"\r\n  # - \"second_rules.yml\"\r\n\r\n\r\n# A scrape configuration containing exactly one endpoint to scrape:\r\n# Here it\'s Prometheus itself.\r\nscrape_configs:\r\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\r\n  - job_name: \"prometheus\"\r\n\r\n\r\n    # metrics_path defaults to \'/metrics\'\r\n    # scheme defaults to \'http\'.\r\n\r\n\r\n    static_configs:\r\n      - targets: [\"localhost:9090\"]\r\n       # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.\r\n        labels:\r\n          app: \"prometheus\"\r\n\r\n  # 添加资源监控目标\r\n  - job_name: \"daprGatewayapi\"\r\n     static_configs:\r\n       - targets: [\"localhost:5022\"]\r\n\r\n-------------------------------------------------------------------------------------------------------------------------\r\n配置参数说明：\r\n- job_name: \"orderservice\" #定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] #订单微服务地址\r\n      \r\n详细配置(根据环境具体来选择使用)：\r\nscrape_configs:\r\n  - job_name: \"orderservice\" # 定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] # 订单微服务地址\r\n    scrape_interval: 15s # 抓取数据的时间间隔，默认为15秒\r\n    scrape_timeout: 10s # 抓取数据的超时时间，默认为10秒\r\n    metrics_path: \"/metrics\" # 指定要抓取的指标路径，默认为/metrics\r\n    scheme: \"https\" # 使用的协议，默认为http\r\n    basic_auth:      username: \"admin\" # 基本身份验证的用户名\r\n      password: \"password\" # 基本身份验证的密码\r\n    tls_config:      ca_file: \"/path/to/ca.crt\" # CA证书文件路径\r\n      cert_file: \"/path/to/client.crt\" # 客户端证书文件路径\r\n      key_file: \"/path/to/client.key\" # 客户端私钥文件路径\r\n    relabel_configs:\r\n      - source_labels: [__address__] # 源标签，指定要重写的标签\r\n        target_label: instance # 目标标签，指定重写后的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n      - source_labels: [__address__]\r\n        target_label: __param_target # 目标标签，指定要添加的标签名称\r\n        replacement: \"/metrics\" # 替换后的标签值\r\n      - source_labels: [__param_target]\r\n        target_label: job # 目标标签，指定要添加的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n\r\n\r\n\r\n5）通过nssm将Prometheus安装到windows服务，可以使用Grafana安装目录下的nssm\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> .\\nssm.exe install\r\n\r\n选择exe文件所在目录，Prometheus不需要启动参数，Arguments不需要，设置Service name为Prometheus\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net stop Prometheus\r\nPrometheus 服务正在停止.\r\nPrometheus 服务已成功停止。\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net start Prometheus\r\nPrometheus 服务正在启动 .\r\nPrometheus 服务已经启动成功。\r\n\r\n\r\n2.2、安装grafana\r\n1）下载grafana：https://grafana.com/grafana/download?platform=windows\r\n  选择安装包的形式，\r\n\r\n2）下载msi文件安装后，直接安装到windows服务，修改为手动启动\r\n\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net stop Grafana\r\nGrafana 服务正在停止.\r\nGrafana 服务已成功停止。\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net start Grafana\r\nGrafana 服务正在启动 .\r\nGrafana 服务已经启动成功。\r\n\r\n\r\n3）访问Grafana：http://localhost:3000/\r\n  默认账号密码都是admin，进入后修改为自己的密码，比如Zlj123456，相对于其他的监控软件，它这个UI确实做的不错。\r\n\r\n\r\n4）添加Prometheus数据源\r\n点击首页右侧 DATA SOURCE卡片，选择Prometheus\r\n\r\n添加Prometheus服务器地址，\r\n\r\n点击底部保存 Save&test\r\n\r\n\r\n5）添加Prometheus控制面板\r\n选择左侧菜单-Dashboards->Create dashboards，点击+Add visualization \r\n\r\nhttp://localhost:3000/dashboard/new?orgId=1&from=now-6h&to=now&timezone=browser\r\n\r\n\r\n3、应用集成\r\n  3.1、创建网关webapi项目，这里我创建的是一个普通的webapi项目，相对于AbpVnext项目集成有一点差异\r\n\r\n\r\n3.2、修改Program.cs，添加Prometheus的集成\r\n#添加命名空间\r\nusing Prometheus;\r\n\r\n# 在MapControllers之前集成\r\n//集成Prometheus\r\napp.UseMetricServer();\r\n//集成Prometheus监控数据访问\r\napp.UseHttpMetrics();\r\napp.MapControllers();\r\napp.Run();\r\n\r\n\r\n3.3、控制器中集成\r\nusing Dapr.Actors;\r\nusing Dapr.Actors.Client;\r\nusing Dapr.Client;\r\nusing FEShop.AppUserService.Services.Dtos.Account;\r\nusing FEShop.AppUserService.Services.Interfaces;\r\nusing Microsoft.AspNetCore.Mvc;\r\nusing Prometheus;\r\nnamespace FEShop.GatewayApi.Controllers.AppApi\r\n{\r\n    /// <summary>\r\n    /// APP用户网关\r\n    /// </summary>\r\n    [ApiController]\r\n    [Route(\"app/[controller]\")]\r\n    public class AppUserController : ControllerBase\r\n    {\r\n        private readonly ILogger<AppUserController> _logger;\r\n        private readonly IActorProxyFactory _actorProxyFactory;\r\n        //1、集成Prometheus\r\n        private static readonly Counter _requestCounter =  Metrics.CreateCounter(\"daprGatewayapi\", \"daprGatewayapi_help\", new CounterConfiguration\r\n        {\r\n            LabelNames = new[] { \"method\", \"endpoint\" }\r\n        });\r\n        /// <summary>\r\n        ///\r\n        /// </summary>\r\n        public AppUserController(ILogger<AppUserController> logger, IActorProxyFactory  actorProxyFactory)\r\n        {\r\n            _logger = logger;\r\n            _actorProxyFactory = actorProxyFactory;\r\n        }\r\n        /// <summary>\r\n        /// 用户登录\r\n        /// </summary>\r\n        /// <param name=\"dto\"></param>\r\n        /// <returns></returns>\r\n        [HttpPost(\"login\")]\r\n        public async Task<IActionResult> LoginAsync([FromBody] LoginInputDto dto)\r\n        {\r\n            //2、使用Prometheus记录请求计数\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/login\").Inc();\r\n            ActorId actorId = new ActorId(dto.Account);\r\n            IAccountService accountService =\r\n                _actorProxyFactory.CreateActorProxy<IAccountService>(\r\n                    actorId,\r\n                    \"AccountService\");\r\n            ResultObject<LoginOutputDto> result = await accountService.LoginAsync(dto);\r\n            return Ok(result);\r\n        }\r\n        /// <summary>\r\n        /// 测试Prometheus日志记录\r\n        /// </summary>\r\n        /// <returns></returns>\r\n        [HttpPost(\"testPrometheusLog\")]\r\n        public async Task<string> TestPrometheusLogAsync()\r\n        {\r\n            //3、测试Prometheus日志记录\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/testPrometheusLog\").Inc();\r\n            _logger.LogInformation(\"Test Prometheus logging\");\r\n            return \"Prometheus logging test successful\";\r\n        }\r\n    }\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n保存到APP查看\r\n下载印象笔记\r\n微服务中间件-资源监控Prometheus\r\n微服务中间件-资源监控Prometheus\r\n1、资源监控相关概念\r\n  1.1、什么是资源监控\r\n\r\n  1.2、不同监控工具对比\r\n\r\n\r\n2、资源监控Prometheus环境部署\r\n  2.1、安装Prometheus\r\n\r\n  1）下载Prometheus资源文件，下载地址：https://prometheus.io/download/#memcached_exporter\r\n\r\n2）、windows版本直接解压，然后运行\r\nPS D:\\> cd D:\\devtools\\prometheus-3.5.0.windows-amd64\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> ls\r\n目录: D:\\devtools\\prometheus-3.5.0.windows-amd64\r\n\r\nMode                 LastWriteTime         Length Name\r\n----                 -------------         ------ ----\r\n-a----         2025/8/23      7:39          11357 LICENSE\r\n-a----         2025/8/23      7:39           3773 NOTICE\r\n-a----         2025/8/23      7:39      161348096 prometheus.exe\r\n-a----         2025/8/23      7:39           1093 prometheus.yml\r\n-a----         2025/8/23      7:39      152659456 promtool.exe\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> .\\prometheus.exe\r\n\r\n\r\n\r\n3）、访问Prometheus\r\n  访问地址：http://localhost:9090/\r\n\r\n\r\n4）编辑Prometheus配置文件\r\n  windows位置：\\prometheus-3.5.0.windows-amd64\\prometheus.yml\r\n# my global config\r\nglobal:\r\n  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\r\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\r\n  # scrape_timeout is set to the global default (10s).\r\n\r\n\r\n# Alertmanager configuration\r\nalerting:\r\n  alertmanagers:\r\n    - static_configs:\r\n        - targets:[\"http://localhost:5022/\"]  #配置需要监控的微服务地址\r\n          # - alertmanager:9093\r\n\r\n\r\n# Load rules once and periodically evaluate them according to the global \'evaluation_interval\'.\r\nrule_files:\r\n  # - \"first_rules.yml\"\r\n  # - \"second_rules.yml\"\r\n\r\n\r\n# A scrape configuration containing exactly one endpoint to scrape:\r\n# Here it\'s Prometheus itself.\r\nscrape_configs:\r\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\r\n  - job_name: \"prometheus\"\r\n\r\n\r\n    # metrics_path defaults to \'/metrics\'\r\n    # scheme defaults to \'http\'.\r\n\r\n\r\n    static_configs:\r\n      - targets: [\"localhost:9090\"]\r\n       # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.\r\n        labels:\r\n          app: \"prometheus\"\r\n\r\n  # 添加资源监控目标\r\n  - job_name: \"daprGatewayapi\"\r\n     static_configs:\r\n       - targets: [\"localhost:5022\"]\r\n\r\n-------------------------------------------------------------------------------------------------------------------------\r\n配置参数说明：\r\n- job_name: \"orderservice\" #定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] #订单微服务地址\r\n      \r\n详细配置(根据环境具体来选择使用)：\r\nscrape_configs:\r\n  - job_name: \"orderservice\" # 定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] # 订单微服务地址\r\n    scrape_interval: 15s # 抓取数据的时间间隔，默认为15秒\r\n    scrape_timeout: 10s # 抓取数据的超时时间，默认为10秒\r\n    metrics_path: \"/metrics\" # 指定要抓取的指标路径，默认为/metrics\r\n    scheme: \"https\" # 使用的协议，默认为http\r\n    basic_auth:      username: \"admin\" # 基本身份验证的用户名\r\n      password: \"password\" # 基本身份验证的密码\r\n    tls_config:      ca_file: \"/path/to/ca.crt\" # CA证书文件路径\r\n      cert_file: \"/path/to/client.crt\" # 客户端证书文件路径\r\n      key_file: \"/path/to/client.key\" # 客户端私钥文件路径\r\n    relabel_configs:\r\n      - source_labels: [__address__] # 源标签，指定要重写的标签\r\n        target_label: instance # 目标标签，指定重写后的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n      - source_labels: [__address__]\r\n        target_label: __param_target # 目标标签，指定要添加的标签名称\r\n        replacement: \"/metrics\" # 替换后的标签值\r\n      - source_labels: [__param_target]\r\n        target_label: job # 目标标签，指定要添加的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n\r\n\r\n\r\n5）通过nssm将Prometheus安装到windows服务，可以使用Grafana安装目录下的nssm\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> .\\nssm.exe install\r\n\r\n选择exe文件所在目录，Prometheus不需要启动参数，Arguments不需要，设置Service name为Prometheus\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net stop Prometheus\r\nPrometheus 服务正在停止.\r\nPrometheus 服务已成功停止。\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net start Prometheus\r\nPrometheus 服务正在启动 .\r\nPrometheus 服务已经启动成功。\r\n\r\n\r\n2.2、安装grafana\r\n1）下载grafana：https://grafana.com/grafana/download?platform=windows\r\n  选择安装包的形式，\r\n\r\n2）下载msi文件安装后，直接安装到windows服务，修改为手动启动\r\n\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net stop Grafana\r\nGrafana 服务正在停止.\r\nGrafana 服务已成功停止。\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net start Grafana\r\nGrafana 服务正在启动 .\r\nGrafana 服务已经启动成功。\r\n\r\n\r\n3）访问Grafana：http://localhost:3000/\r\n  默认账号密码都是admin，进入后修改为自己的密码，比如Zlj123456，相对于其他的监控软件，它这个UI确实做的不错。\r\n\r\n\r\n4）添加Prometheus数据源\r\n点击首页右侧 DATA SOURCE卡片，选择Prometheus\r\n\r\n添加Prometheus服务器地址，\r\n\r\n点击底部保存 Save&test\r\n\r\n\r\n5）添加Prometheus控制面板\r\n选择左侧菜单-Dashboards->Create dashboards，点击+Add visualization \r\n\r\nhttp://localhost:3000/dashboard/new?orgId=1&from=now-6h&to=now&timezone=browser\r\n\r\n\r\n3、应用集成\r\n  3.1、创建网关webapi项目，这里我创建的是一个普通的webapi项目，相对于AbpVnext项目集成有一点差异\r\n\r\n\r\n3.2、修改Program.cs，添加Prometheus的集成\r\n#添加命名空间\r\nusing Prometheus;\r\n\r\n# 在MapControllers之前集成\r\n//集成Prometheus\r\napp.UseMetricServer();\r\n//集成Prometheus监控数据访问\r\napp.UseHttpMetrics();\r\napp.MapControllers();\r\napp.Run();\r\n\r\n\r\n3.3、控制器中集成\r\nusing Dapr.Actors;\r\nusing Dapr.Actors.Client;\r\nusing Dapr.Client;\r\nusing FEShop.AppUserService.Services.Dtos.Account;\r\nusing FEShop.AppUserService.Services.Interfaces;\r\nusing Microsoft.AspNetCore.Mvc;\r\nusing Prometheus;\r\nnamespace FEShop.GatewayApi.Controllers.AppApi\r\n{\r\n    /// <summary>\r\n    /// APP用户网关\r\n    /// </summary>\r\n    [ApiController]\r\n    [Route(\"app/[controller]\")]\r\n    public class AppUserController : ControllerBase\r\n    {\r\n        private readonly ILogger<AppUserController> _logger;\r\n        private readonly IActorProxyFactory _actorProxyFactory;\r\n        //1、集成Prometheus\r\n        private static readonly Counter _requestCounter =  Metrics.CreateCounter(\"daprGatewayapi\", \"daprGatewayapi_help\", new CounterConfiguration\r\n        {\r\n            LabelNames = new[] { \"method\", \"endpoint\" }\r\n        });\r\n        /// <summary>\r\n        ///\r\n        /// </summary>\r\n        public AppUserController(ILogger<AppUserController> logger, IActorProxyFactory  actorProxyFactory)\r\n        {\r\n            _logger = logger;\r\n            _actorProxyFactory = actorProxyFactory;\r\n        }\r\n        /// <summary>\r\n        /// 用户登录\r\n        /// </summary>\r\n        /// <param name=\"dto\"></param>\r\n        /// <returns></returns>\r\n        [HttpPost(\"login\")]\r\n        public async Task<IActionResult> LoginAsync([FromBody] LoginInputDto dto)\r\n        {\r\n            //2、使用Prometheus记录请求计数\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/login\").Inc();\r\n            ActorId actorId = new ActorId(dto.Account);\r\n            IAccountService accountService =\r\n                _actorProxyFactory.CreateActorProxy<IAccountService>(\r\n                    actorId,\r\n                    \"AccountService\");\r\n            ResultObject<LoginOutputDto> result = await accountService.LoginAsync(dto);\r\n            return Ok(result);\r\n        }\r\n        /// <summary>\r\n        /// 测试Prometheus日志记录\r\n        /// </summary>\r\n        /// <returns></returns>\r\n        [HttpPost(\"testPrometheusLog\")]\r\n        public async Task<string> TestPrometheusLogAsync()\r\n        {\r\n            //3、测试Prometheus日志记录\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/testPrometheusLog\").Inc();\r\n            _logger.LogInformation(\"Test Prometheus logging\");\r\n            return \"Prometheus logging test successful\";\r\n        }\r\n    }\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n保存到APP查看\r\n下载印象笔记\r\n微服务中间件-资源监控Prometheus\r\n微服务中间件-资源监控Prometheus\r\n1、资源监控相关概念\r\n  1.1、什么是资源监控\r\n\r\n  1.2、不同监控工具对比\r\n\r\n\r\n2、资源监控Prometheus环境部署\r\n  2.1、安装Prometheus\r\n\r\n  1）下载Prometheus资源文件，下载地址：https://prometheus.io/download/#memcached_exporter\r\n\r\n2）、windows版本直接解压，然后运行\r\nPS D:\\> cd D:\\devtools\\prometheus-3.5.0.windows-amd64\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> ls\r\n目录: D:\\devtools\\prometheus-3.5.0.windows-amd64\r\n\r\nMode                 LastWriteTime         Length Name\r\n----                 -------------         ------ ----\r\n-a----         2025/8/23      7:39          11357 LICENSE\r\n-a----         2025/8/23      7:39           3773 NOTICE\r\n-a----         2025/8/23      7:39      161348096 prometheus.exe\r\n-a----         2025/8/23      7:39           1093 prometheus.yml\r\n-a----         2025/8/23      7:39      152659456 promtool.exe\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> .\\prometheus.exe\r\n\r\n\r\n\r\n3）、访问Prometheus\r\n  访问地址：http://localhost:9090/\r\n\r\n\r\n4）编辑Prometheus配置文件\r\n  windows位置：\\prometheus-3.5.0.windows-amd64\\prometheus.yml\r\n# my global config\r\nglobal:\r\n  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\r\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\r\n  # scrape_timeout is set to the global default (10s).\r\n\r\n\r\n# Alertmanager configuration\r\nalerting:\r\n  alertmanagers:\r\n    - static_configs:\r\n        - targets:[\"http://localhost:5022/\"]  #配置需要监控的微服务地址\r\n          # - alertmanager:9093\r\n\r\n\r\n# Load rules once and periodically evaluate them according to the global \'evaluation_interval\'.\r\nrule_files:\r\n  # - \"first_rules.yml\"\r\n  # - \"second_rules.yml\"\r\n\r\n\r\n# A scrape configuration containing exactly one endpoint to scrape:\r\n# Here it\'s Prometheus itself.\r\nscrape_configs:\r\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\r\n  - job_name: \"prometheus\"\r\n\r\n\r\n    # metrics_path defaults to \'/metrics\'\r\n    # scheme defaults to \'http\'.\r\n\r\n\r\n    static_configs:\r\n      - targets: [\"localhost:9090\"]\r\n       # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.\r\n        labels:\r\n          app: \"prometheus\"\r\n\r\n  # 添加资源监控目标\r\n  - job_name: \"daprGatewayapi\"\r\n     static_configs:\r\n       - targets: [\"localhost:5022\"]\r\n\r\n-------------------------------------------------------------------------------------------------------------------------\r\n配置参数说明：\r\n- job_name: \"orderservice\" #定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] #订单微服务地址\r\n      \r\n详细配置(根据环境具体来选择使用)：\r\nscrape_configs:\r\n  - job_name: \"orderservice\" # 定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] # 订单微服务地址\r\n    scrape_interval: 15s # 抓取数据的时间间隔，默认为15秒\r\n    scrape_timeout: 10s # 抓取数据的超时时间，默认为10秒\r\n    metrics_path: \"/metrics\" # 指定要抓取的指标路径，默认为/metrics\r\n    scheme: \"https\" # 使用的协议，默认为http\r\n    basic_auth:      username: \"admin\" # 基本身份验证的用户名\r\n      password: \"password\" # 基本身份验证的密码\r\n    tls_config:      ca_file: \"/path/to/ca.crt\" # CA证书文件路径\r\n      cert_file: \"/path/to/client.crt\" # 客户端证书文件路径\r\n      key_file: \"/path/to/client.key\" # 客户端私钥文件路径\r\n    relabel_configs:\r\n      - source_labels: [__address__] # 源标签，指定要重写的标签\r\n        target_label: instance # 目标标签，指定重写后的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n      - source_labels: [__address__]\r\n        target_label: __param_target # 目标标签，指定要添加的标签名称\r\n        replacement: \"/metrics\" # 替换后的标签值\r\n      - source_labels: [__param_target]\r\n        target_label: job # 目标标签，指定要添加的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n\r\n\r\n\r\n5）通过nssm将Prometheus安装到windows服务，可以使用Grafana安装目录下的nssm\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> .\\nssm.exe install\r\n\r\n选择exe文件所在目录，Prometheus不需要启动参数，Arguments不需要，设置Service name为Prometheus\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net stop Prometheus\r\nPrometheus 服务正在停止.\r\nPrometheus 服务已成功停止。\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net start Prometheus\r\nPrometheus 服务正在启动 .\r\nPrometheus 服务已经启动成功。\r\n\r\n\r\n2.2、安装grafana\r\n1）下载grafana：https://grafana.com/grafana/download?platform=windows\r\n  选择安装包的形式，\r\n\r\n2）下载msi文件安装后，直接安装到windows服务，修改为手动启动\r\n\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net stop Grafana\r\nGrafana 服务正在停止.\r\nGrafana 服务已成功停止。\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net start Grafana\r\nGrafana 服务正在启动 .\r\nGrafana 服务已经启动成功。\r\n\r\n\r\n3）访问Grafana：http://localhost:3000/\r\n  默认账号密码都是admin，进入后修改为自己的密码，比如Zlj123456，相对于其他的监控软件，它这个UI确实做的不错。\r\n\r\n\r\n4）添加Prometheus数据源\r\n点击首页右侧 DATA SOURCE卡片，选择Prometheus\r\n\r\n添加Prometheus服务器地址，\r\n\r\n点击底部保存 Save&test\r\n\r\n\r\n5）添加Prometheus控制面板\r\n选择左侧菜单-Dashboards->Create dashboards，点击+Add visualization \r\n\r\nhttp://localhost:3000/dashboard/new?orgId=1&from=now-6h&to=now&timezone=browser\r\n\r\n\r\n3、应用集成\r\n  3.1、创建网关webapi项目，这里我创建的是一个普通的webapi项目，相对于AbpVnext项目集成有一点差异\r\n\r\n\r\n3.2、修改Program.cs，添加Prometheus的集成\r\n#添加命名空间\r\nusing Prometheus;\r\n\r\n# 在MapControllers之前集成\r\n//集成Prometheus\r\napp.UseMetricServer();\r\n//集成Prometheus监控数据访问\r\napp.UseHttpMetrics();\r\napp.MapControllers();\r\napp.Run();\r\n\r\n\r\n3.3、控制器中集成\r\nusing Dapr.Actors;\r\nusing Dapr.Actors.Client;\r\nusing Dapr.Client;\r\nusing FEShop.AppUserService.Services.Dtos.Account;\r\nusing FEShop.AppUserService.Services.Interfaces;\r\nusing Microsoft.AspNetCore.Mvc;\r\nusing Prometheus;\r\nnamespace FEShop.GatewayApi.Controllers.AppApi\r\n{\r\n    /// <summary>\r\n    /// APP用户网关\r\n    /// </summary>\r\n    [ApiController]\r\n    [Route(\"app/[controller]\")]\r\n    public class AppUserController : ControllerBase\r\n    {\r\n        private readonly ILogger<AppUserController> _logger;\r\n        private readonly IActorProxyFactory _actorProxyFactory;\r\n        //1、集成Prometheus\r\n        private static readonly Counter _requestCounter =  Metrics.CreateCounter(\"daprGatewayapi\", \"daprGatewayapi_help\", new CounterConfiguration\r\n        {\r\n            LabelNames = new[] { \"method\", \"endpoint\" }\r\n        });\r\n        /// <summary>\r\n        ///\r\n        /// </summary>\r\n        public AppUserController(ILogger<AppUserController> logger, IActorProxyFactory  actorProxyFactory)\r\n        {\r\n            _logger = logger;\r\n            _actorProxyFactory = actorProxyFactory;\r\n        }\r\n        /// <summary>\r\n        /// 用户登录\r\n        /// </summary>\r\n        /// <param name=\"dto\"></param>\r\n        /// <returns></returns>\r\n        [HttpPost(\"login\")]\r\n        public async Task<IActionResult> LoginAsync([FromBody] LoginInputDto dto)\r\n        {\r\n            //2、使用Prometheus记录请求计数\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/login\").Inc();\r\n            ActorId actorId = new ActorId(dto.Account);\r\n            IAccountService accountService =\r\n                _actorProxyFactory.CreateActorProxy<IAccountService>(\r\n                    actorId,\r\n                    \"AccountService\");\r\n            ResultObject<LoginOutputDto> result = await accountService.LoginAsync(dto);\r\n            return Ok(result);\r\n        }\r\n        /// <summary>\r\n        /// 测试Prometheus日志记录\r\n        /// </summary>\r\n        /// <returns></returns>\r\n        [HttpPost(\"testPrometheusLog\")]\r\n        public async Task<string> TestPrometheusLogAsync()\r\n        {\r\n            //3、测试Prometheus日志记录\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/testPrometheusLog\").Inc();\r\n            _logger.LogInformation(\"Test Prometheus logging\");\r\n            return \"Prometheus logging test successful\";\r\n        }\r\n    }\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n保存到APP查看\r\n下载印象笔记\r\n微服务中间件-资源监控Prometheus\r\n微服务中间件-资源监控Prometheus\r\n1、资源监控相关概念\r\n  1.1、什么是资源监控\r\n\r\n  1.2、不同监控工具对比\r\n\r\n\r\n2、资源监控Prometheus环境部署\r\n  2.1、安装Prometheus\r\n\r\n  1）下载Prometheus资源文件，下载地址：https://prometheus.io/download/#memcached_exporter\r\n\r\n2）、windows版本直接解压，然后运行\r\nPS D:\\> cd D:\\devtools\\prometheus-3.5.0.windows-amd64\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> ls\r\n目录: D:\\devtools\\prometheus-3.5.0.windows-amd64\r\n\r\nMode                 LastWriteTime         Length Name\r\n----                 -------------         ------ ----\r\n-a----         2025/8/23      7:39          11357 LICENSE\r\n-a----         2025/8/23      7:39           3773 NOTICE\r\n-a----         2025/8/23      7:39      161348096 prometheus.exe\r\n-a----         2025/8/23      7:39           1093 prometheus.yml\r\n-a----         2025/8/23      7:39      152659456 promtool.exe\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> .\\prometheus.exe\r\n\r\n\r\n\r\n3）、访问Prometheus\r\n  访问地址：http://localhost:9090/\r\n\r\n\r\n4）编辑Prometheus配置文件\r\n  windows位置：\\prometheus-3.5.0.windows-amd64\\prometheus.yml\r\n# my global config\r\nglobal:\r\n  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\r\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\r\n  # scrape_timeout is set to the global default (10s).\r\n\r\n\r\n# Alertmanager configuration\r\nalerting:\r\n  alertmanagers:\r\n    - static_configs:\r\n        - targets:[\"http://localhost:5022/\"]  #配置需要监控的微服务地址\r\n          # - alertmanager:9093\r\n\r\n\r\n# Load rules once and periodically evaluate them according to the global \'evaluation_interval\'.\r\nrule_files:\r\n  # - \"first_rules.yml\"\r\n  # - \"second_rules.yml\"\r\n\r\n\r\n# A scrape configuration containing exactly one endpoint to scrape:\r\n# Here it\'s Prometheus itself.\r\nscrape_configs:\r\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\r\n  - job_name: \"prometheus\"\r\n\r\n\r\n    # metrics_path defaults to \'/metrics\'\r\n    # scheme defaults to \'http\'.\r\n\r\n\r\n    static_configs:\r\n      - targets: [\"localhost:9090\"]\r\n       # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.\r\n        labels:\r\n          app: \"prometheus\"\r\n\r\n  # 添加资源监控目标\r\n  - job_name: \"daprGatewayapi\"\r\n     static_configs:\r\n       - targets: [\"localhost:5022\"]\r\n\r\n-------------------------------------------------------------------------------------------------------------------------\r\n配置参数说明：\r\n- job_name: \"orderservice\" #定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] #订单微服务地址\r\n      \r\n详细配置(根据环境具体来选择使用)：\r\nscrape_configs:\r\n  - job_name: \"orderservice\" # 定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] # 订单微服务地址\r\n    scrape_interval: 15s # 抓取数据的时间间隔，默认为15秒\r\n    scrape_timeout: 10s # 抓取数据的超时时间，默认为10秒\r\n    metrics_path: \"/metrics\" # 指定要抓取的指标路径，默认为/metrics\r\n    scheme: \"https\" # 使用的协议，默认为http\r\n    basic_auth:      username: \"admin\" # 基本身份验证的用户名\r\n      password: \"password\" # 基本身份验证的密码\r\n    tls_config:      ca_file: \"/path/to/ca.crt\" # CA证书文件路径\r\n      cert_file: \"/path/to/client.crt\" # 客户端证书文件路径\r\n      key_file: \"/path/to/client.key\" # 客户端私钥文件路径\r\n    relabel_configs:\r\n      - source_labels: [__address__] # 源标签，指定要重写的标签\r\n        target_label: instance # 目标标签，指定重写后的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n      - source_labels: [__address__]\r\n        target_label: __param_target # 目标标签，指定要添加的标签名称\r\n        replacement: \"/metrics\" # 替换后的标签值\r\n      - source_labels: [__param_target]\r\n        target_label: job # 目标标签，指定要添加的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n\r\n\r\n\r\n5）通过nssm将Prometheus安装到windows服务，可以使用Grafana安装目录下的nssm\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> .\\nssm.exe install\r\n\r\n选择exe文件所在目录，Prometheus不需要启动参数，Arguments不需要，设置Service name为Prometheus\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net stop Prometheus\r\nPrometheus 服务正在停止.\r\nPrometheus 服务已成功停止。\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net start Prometheus\r\nPrometheus 服务正在启动 .\r\nPrometheus 服务已经启动成功。\r\n\r\n\r\n2.2、安装grafana\r\n1）下载grafana：https://grafana.com/grafana/download?platform=windows\r\n  选择安装包的形式，\r\n\r\n2）下载msi文件安装后，直接安装到windows服务，修改为手动启动\r\n\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net stop Grafana\r\nGrafana 服务正在停止.\r\nGrafana 服务已成功停止。\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net start Grafana\r\nGrafana 服务正在启动 .\r\nGrafana 服务已经启动成功。\r\n\r\n\r\n3）访问Grafana：http://localhost:3000/\r\n  默认账号密码都是admin，进入后修改为自己的密码，比如Zlj123456，相对于其他的监控软件，它这个UI确实做的不错。\r\n\r\n\r\n4）添加Prometheus数据源\r\n点击首页右侧 DATA SOURCE卡片，选择Prometheus\r\n\r\n添加Prometheus服务器地址，\r\n\r\n点击底部保存 Save&test\r\n\r\n\r\n5）添加Prometheus控制面板\r\n选择左侧菜单-Dashboards->Create dashboards，点击+Add visualization \r\n\r\nhttp://localhost:3000/dashboard/new?orgId=1&from=now-6h&to=now&timezone=browser\r\n\r\n\r\n3、应用集成\r\n  3.1、创建网关webapi项目，这里我创建的是一个普通的webapi项目，相对于AbpVnext项目集成有一点差异\r\n\r\n\r\n3.2、修改Program.cs，添加Prometheus的集成\r\n#添加命名空间\r\nusing Prometheus;\r\n\r\n# 在MapControllers之前集成\r\n//集成Prometheus\r\napp.UseMetricServer();\r\n//集成Prometheus监控数据访问\r\napp.UseHttpMetrics();\r\napp.MapControllers();\r\napp.Run();\r\n\r\n\r\n3.3、控制器中集成\r\nusing Dapr.Actors;\r\nusing Dapr.Actors.Client;\r\nusing Dapr.Client;\r\nusing FEShop.AppUserService.Services.Dtos.Account;\r\nusing FEShop.AppUserService.Services.Interfaces;\r\nusing Microsoft.AspNetCore.Mvc;\r\nusing Prometheus;\r\nnamespace FEShop.GatewayApi.Controllers.AppApi\r\n{\r\n    /// <summary>\r\n    /// APP用户网关\r\n    /// </summary>\r\n    [ApiController]\r\n    [Route(\"app/[controller]\")]\r\n    public class AppUserController : ControllerBase\r\n    {\r\n        private readonly ILogger<AppUserController> _logger;\r\n        private readonly IActorProxyFactory _actorProxyFactory;\r\n        //1、集成Prometheus\r\n        private static readonly Counter _requestCounter =  Metrics.CreateCounter(\"daprGatewayapi\", \"daprGatewayapi_help\", new CounterConfiguration\r\n        {\r\n            LabelNames = new[] { \"method\", \"endpoint\" }\r\n        });\r\n        /// <summary>\r\n        ///\r\n        /// </summary>\r\n        public AppUserController(ILogger<AppUserController> logger, IActorProxyFactory  actorProxyFactory)\r\n        {\r\n            _logger = logger;\r\n            _actorProxyFactory = actorProxyFactory;\r\n        }\r\n        /// <summary>\r\n        /// 用户登录\r\n        /// </summary>\r\n        /// <param name=\"dto\"></param>\r\n        /// <returns></returns>\r\n        [HttpPost(\"login\")]\r\n        public async Task<IActionResult> LoginAsync([FromBody] LoginInputDto dto)\r\n        {\r\n            //2、使用Prometheus记录请求计数\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/login\").Inc();\r\n            ActorId actorId = new ActorId(dto.Account);\r\n            IAccountService accountService =\r\n                _actorProxyFactory.CreateActorProxy<IAccountService>(\r\n                    actorId,\r\n                    \"AccountService\");\r\n            ResultObject<LoginOutputDto> result = await accountService.LoginAsync(dto);\r\n            return Ok(result);\r\n        }\r\n        /// <summary>\r\n        /// 测试Prometheus日志记录\r\n        /// </summary>\r\n        /// <returns></returns>\r\n        [HttpPost(\"testPrometheusLog\")]\r\n        public async Task<string> TestPrometheusLogAsync()\r\n        {\r\n            //3、测试Prometheus日志记录\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/testPrometheusLog\").Inc();\r\n            _logger.LogInformation(\"Test Prometheus logging\");\r\n            return \"Prometheus logging test successful\";\r\n        }\r\n    }\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n保存到APP查看\r\n下载印象笔记\r\n微服务中间件-资源监控Prometheus\r\n微服务中间件-资源监控Prometheus\r\n1、资源监控相关概念\r\n  1.1、什么是资源监控\r\n\r\n  1.2、不同监控工具对比\r\n\r\n\r\n2、资源监控Prometheus环境部署\r\n  2.1、安装Prometheus\r\n\r\n  1）下载Prometheus资源文件，下载地址：https://prometheus.io/download/#memcached_exporter\r\n\r\n2）、windows版本直接解压，然后运行\r\nPS D:\\> cd D:\\devtools\\prometheus-3.5.0.windows-amd64\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> ls\r\n目录: D:\\devtools\\prometheus-3.5.0.windows-amd64\r\n\r\nMode                 LastWriteTime         Length Name\r\n----                 -------------         ------ ----\r\n-a----         2025/8/23      7:39          11357 LICENSE\r\n-a----         2025/8/23      7:39           3773 NOTICE\r\n-a----         2025/8/23      7:39      161348096 prometheus.exe\r\n-a----         2025/8/23      7:39           1093 prometheus.yml\r\n-a----         2025/8/23      7:39      152659456 promtool.exe\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> .\\prometheus.exe\r\n\r\n\r\n\r\n3）、访问Prometheus\r\n  访问地址：http://localhost:9090/\r\n\r\n\r\n4）编辑Prometheus配置文件\r\n  windows位置：\\prometheus-3.5.0.windows-amd64\\prometheus.yml\r\n# my global config\r\nglobal:\r\n  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\r\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\r\n  # scrape_timeout is set to the global default (10s).\r\n\r\n\r\n# Alertmanager configuration\r\nalerting:\r\n  alertmanagers:\r\n    - static_configs:\r\n        - targets:[\"http://localhost:5022/\"]  #配置需要监控的微服务地址\r\n          # - alertmanager:9093\r\n\r\n\r\n# Load rules once and periodically evaluate them according to the global \'evaluation_interval\'.\r\nrule_files:\r\n  # - \"first_rules.yml\"\r\n  # - \"second_rules.yml\"\r\n\r\n\r\n# A scrape configuration containing exactly one endpoint to scrape:\r\n# Here it\'s Prometheus itself.\r\nscrape_configs:\r\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\r\n  - job_name: \"prometheus\"\r\n\r\n\r\n    # metrics_path defaults to \'/metrics\'\r\n    # scheme defaults to \'http\'.\r\n\r\n\r\n    static_configs:\r\n      - targets: [\"localhost:9090\"]\r\n       # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.\r\n        labels:\r\n          app: \"prometheus\"\r\n\r\n  # 添加资源监控目标\r\n  - job_name: \"daprGatewayapi\"\r\n     static_configs:\r\n       - targets: [\"localhost:5022\"]\r\n\r\n-------------------------------------------------------------------------------------------------------------------------\r\n配置参数说明：\r\n- job_name: \"orderservice\" #定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] #订单微服务地址\r\n      \r\n详细配置(根据环境具体来选择使用)：\r\nscrape_configs:\r\n  - job_name: \"orderservice\" # 定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] # 订单微服务地址\r\n    scrape_interval: 15s # 抓取数据的时间间隔，默认为15秒\r\n    scrape_timeout: 10s # 抓取数据的超时时间，默认为10秒\r\n    metrics_path: \"/metrics\" # 指定要抓取的指标路径，默认为/metrics\r\n    scheme: \"https\" # 使用的协议，默认为http\r\n    basic_auth:      username: \"admin\" # 基本身份验证的用户名\r\n      password: \"password\" # 基本身份验证的密码\r\n    tls_config:      ca_file: \"/path/to/ca.crt\" # CA证书文件路径\r\n      cert_file: \"/path/to/client.crt\" # 客户端证书文件路径\r\n      key_file: \"/path/to/client.key\" # 客户端私钥文件路径\r\n    relabel_configs:\r\n      - source_labels: [__address__] # 源标签，指定要重写的标签\r\n        target_label: instance # 目标标签，指定重写后的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n      - source_labels: [__address__]\r\n        target_label: __param_target # 目标标签，指定要添加的标签名称\r\n        replacement: \"/metrics\" # 替换后的标签值\r\n      - source_labels: [__param_target]\r\n        target_label: job # 目标标签，指定要添加的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n\r\n\r\n\r\n5）通过nssm将Prometheus安装到windows服务，可以使用Grafana安装目录下的nssm\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> .\\nssm.exe install\r\n\r\n选择exe文件所在目录，Prometheus不需要启动参数，Arguments不需要，设置Service name为Prometheus\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net stop Prometheus\r\nPrometheus 服务正在停止.\r\nPrometheus 服务已成功停止。\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net start Prometheus\r\nPrometheus 服务正在启动 .\r\nPrometheus 服务已经启动成功。\r\n\r\n\r\n2.2、安装grafana\r\n1）下载grafana：https://grafana.com/grafana/download?platform=windows\r\n  选择安装包的形式，\r\n\r\n2）下载msi文件安装后，直接安装到windows服务，修改为手动启动\r\n\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net stop Grafana\r\nGrafana 服务正在停止.\r\nGrafana 服务已成功停止。\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net start Grafana\r\nGrafana 服务正在启动 .\r\nGrafana 服务已经启动成功。\r\n\r\n\r\n3）访问Grafana：http://localhost:3000/\r\n  默认账号密码都是admin，进入后修改为自己的密码，比如Zlj123456，相对于其他的监控软件，它这个UI确实做的不错。\r\n\r\n\r\n4）添加Prometheus数据源\r\n点击首页右侧 DATA SOURCE卡片，选择Prometheus\r\n\r\n添加Prometheus服务器地址，\r\n\r\n点击底部保存 Save&test\r\n\r\n\r\n5）添加Prometheus控制面板\r\n选择左侧菜单-Dashboards->Create dashboards，点击+Add visualization \r\n\r\nhttp://localhost:3000/dashboard/new?orgId=1&from=now-6h&to=now&timezone=browser\r\n\r\n\r\n3、应用集成\r\n  3.1、创建网关webapi项目，这里我创建的是一个普通的webapi项目，相对于AbpVnext项目集成有一点差异\r\n\r\n\r\n3.2、修改Program.cs，添加Prometheus的集成\r\n#添加命名空间\r\nusing Prometheus;\r\n\r\n# 在MapControllers之前集成\r\n//集成Prometheus\r\napp.UseMetricServer();\r\n//集成Prometheus监控数据访问\r\napp.UseHttpMetrics();\r\napp.MapControllers();\r\napp.Run();\r\n\r\n\r\n3.3、控制器中集成\r\nusing Dapr.Actors;\r\nusing Dapr.Actors.Client;\r\nusing Dapr.Client;\r\nusing FEShop.AppUserService.Services.Dtos.Account;\r\nusing FEShop.AppUserService.Services.Interfaces;\r\nusing Microsoft.AspNetCore.Mvc;\r\nusing Prometheus;\r\nnamespace FEShop.GatewayApi.Controllers.AppApi\r\n{\r\n    /// <summary>\r\n    /// APP用户网关\r\n    /// </summary>\r\n    [ApiController]\r\n    [Route(\"app/[controller]\")]\r\n    public class AppUserController : ControllerBase\r\n    {\r\n        private readonly ILogger<AppUserController> _logger;\r\n        private readonly IActorProxyFactory _actorProxyFactory;\r\n        //1、集成Prometheus\r\n        private static readonly Counter _requestCounter =  Metrics.CreateCounter(\"daprGatewayapi\", \"daprGatewayapi_help\", new CounterConfiguration\r\n        {\r\n            LabelNames = new[] { \"method\", \"endpoint\" }\r\n        });\r\n        /// <summary>\r\n        ///\r\n        /// </summary>\r\n        public AppUserController(ILogger<AppUserController> logger, IActorProxyFactory  actorProxyFactory)\r\n        {\r\n            _logger = logger;\r\n            _actorProxyFactory = actorProxyFactory;\r\n        }\r\n        /// <summary>\r\n        /// 用户登录\r\n        /// </summary>\r\n        /// <param name=\"dto\"></param>\r\n        /// <returns></returns>\r\n        [HttpPost(\"login\")]\r\n        public async Task<IActionResult> LoginAsync([FromBody] LoginInputDto dto)\r\n        {\r\n            //2、使用Prometheus记录请求计数\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/login\").Inc();\r\n            ActorId actorId = new ActorId(dto.Account);\r\n            IAccountService accountService =\r\n                _actorProxyFactory.CreateActorProxy<IAccountService>(\r\n                    actorId,\r\n                    \"AccountService\");\r\n            ResultObject<LoginOutputDto> result = await accountService.LoginAsync(dto);\r\n            return Ok(result);\r\n        }\r\n        /// <summary>\r\n        /// 测试Prometheus日志记录\r\n        /// </summary>\r\n        /// <returns></returns>\r\n        [HttpPost(\"testPrometheusLog\")]\r\n        public async Task<string> TestPrometheusLogAsync()\r\n        {\r\n            //3、测试Prometheus日志记录\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/testPrometheusLog\").Inc();\r\n            _logger.LogInformation(\"Test Prometheus logging\");\r\n            return \"Prometheus logging test successful\";\r\n        }\r\n    }\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n保存到APP查看\r\n下载印象笔记\r\n微服务中间件-资源监控Prometheus\r\n微服务中间件-资源监控Prometheus\r\n1、资源监控相关概念\r\n  1.1、什么是资源监控\r\n\r\n  1.2、不同监控工具对比\r\n\r\n\r\n2、资源监控Prometheus环境部署\r\n  2.1、安装Prometheus\r\n\r\n  1）下载Prometheus资源文件，下载地址：https://prometheus.io/download/#memcached_exporter\r\n\r\n2）、windows版本直接解压，然后运行\r\nPS D:\\> cd D:\\devtools\\prometheus-3.5.0.windows-amd64\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> ls\r\n目录: D:\\devtools\\prometheus-3.5.0.windows-amd64\r\n\r\nMode                 LastWriteTime         Length Name\r\n----                 -------------         ------ ----\r\n-a----         2025/8/23      7:39          11357 LICENSE\r\n-a----         2025/8/23      7:39           3773 NOTICE\r\n-a----         2025/8/23      7:39      161348096 prometheus.exe\r\n-a----         2025/8/23      7:39           1093 prometheus.yml\r\n-a----         2025/8/23      7:39      152659456 promtool.exe\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> .\\prometheus.exe\r\n\r\n\r\n\r\n3）、访问Prometheus\r\n  访问地址：http://localhost:9090/\r\n\r\n\r\n4）编辑Prometheus配置文件\r\n  windows位置：\\prometheus-3.5.0.windows-amd64\\prometheus.yml\r\n# my global config\r\nglobal:\r\n  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\r\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\r\n  # scrape_timeout is set to the global default (10s).\r\n\r\n\r\n# Alertmanager configuration\r\nalerting:\r\n  alertmanagers:\r\n    - static_configs:\r\n        - targets:[\"http://localhost:5022/\"]  #配置需要监控的微服务地址\r\n          # - alertmanager:9093\r\n\r\n\r\n# Load rules once and periodically evaluate them according to the global \'evaluation_interval\'.\r\nrule_files:\r\n  # - \"first_rules.yml\"\r\n  # - \"second_rules.yml\"\r\n\r\n\r\n# A scrape configuration containing exactly one endpoint to scrape:\r\n# Here it\'s Prometheus itself.\r\nscrape_configs:\r\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\r\n  - job_name: \"prometheus\"\r\n\r\n\r\n    # metrics_path defaults to \'/metrics\'\r\n    # scheme defaults to \'http\'.\r\n\r\n\r\n    static_configs:\r\n      - targets: [\"localhost:9090\"]\r\n       # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.\r\n        labels:\r\n          app: \"prometheus\"\r\n\r\n  # 添加资源监控目标\r\n  - job_name: \"daprGatewayapi\"\r\n     static_configs:\r\n       - targets: [\"localhost:5022\"]\r\n\r\n-------------------------------------------------------------------------------------------------------------------------\r\n配置参数说明：\r\n- job_name: \"orderservice\" #定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] #订单微服务地址\r\n      \r\n详细配置(根据环境具体来选择使用)：\r\nscrape_configs:\r\n  - job_name: \"orderservice\" # 定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] # 订单微服务地址\r\n    scrape_interval: 15s # 抓取数据的时间间隔，默认为15秒\r\n    scrape_timeout: 10s # 抓取数据的超时时间，默认为10秒\r\n    metrics_path: \"/metrics\" # 指定要抓取的指标路径，默认为/metrics\r\n    scheme: \"https\" # 使用的协议，默认为http\r\n    basic_auth:      username: \"admin\" # 基本身份验证的用户名\r\n      password: \"password\" # 基本身份验证的密码\r\n    tls_config:      ca_file: \"/path/to/ca.crt\" # CA证书文件路径\r\n      cert_file: \"/path/to/client.crt\" # 客户端证书文件路径\r\n      key_file: \"/path/to/client.key\" # 客户端私钥文件路径\r\n    relabel_configs:\r\n      - source_labels: [__address__] # 源标签，指定要重写的标签\r\n        target_label: instance # 目标标签，指定重写后的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n      - source_labels: [__address__]\r\n        target_label: __param_target # 目标标签，指定要添加的标签名称\r\n        replacement: \"/metrics\" # 替换后的标签值\r\n      - source_labels: [__param_target]\r\n        target_label: job # 目标标签，指定要添加的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n\r\n\r\n\r\n5）通过nssm将Prometheus安装到windows服务，可以使用Grafana安装目录下的nssm\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> .\\nssm.exe install\r\n\r\n选择exe文件所在目录，Prometheus不需要启动参数，Arguments不需要，设置Service name为Prometheus\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net stop Prometheus\r\nPrometheus 服务正在停止.\r\nPrometheus 服务已成功停止。\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net start Prometheus\r\nPrometheus 服务正在启动 .\r\nPrometheus 服务已经启动成功。\r\n\r\n\r\n2.2、安装grafana\r\n1）下载grafana：https://grafana.com/grafana/download?platform=windows\r\n  选择安装包的形式，\r\n\r\n2）下载msi文件安装后，直接安装到windows服务，修改为手动启动\r\n\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net stop Grafana\r\nGrafana 服务正在停止.\r\nGrafana 服务已成功停止。\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net start Grafana\r\nGrafana 服务正在启动 .\r\nGrafana 服务已经启动成功。\r\n\r\n\r\n3）访问Grafana：http://localhost:3000/\r\n  默认账号密码都是admin，进入后修改为自己的密码，比如Zlj123456，相对于其他的监控软件，它这个UI确实做的不错。\r\n\r\n\r\n4）添加Prometheus数据源\r\n点击首页右侧 DATA SOURCE卡片，选择Prometheus\r\n\r\n添加Prometheus服务器地址，\r\n\r\n点击底部保存 Save&test\r\n\r\n\r\n5）添加Prometheus控制面板\r\n选择左侧菜单-Dashboards->Create dashboards，点击+Add visualization \r\n\r\nhttp://localhost:3000/dashboard/new?orgId=1&from=now-6h&to=now&timezone=browser\r\n\r\n\r\n3、应用集成\r\n  3.1、创建网关webapi项目，这里我创建的是一个普通的webapi项目，相对于AbpVnext项目集成有一点差异\r\n\r\n\r\n3.2、修改Program.cs，添加Prometheus的集成\r\n#添加命名空间\r\nusing Prometheus;\r\n\r\n# 在MapControllers之前集成\r\n//集成Prometheus\r\napp.UseMetricServer();\r\n//集成Prometheus监控数据访问\r\napp.UseHttpMetrics();\r\napp.MapControllers();\r\napp.Run();\r\n\r\n\r\n3.3、控制器中集成\r\nusing Dapr.Actors;\r\nusing Dapr.Actors.Client;\r\nusing Dapr.Client;\r\nusing FEShop.AppUserService.Services.Dtos.Account;\r\nusing FEShop.AppUserService.Services.Interfaces;\r\nusing Microsoft.AspNetCore.Mvc;\r\nusing Prometheus;\r\nnamespace FEShop.GatewayApi.Controllers.AppApi\r\n{\r\n    /// <summary>\r\n    /// APP用户网关\r\n    /// </summary>\r\n    [ApiController]\r\n    [Route(\"app/[controller]\")]\r\n    public class AppUserController : ControllerBase\r\n    {\r\n        private readonly ILogger<AppUserController> _logger;\r\n        private readonly IActorProxyFactory _actorProxyFactory;\r\n        //1、集成Prometheus\r\n        private static readonly Counter _requestCounter =  Metrics.CreateCounter(\"daprGatewayapi\", \"daprGatewayapi_help\", new CounterConfiguration\r\n        {\r\n            LabelNames = new[] { \"method\", \"endpoint\" }\r\n        });\r\n        /// <summary>\r\n        ///\r\n        /// </summary>\r\n        public AppUserController(ILogger<AppUserController> logger, IActorProxyFactory  actorProxyFactory)\r\n        {\r\n            _logger = logger;\r\n            _actorProxyFactory = actorProxyFactory;\r\n        }\r\n        /// <summary>\r\n        /// 用户登录\r\n        /// </summary>\r\n        /// <param name=\"dto\"></param>\r\n        /// <returns></returns>\r\n        [HttpPost(\"login\")]\r\n        public async Task<IActionResult> LoginAsync([FromBody] LoginInputDto dto)\r\n        {\r\n            //2、使用Prometheus记录请求计数\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/login\").Inc();\r\n            ActorId actorId = new ActorId(dto.Account);\r\n            IAccountService accountService =\r\n                _actorProxyFactory.CreateActorProxy<IAccountService>(\r\n                    actorId,\r\n                    \"AccountService\");\r\n            ResultObject<LoginOutputDto> result = await accountService.LoginAsync(dto);\r\n            return Ok(result);\r\n        }\r\n        /// <summary>\r\n        /// 测试Prometheus日志记录\r\n        /// </summary>\r\n        /// <returns></returns>\r\n        [HttpPost(\"testPrometheusLog\")]\r\n        public async Task<string> TestPrometheusLogAsync()\r\n        {\r\n            //3、测试Prometheus日志记录\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/testPrometheusLog\").Inc();\r\n            _logger.LogInformation(\"Test Prometheus logging\");\r\n            return \"Prometheus logging test successful\";\r\n        }\r\n    }\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n保存到APP查看\r\n下载印象笔记\r\n微服务中间件-资源监控Prometheus\r\n微服务中间件-资源监控Prometheus\r\n1、资源监控相关概念\r\n  1.1、什么是资源监控\r\n\r\n  1.2、不同监控工具对比\r\n\r\n\r\n2、资源监控Prometheus环境部署\r\n  2.1、安装Prometheus\r\n\r\n  1）下载Prometheus资源文件，下载地址：https://prometheus.io/download/#memcached_exporter\r\n\r\n2）、windows版本直接解压，然后运行\r\nPS D:\\> cd D:\\devtools\\prometheus-3.5.0.windows-amd64\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> ls\r\n目录: D:\\devtools\\prometheus-3.5.0.windows-amd64\r\n\r\nMode                 LastWriteTime         Length Name\r\n----                 -------------         ------ ----\r\n-a----         2025/8/23      7:39          11357 LICENSE\r\n-a----         2025/8/23      7:39           3773 NOTICE\r\n-a----         2025/8/23      7:39      161348096 prometheus.exe\r\n-a----         2025/8/23      7:39           1093 prometheus.yml\r\n-a----         2025/8/23      7:39      152659456 promtool.exe\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> .\\prometheus.exe\r\n\r\n\r\n\r\n3）、访问Prometheus\r\n  访问地址：http://localhost:9090/\r\n\r\n\r\n4）编辑Prometheus配置文件\r\n  windows位置：\\prometheus-3.5.0.windows-amd64\\prometheus.yml\r\n# my global config\r\nglobal:\r\n  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\r\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\r\n  # scrape_timeout is set to the global default (10s).\r\n\r\n\r\n# Alertmanager configuration\r\nalerting:\r\n  alertmanagers:\r\n    - static_configs:\r\n        - targets:[\"http://localhost:5022/\"]  #配置需要监控的微服务地址\r\n          # - alertmanager:9093\r\n\r\n\r\n# Load rules once and periodically evaluate them according to the global \'evaluation_interval\'.\r\nrule_files:\r\n  # - \"first_rules.yml\"\r\n  # - \"second_rules.yml\"\r\n\r\n\r\n# A scrape configuration containing exactly one endpoint to scrape:\r\n# Here it\'s Prometheus itself.\r\nscrape_configs:\r\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\r\n  - job_name: \"prometheus\"\r\n\r\n\r\n    # metrics_path defaults to \'/metrics\'\r\n    # scheme defaults to \'http\'.\r\n\r\n\r\n    static_configs:\r\n      - targets: [\"localhost:9090\"]\r\n       # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.\r\n        labels:\r\n          app: \"prometheus\"\r\n\r\n  # 添加资源监控目标\r\n  - job_name: \"daprGatewayapi\"\r\n     static_configs:\r\n       - targets: [\"localhost:5022\"]\r\n\r\n-------------------------------------------------------------------------------------------------------------------------\r\n配置参数说明：\r\n- job_name: \"orderservice\" #定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] #订单微服务地址\r\n      \r\n详细配置(根据环境具体来选择使用)：\r\nscrape_configs:\r\n  - job_name: \"orderservice\" # 定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] # 订单微服务地址\r\n    scrape_interval: 15s # 抓取数据的时间间隔，默认为15秒\r\n    scrape_timeout: 10s # 抓取数据的超时时间，默认为10秒\r\n    metrics_path: \"/metrics\" # 指定要抓取的指标路径，默认为/metrics\r\n    scheme: \"https\" # 使用的协议，默认为http\r\n    basic_auth:      username: \"admin\" # 基本身份验证的用户名\r\n      password: \"password\" # 基本身份验证的密码\r\n    tls_config:      ca_file: \"/path/to/ca.crt\" # CA证书文件路径\r\n      cert_file: \"/path/to/client.crt\" # 客户端证书文件路径\r\n      key_file: \"/path/to/client.key\" # 客户端私钥文件路径\r\n    relabel_configs:\r\n      - source_labels: [__address__] # 源标签，指定要重写的标签\r\n        target_label: instance # 目标标签，指定重写后的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n      - source_labels: [__address__]\r\n        target_label: __param_target # 目标标签，指定要添加的标签名称\r\n        replacement: \"/metrics\" # 替换后的标签值\r\n      - source_labels: [__param_target]\r\n        target_label: job # 目标标签，指定要添加的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n\r\n\r\n\r\n5）通过nssm将Prometheus安装到windows服务，可以使用Grafana安装目录下的nssm\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> .\\nssm.exe install\r\n\r\n选择exe文件所在目录，Prometheus不需要启动参数，Arguments不需要，设置Service name为Prometheus\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net stop Prometheus\r\nPrometheus 服务正在停止.\r\nPrometheus 服务已成功停止。\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net start Prometheus\r\nPrometheus 服务正在启动 .\r\nPrometheus 服务已经启动成功。\r\n\r\n\r\n2.2、安装grafana\r\n1）下载grafana：https://grafana.com/grafana/download?platform=windows\r\n  选择安装包的形式，\r\n\r\n2）下载msi文件安装后，直接安装到windows服务，修改为手动启动\r\n\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net stop Grafana\r\nGrafana 服务正在停止.\r\nGrafana 服务已成功停止。\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net start Grafana\r\nGrafana 服务正在启动 .\r\nGrafana 服务已经启动成功。\r\n\r\n\r\n3）访问Grafana：http://localhost:3000/\r\n  默认账号密码都是admin，进入后修改为自己的密码，比如Zlj123456，相对于其他的监控软件，它这个UI确实做的不错。\r\n\r\n\r\n4）添加Prometheus数据源\r\n点击首页右侧 DATA SOURCE卡片，选择Prometheus\r\n\r\n添加Prometheus服务器地址，\r\n\r\n点击底部保存 Save&test\r\n\r\n\r\n5）添加Prometheus控制面板\r\n选择左侧菜单-Dashboards->Create dashboards，点击+Add visualization \r\n\r\nhttp://localhost:3000/dashboard/new?orgId=1&from=now-6h&to=now&timezone=browser\r\n\r\n\r\n3、应用集成\r\n  3.1、创建网关webapi项目，这里我创建的是一个普通的webapi项目，相对于AbpVnext项目集成有一点差异\r\n\r\n\r\n3.2、修改Program.cs，添加Prometheus的集成\r\n#添加命名空间\r\nusing Prometheus;\r\n\r\n# 在MapControllers之前集成\r\n//集成Prometheus\r\napp.UseMetricServer();\r\n//集成Prometheus监控数据访问\r\napp.UseHttpMetrics();\r\napp.MapControllers();\r\napp.Run();\r\n\r\n\r\n3.3、控制器中集成\r\nusing Dapr.Actors;\r\nusing Dapr.Actors.Client;\r\nusing Dapr.Client;\r\nusing FEShop.AppUserService.Services.Dtos.Account;\r\nusing FEShop.AppUserService.Services.Interfaces;\r\nusing Microsoft.AspNetCore.Mvc;\r\nusing Prometheus;\r\nnamespace FEShop.GatewayApi.Controllers.AppApi\r\n{\r\n    /// <summary>\r\n    /// APP用户网关\r\n    /// </summary>\r\n    [ApiController]\r\n    [Route(\"app/[controller]\")]\r\n    public class AppUserController : ControllerBase\r\n    {\r\n        private readonly ILogger<AppUserController> _logger;\r\n        private readonly IActorProxyFactory _actorProxyFactory;\r\n        //1、集成Prometheus\r\n        private static readonly Counter _requestCounter =  Metrics.CreateCounter(\"daprGatewayapi\", \"daprGatewayapi_help\", new CounterConfiguration\r\n        {\r\n            LabelNames = new[] { \"method\", \"endpoint\" }\r\n        });\r\n        /// <summary>\r\n        ///\r\n        /// </summary>\r\n        public AppUserController(ILogger<AppUserController> logger, IActorProxyFactory  actorProxyFactory)\r\n        {\r\n            _logger = logger;\r\n            _actorProxyFactory = actorProxyFactory;\r\n        }\r\n        /// <summary>\r\n        /// 用户登录\r\n        /// </summary>\r\n        /// <param name=\"dto\"></param>\r\n        /// <returns></returns>\r\n        [HttpPost(\"login\")]\r\n        public async Task<IActionResult> LoginAsync([FromBody] LoginInputDto dto)\r\n        {\r\n            //2、使用Prometheus记录请求计数\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/login\").Inc();\r\n            ActorId actorId = new ActorId(dto.Account);\r\n            IAccountService accountService =\r\n                _actorProxyFactory.CreateActorProxy<IAccountService>(\r\n                    actorId,\r\n                    \"AccountService\");\r\n            ResultObject<LoginOutputDto> result = await accountService.LoginAsync(dto);\r\n            return Ok(result);\r\n        }\r\n        /// <summary>\r\n        /// 测试Prometheus日志记录\r\n        /// </summary>\r\n        /// <returns></returns>\r\n        [HttpPost(\"testPrometheusLog\")]\r\n        public async Task<string> TestPrometheusLogAsync()\r\n        {\r\n            //3、测试Prometheus日志记录\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/testPrometheusLog\").Inc();\r\n            _logger.LogInformation(\"Test Prometheus logging\");\r\n            return \"Prometheus logging test successful\";\r\n        }\r\n    }\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n保存到APP查看\r\n下载印象笔记\r\n微服务中间件-资源监控Prometheus\r\n微服务中间件-资源监控Prometheus\r\n1、资源监控相关概念\r\n  1.1、什么是资源监控\r\n\r\n  1.2、不同监控工具对比\r\n\r\n\r\n2、资源监控Prometheus环境部署\r\n  2.1、安装Prometheus\r\n\r\n  1）下载Prometheus资源文件，下载地址：https://prometheus.io/download/#memcached_exporter\r\n\r\n2）、windows版本直接解压，然后运行\r\nPS D:\\> cd D:\\devtools\\prometheus-3.5.0.windows-amd64\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> ls\r\n目录: D:\\devtools\\prometheus-3.5.0.windows-amd64\r\n\r\nMode                 LastWriteTime         Length Name\r\n----                 -------------         ------ ----\r\n-a----         2025/8/23      7:39          11357 LICENSE\r\n-a----         2025/8/23      7:39           3773 NOTICE\r\n-a----         2025/8/23      7:39      161348096 prometheus.exe\r\n-a----         2025/8/23      7:39           1093 prometheus.yml\r\n-a----         2025/8/23      7:39      152659456 promtool.exe\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> .\\prometheus.exe\r\n\r\n\r\n\r\n3）、访问Prometheus\r\n  访问地址：http://localhost:9090/\r\n\r\n\r\n4）编辑Prometheus配置文件\r\n  windows位置：\\prometheus-3.5.0.windows-amd64\\prometheus.yml\r\n# my global config\r\nglobal:\r\n  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\r\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\r\n  # scrape_timeout is set to the global default (10s).\r\n\r\n\r\n# Alertmanager configuration\r\nalerting:\r\n  alertmanagers:\r\n    - static_configs:\r\n        - targets:[\"http://localhost:5022/\"]  #配置需要监控的微服务地址\r\n          # - alertmanager:9093\r\n\r\n\r\n# Load rules once and periodically evaluate them according to the global \'evaluation_interval\'.\r\nrule_files:\r\n  # - \"first_rules.yml\"\r\n  # - \"second_rules.yml\"\r\n\r\n\r\n# A scrape configuration containing exactly one endpoint to scrape:\r\n# Here it\'s Prometheus itself.\r\nscrape_configs:\r\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\r\n  - job_name: \"prometheus\"\r\n\r\n\r\n    # metrics_path defaults to \'/metrics\'\r\n    # scheme defaults to \'http\'.\r\n\r\n\r\n    static_configs:\r\n      - targets: [\"localhost:9090\"]\r\n       # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.\r\n        labels:\r\n          app: \"prometheus\"\r\n\r\n  # 添加资源监控目标\r\n  - job_name: \"daprGatewayapi\"\r\n     static_configs:\r\n       - targets: [\"localhost:5022\"]\r\n\r\n-------------------------------------------------------------------------------------------------------------------------\r\n配置参数说明：\r\n- job_name: \"orderservice\" #定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] #订单微服务地址\r\n      \r\n详细配置(根据环境具体来选择使用)：\r\nscrape_configs:\r\n  - job_name: \"orderservice\" # 定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] # 订单微服务地址\r\n    scrape_interval: 15s # 抓取数据的时间间隔，默认为15秒\r\n    scrape_timeout: 10s # 抓取数据的超时时间，默认为10秒\r\n    metrics_path: \"/metrics\" # 指定要抓取的指标路径，默认为/metrics\r\n    scheme: \"https\" # 使用的协议，默认为http\r\n    basic_auth:      username: \"admin\" # 基本身份验证的用户名\r\n      password: \"password\" # 基本身份验证的密码\r\n    tls_config:      ca_file: \"/path/to/ca.crt\" # CA证书文件路径\r\n      cert_file: \"/path/to/client.crt\" # 客户端证书文件路径\r\n      key_file: \"/path/to/client.key\" # 客户端私钥文件路径\r\n    relabel_configs:\r\n      - source_labels: [__address__] # 源标签，指定要重写的标签\r\n        target_label: instance # 目标标签，指定重写后的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n      - source_labels: [__address__]\r\n        target_label: __param_target # 目标标签，指定要添加的标签名称\r\n        replacement: \"/metrics\" # 替换后的标签值\r\n      - source_labels: [__param_target]\r\n        target_label: job # 目标标签，指定要添加的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n\r\n\r\n\r\n5）通过nssm将Prometheus安装到windows服务，可以使用Grafana安装目录下的nssm\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> .\\nssm.exe install\r\n\r\n选择exe文件所在目录，Prometheus不需要启动参数，Arguments不需要，设置Service name为Prometheus\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net stop Prometheus\r\nPrometheus 服务正在停止.\r\nPrometheus 服务已成功停止。\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net start Prometheus\r\nPrometheus 服务正在启动 .\r\nPrometheus 服务已经启动成功。\r\n\r\n\r\n2.2、安装grafana\r\n1）下载grafana：https://grafana.com/grafana/download?platform=windows\r\n  选择安装包的形式，\r\n\r\n2）下载msi文件安装后，直接安装到windows服务，修改为手动启动\r\n\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net stop Grafana\r\nGrafana 服务正在停止.\r\nGrafana 服务已成功停止。\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net start Grafana\r\nGrafana 服务正在启动 .\r\nGrafana 服务已经启动成功。\r\n\r\n\r\n3）访问Grafana：http://localhost:3000/\r\n  默认账号密码都是admin，进入后修改为自己的密码，比如Zlj123456，相对于其他的监控软件，它这个UI确实做的不错。\r\n\r\n\r\n4）添加Prometheus数据源\r\n点击首页右侧 DATA SOURCE卡片，选择Prometheus\r\n\r\n添加Prometheus服务器地址，\r\n\r\n点击底部保存 Save&test\r\n\r\n\r\n5）添加Prometheus控制面板\r\n选择左侧菜单-Dashboards->Create dashboards，点击+Add visualization \r\n\r\nhttp://localhost:3000/dashboard/new?orgId=1&from=now-6h&to=now&timezone=browser\r\n\r\n\r\n3、应用集成\r\n  3.1、创建网关webapi项目，这里我创建的是一个普通的webapi项目，相对于AbpVnext项目集成有一点差异\r\n\r\n\r\n3.2、修改Program.cs，添加Prometheus的集成\r\n#添加命名空间\r\nusing Prometheus;\r\n\r\n# 在MapControllers之前集成\r\n//集成Prometheus\r\napp.UseMetricServer();\r\n//集成Prometheus监控数据访问\r\napp.UseHttpMetrics();\r\napp.MapControllers();\r\napp.Run();\r\n\r\n\r\n3.3、控制器中集成\r\nusing Dapr.Actors;\r\nusing Dapr.Actors.Client;\r\nusing Dapr.Client;\r\nusing FEShop.AppUserService.Services.Dtos.Account;\r\nusing FEShop.AppUserService.Services.Interfaces;\r\nusing Microsoft.AspNetCore.Mvc;\r\nusing Prometheus;\r\nnamespace FEShop.GatewayApi.Controllers.AppApi\r\n{\r\n    /// <summary>\r\n    /// APP用户网关\r\n    /// </summary>\r\n    [ApiController]\r\n    [Route(\"app/[controller]\")]\r\n    public class AppUserController : ControllerBase\r\n    {\r\n        private readonly ILogger<AppUserController> _logger;\r\n        private readonly IActorProxyFactory _actorProxyFactory;\r\n        //1、集成Prometheus\r\n        private static readonly Counter _requestCounter =  Metrics.CreateCounter(\"daprGatewayapi\", \"daprGatewayapi_help\", new CounterConfiguration\r\n        {\r\n            LabelNames = new[] { \"method\", \"endpoint\" }\r\n        });\r\n        /// <summary>\r\n        ///\r\n        /// </summary>\r\n        public AppUserController(ILogger<AppUserController> logger, IActorProxyFactory  actorProxyFactory)\r\n        {\r\n            _logger = logger;\r\n            _actorProxyFactory = actorProxyFactory;\r\n        }\r\n        /// <summary>\r\n        /// 用户登录\r\n        /// </summary>\r\n        /// <param name=\"dto\"></param>\r\n        /// <returns></returns>\r\n        [HttpPost(\"login\")]\r\n        public async Task<IActionResult> LoginAsync([FromBody] LoginInputDto dto)\r\n        {\r\n            //2、使用Prometheus记录请求计数\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/login\").Inc();\r\n            ActorId actorId = new ActorId(dto.Account);\r\n            IAccountService accountService =\r\n                _actorProxyFactory.CreateActorProxy<IAccountService>(\r\n                    actorId,\r\n                    \"AccountService\");\r\n            ResultObject<LoginOutputDto> result = await accountService.LoginAsync(dto);\r\n            return Ok(result);\r\n        }\r\n        /// <summary>\r\n        /// 测试Prometheus日志记录\r\n        /// </summary>\r\n        /// <returns></returns>\r\n        [HttpPost(\"testPrometheusLog\")]\r\n        public async Task<string> TestPrometheusLogAsync()\r\n        {\r\n            //3、测试Prometheus日志记录\r\n            _requestCounter.WithLabels(\"Post\", \"api/appuser/testPrometheusLog\").Inc();\r\n            _logger.LogInformation(\"Test Prometheus logging\");\r\n            return \"Prometheus logging test successful\";\r\n        }\r\n    }\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n保存到APP查看\r\n下载印象笔记\r\n微服务中间件-资源监控Prometheus\r\n微服务中间件-资源监控Prometheus\r\n1、资源监控相关概念\r\n  1.1、什么是资源监控\r\n\r\n  1.2、不同监控工具对比\r\n\r\n\r\n2、资源监控Prometheus环境部署\r\n  2.1、安装Prometheus\r\n\r\n  1）下载Prometheus资源文件，下载地址：https://prometheus.io/download/#memcached_exporter\r\n\r\n2）、windows版本直接解压，然后运行\r\nPS D:\\> cd D:\\devtools\\prometheus-3.5.0.windows-amd64\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> ls\r\n目录: D:\\devtools\\prometheus-3.5.0.windows-amd64\r\n\r\nMode                 LastWriteTime         Length Name\r\n----                 -------------         ------ ----\r\n-a----         2025/8/23      7:39          11357 LICENSE\r\n-a----         2025/8/23      7:39           3773 NOTICE\r\n-a----         2025/8/23      7:39      161348096 prometheus.exe\r\n-a----         2025/8/23      7:39           1093 prometheus.yml\r\n-a----         2025/8/23      7:39      152659456 promtool.exe\r\nPS D:\\devtools\\prometheus-3.5.0.windows-amd64> .\\prometheus.exe\r\n\r\n\r\n\r\n3）、访问Prometheus\r\n  访问地址：http://localhost:9090/\r\n\r\n\r\n4）编辑Prometheus配置文件\r\n  windows位置：\\prometheus-3.5.0.windows-amd64\\prometheus.yml\r\n# my global config\r\nglobal:\r\n  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\r\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\r\n  # scrape_timeout is set to the global default (10s).\r\n\r\n\r\n# Alertmanager configuration\r\nalerting:\r\n  alertmanagers:\r\n    - static_configs:\r\n        - targets:[\"http://localhost:5022/\"]  #配置需要监控的微服务地址\r\n          # - alertmanager:9093\r\n\r\n\r\n# Load rules once and periodically evaluate them according to the global \'evaluation_interval\'.\r\nrule_files:\r\n  # - \"first_rules.yml\"\r\n  # - \"second_rules.yml\"\r\n\r\n\r\n# A scrape configuration containing exactly one endpoint to scrape:\r\n# Here it\'s Prometheus itself.\r\nscrape_configs:\r\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\r\n  - job_name: \"prometheus\"\r\n\r\n\r\n    # metrics_path defaults to \'/metrics\'\r\n    # scheme defaults to \'http\'.\r\n\r\n\r\n    static_configs:\r\n      - targets: [\"localhost:9090\"]\r\n       # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.\r\n        labels:\r\n          app: \"prometheus\"\r\n\r\n  # 添加资源监控目标\r\n  - job_name: \"daprGatewayapi\"\r\n     static_configs:\r\n       - targets: [\"localhost:5022\"]\r\n\r\n-------------------------------------------------------------------------------------------------------------------------\r\n配置参数说明：\r\n- job_name: \"orderservice\" #定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] #订单微服务地址\r\n      \r\n详细配置(根据环境具体来选择使用)：\r\nscrape_configs:\r\n  - job_name: \"orderservice\" # 定时器任务执行名称\r\n    static_configs:\r\n      - targets: [\"localhost:44362\"] # 订单微服务地址\r\n    scrape_interval: 15s # 抓取数据的时间间隔，默认为15秒\r\n    scrape_timeout: 10s # 抓取数据的超时时间，默认为10秒\r\n    metrics_path: \"/metrics\" # 指定要抓取的指标路径，默认为/metrics\r\n    scheme: \"https\" # 使用的协议，默认为http\r\n    basic_auth:      username: \"admin\" # 基本身份验证的用户名\r\n      password: \"password\" # 基本身份验证的密码\r\n    tls_config:      ca_file: \"/path/to/ca.crt\" # CA证书文件路径\r\n      cert_file: \"/path/to/client.crt\" # 客户端证书文件路径\r\n      key_file: \"/path/to/client.key\" # 客户端私钥文件路径\r\n    relabel_configs:\r\n      - source_labels: [__address__] # 源标签，指定要重写的标签\r\n        target_label: instance # 目标标签，指定重写后的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n      - source_labels: [__address__]\r\n        target_label: __param_target # 目标标签，指定要添加的标签名称\r\n        replacement: \"/metrics\" # 替换后的标签值\r\n      - source_labels: [__param_target]\r\n        target_label: job # 目标标签，指定要添加的标签名称\r\n        replacement: \"orderservice\" # 替换后的标签值\r\n\r\n\r\n\r\n5）通过nssm将Prometheus安装到windows服务，可以使用Grafana安装目录下的nssm\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> .\\nssm.exe install\r\n\r\n选择exe文件所在目录，Prometheus不需要启动参数，Arguments不需要，设置Service name为Prometheus\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net stop Prometheus\r\nPrometheus 服务正在停止.\r\nPrometheus 服务已成功停止。\r\n\r\nPS D:\\devtools\\grafana\\nssm-2.24\\win64> net start Prometheus\r\nPrometheus 服务正在启动 .\r\nPrometheus 服务已经启动成功。\r\n\r\n\r\n2.2、安装grafana\r\n1）下载grafana：https://grafana.com/grafana/download?platform=windows\r\n  选择安装包的形式，\r\n\r\n2）下载msi文件安装后，直接安装到windows服务，修改为手动启动\r\n\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net stop Grafana\r\nGrafana 服务正在停止.\r\nGrafana 服务已成功停止。\r\nPS D:\\Workspace\\DotNet\\ZLJ.Dapr.MicroserviceProject> net start Grafana\r\nGrafana 服务正在启动 .\r\nGrafana 服务已经启动成功。\r\n\r\n\r\n3）访问Grafana：http://localhost:3000/\r\n  默认账号密码都是admin，进入后修改为自己的密码，比如Zlj123456，相对于其他的监控软件，它这个UI确实做的不错。\r\n\r\n\r\n4）添加Prometheus数据源\r\n点击首页右侧 DATA SOURCE卡片，选择Prometheus\r\n\r\n添加Prometheus服务器地址，\r\n\r\n点击底部保存 Save&test\r\n\r\n\r\n5）添加Prometheus控制面板\r\n选择左侧菜单-Dashboards->Create dashboards，点击+Add visualization \r\n\r\nhttp://localhost:3000/dashboard/new?orgId=1&from=now-6h&to=now&timezone=browser\r\n\r\n\r\n3、应用集成\r\n  3.1、创建网关webapi项目，这里我创建的是一个普通的webapi项目，相对于AbpVnext项目集成有一点差异\r\n\r\n\r\n3.2、修改Program.cs，添加Prometheus的集成\r\n#添加命名空间\r\nusing Prometheus;\r\n\r\n# 在MapControllers之前集成\r\n//集成Prometheus\r\napp.UseMetricServer();\r\n//集成Prometheus监控数据访问\r\napp.UseHttpMetrics();\r\napp.MapControllers();\r\napp.Run();\r\n\r\n\r\n3.3、控制器中集成\r\nusing Dapr.Actors;\r\nusing Dapr.Actors.Client;\r\nusing Dapr.Client;\r\nusing FEShop.AppUserService.Services.Dtos.Account;\r\nusing FEShop.AppUserService.Services.Interfaces;\r\nusing Microsoft.AspNetCore.Mvc;\r\nusing Prometheus;\r\nnamespace FEShop.GatewayApi.Controllers.AppApi\r\n{\r\n    /// <summary>\r\n    /// APP用户网关\r\n    /// </summary>\r\n    [ApiController]\r\n    [Route(\"app/[controller]\")]\r\n    public class AppUserController : ControllerBase\r\n    {\r\n        private readonly ILogger<AppUserController> _logger;\r\n        private readonly IActorProxyFactory _actorProxyFactory;\r\n        //1、集成Prometheus\r\n        private static readonly Counter _requestCounter =  Metrics.CreateCounter(\"daprGatewayapi\", \"daprGatewayapi_help\", new CounterConfiguration\r\n        {\r\n            LabelNames = new[] { \"method\", \"endpoint\" }\r\n        });\r\n        /// <summary>\r\n        ///\r\n        /// </summary>\r\n        public AppUserController(ILogger<AppUserController> logger, IActorProxyFactory  actorProxyFactory)\r\n        {\r\n         ', '1', 1, '游戏', 1, 1, 1911, 19, 11, 3, NULL, 1, 1, '2025-10-11 06:43:08', '刘海', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (4, 'Skywallking链路监控与dotnet项目集成', '链路监控是一种网络管理功能，它涉及到对网络链路的持续监控和性能评估，以确保网络的可靠性、稳定性和效率', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>微服务中间件-Skywalking链路监控</title>\r\n    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/github-dark.min.css\">\r\n    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js\"></script>\r\n    <script>hljs.highlightAll();</script>\r\n    <style>\r\n        :root {\r\n            --primary-color: #3498db;\r\n            --secondary-color: #2980b9;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --code-bg: #2d2d2d;\r\n            --border-color: #bdc3c7;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: #333;\r\n            background-color: #f9f9f9;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            display: flex;\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            box-shadow: 0 0 20px rgba(0, 0, 0, 0.1);\r\n            background-color: white;\r\n        }\r\n        \r\n        .sidebar {\r\n            width: 280px;\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 20px;\r\n            position: sticky;\r\n            top: 0;\r\n            height: 100vh;\r\n            overflow-y: auto;\r\n        }\r\n        \r\n        .sidebar h2 {\r\n            color: var(--light-color);\r\n            margin-bottom: 20px;\r\n            padding-bottom: 10px;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        .sidebar ul {\r\n            list-style: none;\r\n        }\r\n        \r\n        .sidebar li {\r\n            margin-bottom: 10px;\r\n        }\r\n        \r\n        .sidebar a {\r\n            color: var(--light-color);\r\n            text-decoration: none;\r\n            display: block;\r\n            padding: 8px 10px;\r\n            border-radius: 4px;\r\n            transition: all 0.3s;\r\n        }\r\n        \r\n        .sidebar a:hover {\r\n            background-color: rgba(255, 255, 255, 0.1);\r\n            color: white;\r\n        }\r\n        \r\n        .content {\r\n            flex: 1;\r\n            padding: 40px;\r\n        }\r\n        \r\n        header {\r\n            margin-bottom: 40px;\r\n            padding-bottom: 20px;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        h1 {\r\n            color: var(--dark-color);\r\n            margin-bottom: 10px;\r\n        }\r\n        \r\n        h2 {\r\n            color: var(--primary-color);\r\n            margin: 30px 0 15px;\r\n            padding-bottom: 10px;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        h3 {\r\n            color: var(--secondary-color);\r\n            margin: 20px 0 10px;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 15px;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-bottom: 20px;\r\n            margin-left: 20px;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .code-block {\r\n            background-color: var(--code-bg);\r\n            border-radius: 5px;\r\n            padding: 15px;\r\n            margin: 20px 0;\r\n            overflow-x: auto;\r\n        }\r\n        \r\n        .code-block pre {\r\n            margin: 0;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #fff8e1;\r\n            border-left: 4px solid #ffc107;\r\n            padding: 15px;\r\n            margin: 20px 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 20px 0;\r\n        }\r\n        \r\n        th, td {\r\n            border: 1px solid var(--border-color);\r\n            padding: 10px;\r\n            text-align: left;\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--light-color);\r\n        }\r\n        \r\n        .image-placeholder {\r\n            background-color: #f5f5f5;\r\n            border: 1px dashed #ccc;\r\n            padding: 40px 20px;\r\n            text-align: center;\r\n            margin: 20px 0;\r\n            color: #666;\r\n        }\r\n        \r\n        .download-link {\r\n            display: inline-block;\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            padding: 10px 15px;\r\n            border-radius: 4px;\r\n            text-decoration: none;\r\n            margin: 10px 0;\r\n            transition: background-color 0.3s;\r\n        }\r\n        \r\n        .download-link:hover {\r\n            background-color: var(--secondary-color);\r\n        }\r\n        \r\n        .command {\r\n            background-color: #2d2d2d;\r\n            color: #f8f8f2;\r\n            padding: 10px 15px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', monospace;\r\n            margin: 10px 0;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .container {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .sidebar {\r\n                width: 100%;\r\n                height: auto;\r\n                position: relative;\r\n            }\r\n            \r\n            .content {\r\n                padding: 20px;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <div class=\"container\">\r\n        <aside class=\"sidebar\">\r\n            <h2>SkyWalking链路监控</h2>\r\n            <ul>\r\n                <li><a href=\"#section1\">1. 链路监控概念</a>\r\n                    <ul>\r\n                        <li><a href=\"#section1-1\">1.1 什么是链路监控</a></li>\r\n                        <li><a href=\"#section1-2\">1.2 SkyWalking角色构成</a></li>\r\n                        <li><a href=\"#section1-3\">1.3 微服务链路监控拓扑图</a></li>\r\n                    </ul>\r\n                </li>\r\n                <li><a href=\"#section2\">2. 技术选型</a></li>\r\n                <li><a href=\"#section3\">3. Skywalking安装</a>\r\n                    <ul>\r\n                        <li><a href=\"#section3-1\">3.1 下载Skywalking</a></li>\r\n                        <li><a href=\"#section3-2\">3.2 解压Skywalking</a></li>\r\n                        <li><a href=\"#section3-3\">3.3 部署skywalking</a></li>\r\n                    </ul>\r\n                </li>\r\n                <li><a href=\"#section4\">4. Skywalking集成</a>\r\n                    <ul>\r\n                        <li><a href=\"#section4-1\">4.1 安装Consul</a></li>\r\n                        <li><a href=\"#section4-2\">4.2 创建商品微服务</a></li>\r\n                        <li><a href=\"#section4-3\">4.3 创建网关层</a></li>\r\n                        <li><a href=\"#section4-4\">4.4 创建网站聚合服务</a></li>\r\n                    </ul>\r\n                </li>\r\n                <li><a href=\"#section5\">5. 启动Skywalking客户端</a></li>\r\n            </ul>\r\n        </aside>\r\n        \r\n        <main class=\"content\">\r\n            <header>\r\n                <h1>微服务中间件-Skywalking链路监控</h1>\r\n                <p>本文详细介绍了Skywalking链路监控在微服务项目中的应用，包括注册中心consul基础，Ocelot网关技术。</p>\r\n            </header>\r\n            \r\n            <section id=\"section1\">\r\n                <h2>1. 链路监控概念</h2>\r\n                \r\n                <article id=\"section1-1\">\r\n                    <h3>1.1 什么是链路监控？</h3>\r\n                    <p>链路监控是一种网络管理功能，它涉及到对网络链路的持续监控和性能评估，以确保网络的可靠性、稳定性和效率。链路监控包括：</p>\r\n                    <ul>\r\n                        <li><strong>状态监控</strong>：实时监测网络链路的状态，包括链路是否在线、是否存在故障、数据传输是否正常等。</li>\r\n                        <li><strong>性能监控</strong>：评估链路的性能指标，如宽带利用率、吞吐量</li>\r\n                        <li><strong>故障管理</strong>：链路出现故障时，能够及时发现并报警，同时支持故障的定位和诊断</li>\r\n                        <li><strong>配置管理</strong>：监控链路配置的变化，确保链路参数符合网络设计要求</li>\r\n                        <li><strong>安全性监控</strong>：检测链路上的非法访问、攻击行为或其他安全威胁。</li>\r\n                    </ul>\r\n                </article>\r\n                \r\n                <article id=\"section1-2\">\r\n                    <h3>1.2 SkyWalking链路监控角色构成：</h3>\r\n                    <ul>\r\n                        <li><strong>SkyWalking Agent</strong>：负责从应用中收集链路信息，并发送给SkyWalking的OAP服务器。它会收集Tracing和Metrics数据，将数据格式化为SkyWalking适用的格式。</li>\r\n                        <li><strong>SkyWalking OAP（Observability Analysis Platform）</strong>：接收探针发送的数据，并在内存中使用分析引擎进行数据的整合运算，然后将数据存储到对应的存储介质上。OAP支持数据聚合、数据分析以及驱动数据流从探针到用户界面的流程。</li>\r\n                        <li><strong>Storage</strong>：通过开放的插件化的接口存放SkyWalking数据，目前支持的存储器有Elasticsearch、MySQL、ShardingSphere、TiDB、H2等。</li>\r\n                        <li><strong>UI界面</strong>：SkyWalking提供了一个Web界面，用于展示应用的链路追踪和性能监控数据，包括服务拓扑图、服务指标、调用链路等。</li>\r\n                    </ul>\r\n                </article>\r\n                \r\n                <article id=\"section1-3\">\r\n                    <h3>1.3 微服务中的链路监控拓扑图：</h3>\r\n                    <div class=\"image-placeholder\">\r\n                        [微服务链路监控拓扑图]\r\n                    </div>\r\n                    <div class=\"note\">\r\n                        <p><strong>注意：</strong>本章节篇幅较长，详细介绍了Skywalking链路监控在微服务项目中的应用，包括注册中心consul基础，Ocelot网关技术。</p>\r\n                    </div>\r\n                </article>\r\n            </section>\r\n            \r\n            <section id=\"section2\">\r\n                <h2>2. 技术选型</h2>\r\n                <p>目前一些主流的链路监控工具，如表所示：</p>\r\n                <table>\r\n                    <thead>\r\n                        <tr>\r\n                            <th>维度</th>\r\n                            <th>Skywalking</th>\r\n                            <th>Cat</th>\r\n                            <th>Zipkin</th>\r\n                            <th>PinPoint</th>\r\n                        </tr>\r\n                    </thead>\r\n                    <tbody>\r\n                        <tr>\r\n                            <td>实现方式</td>\r\n                            <td>Java探针，字节码增强</td>\r\n                            <td>代码埋点（拦截器，注解，过滤器等）</td>\r\n                            <td>拦截请求，发送（HTTP，MQ）数据至Zipkin服务</td>\r\n                            <td>Java探针，字节码增强</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>接入方式</td>\r\n                            <td>JavaAgent字节码，支持20+的中间件、框架、类库</td>\r\n                            <td>代码侵入</td>\r\n                            <td>基于Linkerd或者Sleuth方式，引入配置即可</td>\r\n                            <td>JavaAgent字节码，高并发情况下，代理对吞吐量的影响比skywalking和zipkin都大</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>agent到collector的协议</td>\r\n                            <td>gRPC</td>\r\n                            <td>http/tcp</td>\r\n                            <td>http,MQ</td>\r\n                            <td>thrift</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>可扩展性</td>\r\n                            <td>OAP+Web+agent+存储+zk，使得能够水平扩展以便支持大规模服务器集群。</td>\r\n                            <td>水平扩展服务端</td>\r\n                            <td>多个zipkin-Server实例进行异步消费mq中的监控信息</td>\r\n                            <td>collector+web+agent+存储，使得能够水平扩展以便支持大规模服务器集群。</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>数据存储</td>\r\n                            <td>ES，H2，Mysql，TiDB，Sharding-Sphere</td>\r\n                            <td>Mysql,Hdfs</td>\r\n                            <td>ES，mysql,Cassandra</td>\r\n                            <td>Hbase(RowKey精确查找，SCAN范围查找，全表扫描),Mysql</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>分析粒度</td>\r\n                            <td>方法级，全局调用统计、traceid查询，报警，JVM监控</td>\r\n                            <td>代码级，全局调用统计，报警，JVM监控</td>\r\n                            <td>接口级，支持traceid查询</td>\r\n                            <td>方法级，全局调用统计、报警</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>调用链可视化</td>\r\n                            <td>有</td>\r\n                            <td>有</td>\r\n                            <td>有</td>\r\n                            <td>有</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>报表</td>\r\n                            <td>中</td>\r\n                            <td>丰富</td>\r\n                            <td>少</td>\r\n                            <td>中</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>调用链应用拓扑</td>\r\n                            <td>好</td>\r\n                            <td>简单，仅限于服务与服务之间</td>\r\n                            <td>简单，仅限于服务与服务之间</td>\r\n                            <td>好</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>埋点方式</td>\r\n                            <td>无侵入</td>\r\n                            <td>侵入</td>\r\n                            <td>侵入</td>\r\n                            <td>无侵入</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>Heartbeat支持</td>\r\n                            <td>有</td>\r\n                            <td>有</td>\r\n                            <td>无</td>\r\n                            <td>有</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>Metric支持</td>\r\n                            <td>有</td>\r\n                            <td>有</td>\r\n                            <td>无</td>\r\n                            <td>无</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>是否支持webflux</td>\r\n                            <td>是</td>\r\n                            <td>否</td>\r\n                            <td>是</td>\r\n                            <td>是</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>客户端支持</td>\r\n                            <td>Java, C#, PHP, Node.js, Go</td>\r\n                            <td>Java、C/C++、Node.js、Python</td>\r\n                            <td>java</td>\r\n                            <td>Java,php</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>中文支持</td>\r\n                            <td>好</td>\r\n                            <td>好</td>\r\n                            <td>无</td>\r\n                            <td>无</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>社区支持</td>\r\n                            <td>好</td>\r\n                            <td>好</td>\r\n                            <td>好</td>\r\n                            <td>一般</td>\r\n                        </tr>\r\n                        <tr>\r\n                            <td>国内案例</td>\r\n                            <td>阿里，小米，滴滴，华为、当当等等</td>\r\n                            <td>美团、携程、陆金所等等</td>\r\n                            <td>京东，阿里定制后不开源</td>\r\n                            <td>暂无</td>\r\n                        </tr>\r\n                    </tbody>\r\n                </table>\r\n            </section>\r\n            \r\n            <section id=\"section3\">\r\n                <h2>3. Skywalking安装</h2>\r\n                \r\n                <article id=\"section3-1\">\r\n                    <h3>3.1 下载Skywalking</h3>\r\n                    <p>通过百度网盘分享的文件：apache-skywalking-apm-es7-8.7.0.tar.gz</p>\r\n                    <a href=\"#\" class=\"download-link\">链接：https://pan.baidu.com/s/12xMWkdbV2oIa4IsrZFzi5A?pwd=235a</a>\r\n                    <p>提取码：235a</p>\r\n                    <p>官网下载地址：<a href=\"https://skywalking.apache.org/downloads/\">https://skywalking.apache.org/downloads/</a></p>\r\n                </article>\r\n                \r\n                <article id=\"section3-2\">\r\n                    <h3>3.2 解压apache-skywalking-apm-es7-8.7.0.tar.gz到指定目录</h3>\r\n                    <p>不要放在有中文的目录下面。</p>\r\n                    <div class=\"image-placeholder\">\r\n                        [解压目录示意图]\r\n                    </div>\r\n                </article>\r\n                \r\n                <article id=\"section3-3\">\r\n                    <h3>3.3 部署skywalking</h3>\r\n                    \r\n                    <h4>3.3.1 部署skywalking需要安装Jdk，Es</h4>\r\n                    <p>Java JDK1.8+</p>\r\n                    <a href=\"#\" class=\"download-link\">链接：https://pan.baidu.com/s/1itcg1ntf4qL85WoONIsdvg?pwd=sfn4</a>\r\n                    <p>提取码：sfn4</p>\r\n                    \r\n                    <p>下载ElasticSearch</p>\r\n                    <a href=\"#\" class=\"download-link\">链接：https://pan.baidu.com/s/1H3HF-M4vM-N2zfWUh_Qkmw?pwd=f8az</a>\r\n                    <p>提取码：f8az</p>\r\n                    \r\n                    <p>启动ElasticSearch</p>\r\n                    <div class=\"command\">\r\n                        D:\\devtools\\elasticsearch-7.10.1\\bin>.\\elasticsearch.bat\r\n                    </div>\r\n                    \r\n                    <p>访问http://localhost:9200/ 查看es是否可用，当前使用的ES版本为7.10.1</p>\r\n                    <p>访问ES地址，浏览器会输出一段JSON数据</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"json\">{\r\n  \"name\" : \"ZLJ-TBOOK-8845\",\r\n  \"cluster_name\" : \"elasticsearch\",\r\n  \"cluster_uuid\" : \"B3kNkgxQQmqvvMRX8j2JUA\",\r\n  \"version\" : {\r\n    \"number\" : \"7.10.1\",\r\n    \"build_flavor\" : \"default\",\r\n    \"build_type\" : \"zip\",\r\n    \"build_hash\" : \"1c34507e66d7db1211f66f3513706fdf548736aa\",\r\n    \"build_date\" : \"2020-12-05T01:00:33.671820Z\",\r\n    \"build_snapshot\" : false,\r\n    \"lucene_version\" : \"8.7.0\",\r\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\r\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\r\n  },\r\n  \"tagline\" : \"You Know, for Search\"\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>3.3.2 启动Skywalking服务端：</h4>\r\n                    <p>1）配置Skywalking：</p>\r\n                    <p>打开Skywalking安装目录 apache-skywalking-apm-bin-es7\\config\\ 目录下找到application.yml配置文件并编辑</p>\r\n                    <p>在120行节点storage:下</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"yaml\">selector: ${SW_STORAGE:h2}</code></pre>\r\n                    </div>\r\n                    <p>这个是默认选用的数据库类型，当前是H2，将h2修改为elasticsearch7即可，其它配置采用默认</p>\r\n                    <p>修改后如下：</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"yaml\">selector: ${SW_STORAGE:elasticsearch7}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>配置说明：</p>\r\n                    <ul>\r\n                        <li>selector: ${SW_STORAGE:elasticsearch7} 选择存储方式</li>\r\n                        <li>gRPCHost: ${SW_CORE_GRPC_HOST:0.0.0.0} 数据收集IP</li>\r\n                        <li>gRPCPort: ${SW_CORE_GRPC_PORT:11800} 数据收集端口</li>\r\n                        <li>restHost: ${SW_CORE_REST_HOST:0.0.0.0} 数据显示IP</li>\r\n                        <li>restPort: ${SW_CORE_REST_PORT:12800} 数据显示端口</li>\r\n                    </ul>\r\n                    \r\n                    <p>ElasticSearch收集日志的方式有REST_FULL（端口12800）和GRPC（端口11800）两种模式</p>\r\n                    \r\n                    <p>2）运行skywalking，找到bin目录，执行oapService.bat</p>\r\n                    <p>启动skywalking，使用命令行执行oapService.bat，弹出SKyawlking-Collector（日志收集器）</p>\r\n                    <div class=\"command\">\r\n                        D:\\devtools\\apache-skywalking-apm-bin-es7\\bin>oapService.bat\r\n                    </div>\r\n                    <div class=\"image-placeholder\">\r\n                        [Skywalking启动界面]\r\n                    </div>\r\n                </article>\r\n            </section>\r\n            \r\n            <section id=\"section4\">\r\n                <h2>4. Skywalking集成</h2>\r\n                \r\n                <article id=\"section4-1\">\r\n                    <h3>4.1 安装Consul服务注册工具</h3>\r\n                    \r\n                    <h4>4.1.1 下载地址：</h4>\r\n                    <p><a href=\"https://developer.hashicorp.com/consul/install\">https://developer.hashicorp.com/consul/install</a></p>\r\n                    \r\n                    <h4>4.1.2 下载后解压：</h4>\r\n                    <div class=\"image-placeholder\">\r\n                        [Consul解压目录]\r\n                    </div>\r\n                    \r\n                    <h4>4.1.3 启动consul</h4>\r\n                    <div class=\"command\">\r\n                        D:\\devtools\\consul>consul.exe agent -dev\r\n                    </div>\r\n                    \r\n                    <h4>4.1.4 访问consul界面：</h4>\r\n                    <p><a href=\"http://localhost:8500/ui/dc1/services\">http://localhost:8500/ui/dc1/services</a></p>\r\n                    <div class=\"image-placeholder\">\r\n                        [Consul管理界面]\r\n                    </div>\r\n                </article>\r\n                \r\n                <article id=\"section4-2\">\r\n                    <h3>4.2 创建商品微服务</h3>\r\n                    \r\n                    <h4>4.2.1 命令行创建商品微服务项目</h4>\r\n                    <div class=\"command\">\r\n                        D:\\Workspace\\DotNet\\netCoreDemos\\dev\\36-Skywalking>abp new SkyWalking.ProductService -t app-nolayers --dbms mysql -u none -csf -v8.1.4\r\n                    </div>\r\n                    <p>如果安装了高版本的.net，可以使用--framework来指定使用的版本，防止与abp模块的版本不一致</p>\r\n                    <div class=\"command\">\r\n                        D:\\Workspace\\DotNet\\netCoreDemos\\dev\\36-Skywalking>abp new SkyWalking.ProductService -t app-nolayers --dbms mysql -u none -csf -v 8.1.4 --framework net8.0\r\n                    </div>\r\n                    \r\n                    <h4>4.2.2 简化项目，参考AbpVnext项目改造</h4>\r\n                    <p>保留以下包的引用，Consul、Mapster为新添加的包。</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"xml\">&lt;ItemGroup&gt;\r\n  &lt;!--新增包--&gt;\r\n  &lt;PackageReference Include=\"Consul\" Version=\"1.7.14.7\" /&gt;\r\n  &lt;PackageReference Include=\"Mapster\" Version=\"7.4.0\" /&gt;\r\n  &lt;PackageReference Include=\"SkyAPM.Agent.AspNetCore\" Version=\"2.2.0\" /&gt;\r\n&lt;/ItemGroup&gt;\r\n&lt;ItemGroup&gt;\r\n  &lt;!--Abp框架自带包--&gt;\r\n  &lt;PackageReference Include=\"Serilog.AspNetCore\" Version=\"8.0.0\" /&gt;\r\n  &lt;PackageReference Include=\"Serilog.Sinks.Async\" Version=\"1.5.0\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AspNetCore.Mvc\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.Autofac\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AutoMapper\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.Swashbuckle\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AspNetCore.Authentication.JwtBearer\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AspNetCore.Serilog\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.EntityFrameworkCore.MySQL\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Microsoft.Extensions.FileProviders.Embedded\" Version=\"8.0.0\" /&gt;\r\n  &lt;PackageReference Include=\"Microsoft.EntityFrameworkCore.Tools\" Version=\"8.0.0\"&gt;\r\n    &lt;IncludeAssets&gt;runtime; build; native; contentfiles; analyzers&lt;/IncludeAssets&gt;\r\n    &lt;PrivateAssets&gt;compile; contentFiles; build; buildMultitargeting; buildTransitive; analyzers; native&lt;/PrivateAssets&gt;\r\n  &lt;/PackageReference&gt;\r\n&lt;/ItemGroup&gt;</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.2.3 创建实体类、执行数据迁移、生成数据库表</h4>\r\n                    \r\n                    <p>1）创建产品实体类 Products.cs</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using Volo.Abp.Domain.Entities;\r\nnamespace SkyWalking.ProductService.Entities\r\n{\r\n    /// &lt;summary&gt;\r\n    /// 商品信息表\r\n    /// &lt;/summary&gt;\r\n    public class Products : Entity&lt;Guid&gt;\r\n    {\r\n        public string ProductCode { set; get; }    //商品编码\r\n        public string ProductUrl { set; get; }         // 商品主图\r\n        public string ProductTitle { set; get; }       //商品标题\r\n        public string ProductDescription { set; get; }     // 图文描述\r\n        public decimal ProductVirtualprice { set; get; } //商品虚拟价格\r\n        public decimal ProductPrice { set; get; }       //价格\r\n        public int ProductSort { set; get; }    //商品序号\r\n        public int ProductSold { set; get; }        //已售件数\r\n        public int ProductStock { set; get; }       //商品库存\r\n        public string ProductStatus { set; get; } // 商品状态\r\n        public List&lt;ProductImage&gt; productImages { set; get; }\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>2）创建产品图片实体类</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using Volo.Abp.Domain.Entities;\r\nnamespace SkyWalking.ProductService.Entities\r\n{\r\n    /// &lt;summary&gt;\r\n    /// 商品图片类\r\n    /// &lt;/summary&gt;\r\n    public class ProductImage : Entity&lt;Guid&gt;\r\n    {\r\n        public Guid ProductId { set; get; } // 商品编号\r\n        public int ImageSort { set; get; } // 排序\r\n        public string ImageStatus { set; get; } // 状态（1：启用，2：禁用）\r\n        public string ImageUrl { set; get; } // 图片url\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>3）创建产品仓储层：</p>\r\n                    <p>在Repositorys目录下创建仓储层接口和实现</p>\r\n                    \r\n                    <p>仓储层接口：</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using SkyWalking.ProductService.Entities;\r\nusing Volo.Abp.Domain.Repositories;\r\nnamespace SkyWalking.ProductService.Repositorys;\r\n/// &lt;summary&gt;\r\n/// 商品仓储接口\r\n/// &lt;/summary&gt;\r\npublic interface IProductRepository : IRepository&lt;Products,Guid&gt;\r\n{\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>仓储层实现：</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using SkyWalking.ProductService.Data;\r\nusing SkyWalking.ProductService.Entities;\r\nusing Volo.Abp.DependencyInjection;\r\nusing Volo.Abp.Domain.Repositories.EntityFrameworkCore;\r\nusing Volo.Abp.EntityFrameworkCore;\r\nnamespace SkyWalking.ProductService.Repositorys;\r\n/// &lt;summary&gt;\r\n/// 商品仓储实现\r\n/// &lt;/summary&gt;\r\n[Dependency(ServiceLifetime.Singleton)]\r\npublic class ProductRepository : EfCoreRepository&lt;ProductServiceDbContext, Products, Guid&gt;, IProductRepository\r\n{\r\n    public ProductRepository(IDbContextProvider&lt;ProductServiceDbContext&gt; dbContextProvider) : base(dbContextProvider)\r\n    {\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>4）创建产品Dto</p>\r\n                    <p>在Services目录-Dtos目录下创建ProductDto、IProductService、ProductService</p>\r\n                    <p>ProductDto：</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using Volo.Abp.Application.Dtos;\r\nnamespace SkyWalking.ProductService.Services.Dtos\r\n{\r\n    /// &lt;summary&gt;\r\n    /// 商品Dto\r\n    /// &lt;/summary&gt;\r\n    public class ProductDto : EntityDto&lt;Guid&gt;\r\n    {\r\n        public string ProductCode { set; get; }        //商品编码\r\n        public string ProductUrl { set; get; }         // 商品主图\r\n        public string ProductTitle { set; get; }       //商品标题\r\n        public string ProductDescription { set; get; } // 图文描述\r\n        public decimal ProductVirtualprice { set; get;}//商品虚拟价格\r\n        public decimal ProductPrice { set; get; }      //价格\r\n        public int ProductSort { set; get; }           //商品序号\r\n        public int ProductSold { set; get; }           //已售件数\r\n        public int ProductStock { set; get; }          //商品库存\r\n        public string ProductStatus { set; get; }      //商品状态\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>5）创建服务层接口和实现</p>\r\n                    <p>产品服务层接口 IProductService</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using SkyWalking.ProductService.Services.Dtos;\r\nusing Volo.Abp.Application.Services;\r\nnamespace SkyWalking.ProductService.Services;\r\n/// &lt;summary&gt;\r\n/// 商品服务层\r\n/// &lt;/summary&gt;\r\npublic interface IProductService : ICrudAppService&lt;ProductDto, Guid&gt;\r\n{\r\n    public Task&lt;List&lt;ProductDto&gt;&gt; GetProductsAsync();\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>产品服务层实现 ProductService</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using SkyWalking.ProductService.Entities;\r\nusing SkyWalking.ProductService.Repositorys;\r\nusing SkyWalking.ProductService.Services.Dtos;\r\nusing Mapster;\r\nusing Volo.Abp.Application.Services;\r\nusing Volo.Abp.DependencyInjection;\r\nnamespace SkyWalking.ProductService.Services;\r\n[Dependency(ServiceLifetime.Scoped)]\r\npublic class ProductService : CrudAppService&lt;Products, ProductDto, Guid&gt;, IProductService\r\n{\r\n    public IProductRepository _repository;\r\n    public ProductService(IProductRepository repository) : base(repository)\r\n    {\r\n        this._repository = repository;\r\n    }\r\n    /// &lt;summary&gt;\r\n    /// 查询商品数据\r\n    /// &lt;/summary&gt;\r\n    /// &lt;returns&gt;&lt;/returns&gt;\r\n    public Task&lt;List&lt;ProductDto&gt;&gt; GetProductsAsync()\r\n    {\r\n        List&lt;Products&gt; products = _repository.GetListAsync().Result;\r\n        var dto = products.Adapt&lt;List&lt;ProductDto&gt;&gt;();\r\n        return Task.FromResult(dto);\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>6）创建实体-Dto映射关系</p>\r\n                    <p>修改ObjectMapping目录下ProductServiceAutoMapperProfile.cs</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using AutoMapper;\r\nusing SkyWalking.ProductService.Entities;\r\nusing SkyWalking.ProductService.Services.Dtos;\r\nnamespace SkyWalking.ProductService.ObjectMapping;\r\npublic class ProductServiceAutoMapperProfile : Profile\r\n{\r\n    public ProductServiceAutoMapperProfile()\r\n    {\r\n        /* Create your AutoMapper object mappings here */\r\n        CreateMap&lt;Products, ProductDto&gt;();\r\n        CreateMap&lt;ProductDto, Products&gt;();\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>7）在DbContext中增加数据表的配置项</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using Microsoft.EntityFrameworkCore;\r\nusing SkyWalking.ProductService.Entities;\r\nusing Volo.Abp.EntityFrameworkCore;\r\nnamespace SkyWalking.ProductService.Data;\r\npublic class ProductServiceDbContext : AbpDbContext&lt;ProductServiceDbContext&gt;\r\n{\r\n    public ProductServiceDbContext(DbContextOptions&lt;ProductServiceDbContext&gt; options)\r\n        : base(options)\r\n    {\r\n    }\r\n    /// &lt;summary&gt;\r\n    /// 1、商品模型\r\n    /// &lt;/summary&gt;\r\n    public DbSet&lt;Products&gt; products { get; set; }\r\n    protected override void OnModelCreating(ModelBuilder builder)\r\n    {\r\n        base.OnModelCreating(builder);\r\n        /* Include modules to your migration db context */\r\n        /* Configure your own entities here */\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>8）执行数据迁移、生成数据库表</p>\r\n                    <div class=\"command\">\r\n                        #生成迁移文件\r\n                        D:\\Workspace\\DotNet\\netCoreDemos\\dev\\36-Skywalking\\SkyWalking.ProductService>dotnet ef migrations add SkywalkingProjectMigrations\r\n                        Build started...\r\n                        Build succeeded.\r\n                        Done. To undo this action, use \'ef migrations remove\'\r\n                        # 执行迁移文件、生成数据库表\r\n                        D:\\Workspace\\DotNet\\netCoreDemos\\dev\\36-Skywalking\\SkyWalking.ProductService>dotnet ef database update\r\n                    </div>\r\n                    \r\n                    <p>9) 创建控制器 ProductController.cs</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using SkyWalking.ProductService.Services;\r\nusing SkyWalking.ProductService.Services.Dtos;\r\nusing Mapster;\r\nusing Microsoft.AspNetCore.Mvc;\r\nusing Volo.Abp.Application.Dtos;\r\nusing Volo.Abp.AspNetCore.Mvc;\r\nnamespace SkyWalking.ProductService.Controllers\r\n{\r\n    /// &lt;summary&gt;\r\n    /// 商城首页控制器\r\n    /// &lt;/summary&gt;\r\n    [ApiController]\r\n    [Route(\"api/app/product\")]\r\n    public class ProductController : AbpController,IProductService\r\n    {\r\n        public IProductService productService { set; get; }\r\n        /// &lt;summary&gt;\r\n        /// 创建商品数据\r\n        /// &lt;/summary&gt;\r\n        /// &lt;param name=\"input\"&gt;&lt;/param&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        [HttpPost(\"create\")]\r\n        public async Task&lt;ProductDto&gt; CreateAsync([FromBody] ProductDto input)\r\n        {\r\n            try\r\n            {\r\n                var dto = await productService.CreateAsync(input);\r\n                return dto;\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                throw;\r\n            }\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 删除商品数据\r\n        /// &lt;/summary&gt;\r\n        /// &lt;param name=\"id\"&gt;&lt;/param&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        /// &lt;exception cref=\"NotImplementedException\"&gt;&lt;/exception&gt;\r\n        [HttpDelete(\"id\")]\r\n        public Task DeleteAsync(Guid id)\r\n        {\r\n            throw new NotImplementedException();\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 获取单个商品数据\r\n        /// &lt;/summary&gt;\r\n        /// &lt;param name=\"id\"&gt;&lt;/param&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        /// &lt;exception cref=\"NotImplementedException\"&gt;&lt;/exception&gt;\r\n        [HttpGet(\"id\")]\r\n        public Task&lt;ProductDto&gt; GetAsync(Guid id)\r\n        {\r\n            throw new NotImplementedException();\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 获取商品列表\r\n        /// &lt;/summary&gt;\r\n        /// &lt;param name=\"input\"&gt;&lt;/param&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        [HttpGet(\"GetList\")]\r\n        public Task&lt;PagedResultDto&lt;ProductDto&gt;&gt; GetListAsync(PagedAndSortedResultRequestDto input)\r\n        {\r\n            return productService.GetListAsync(input);\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 获取所有商品  \r\n        /// &lt;/summary&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        [HttpGet(\"GetProducts\")]\r\n        public Task&lt;List&lt;ProductDto&gt;&gt; GetProductsAsync()\r\n        {\r\n            Console.WriteLine(\"执行查询...GetProductsAsync\");\r\n            return productService.GetProductsAsync();\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 编辑商品数据\r\n        /// &lt;/summary&gt;\r\n        /// &lt;param name=\"id\"&gt;&lt;/param&gt;\r\n        /// &lt;param name=\"input\"&gt;&lt;/param&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        [HttpPut]\r\n        public Task&lt;ProductDto&gt; UpdateAsync(Guid id, ProductDto input)\r\n        {\r\n            return productService.UpdateAsync(id, input);\r\n        }\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>10）在根目录下创建Skywalking监控配置文件skyapm.json</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"json\">{\r\n  \"SkyWalking\": {\r\n    \"ServiceName\": \"productservice\",\r\n    \"Namespace\": \"\",\r\n    \"HeaderVersions\": [\r\n      \"sw8\"\r\n    ],\r\n    \"Sampling\": {\r\n      \"SamplePer3Secs\": -1,\r\n      \"Percentage\": -1.0\r\n    },\r\n    \"Logging\": {\r\n      \"Level\": \"Information\",\r\n      \"FilePath\": \"logs\\\\skyapm-{Date}.log\"\r\n    },\r\n    \"Transport\": {\r\n      \"Interval\": 3000,\r\n      \"ProtocolVersion\": \"v8\",\r\n      \"QueueSize\": 30000,\r\n      \"BatchSize\": 3000,\r\n      \"gRPC\": {\r\n        \"Servers\": \"localhost:11800\",\r\n        \"Timeout\": 10000,\r\n        \"ConnectTimeout\": 10000,\r\n        \"ReportTimeout\": 600000,\r\n        \"Authentication\": \"\"\r\n      }\r\n    }\r\n  }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.2.4 集成Consul服务注册</h4>\r\n                    <p>1）创建服务注册支持类</p>\r\n                    <p>服务注册选项ServiceRegistryOptions：</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">namespace SkyWalking.ProductService.Registrys\r\n{\r\n    public class ServiceRegistryOptions\r\n    {\r\n        public ServiceRegistryOptions()\r\n        {\r\n            this.ServiceID = Guid.NewGuid().ToString();\r\n        }\r\n        public string ServiceID { set; get; }\r\n        public string ConsulAddress { set; get; }\r\n        public string ServiceAddress { set; get; }\r\n        public string ServiceName { set; get; }\r\n        public string HealthCheckAddress { set; get; }\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>服务注册类ConsulServiceRegistry.cs：</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using Consul;\r\nusing Microsoft.Extensions.Options;\r\nnamespace SkyWalking.ProductService.Registrys\r\n{\r\n    /// &lt;summary&gt;\r\n    /// 服务注册类\r\n    /// &lt;/summary&gt;\r\n    public class ConsulServiceRegistry\r\n    {\r\n        public ServiceRegistryOptions serviceRegistryOptions;\r\n        public ConsulServiceRegistry(IOptions&lt;ServiceRegistryOptions&gt; options)\r\n        {\r\n            this.serviceRegistryOptions = options.Value;\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 服务注册\r\n        /// &lt;/summary&gt;\r\n        public void Registry()\r\n        {\r\n            // 1、创建consul服务器连接\r\n            var consulClient = new ConsulClient(configuration =&gt;\r\n            {\r\n                //1.1 填写consul服务地址\r\n                configuration.Address = new Uri(serviceRegistryOptions.ConsulAddress);\r\n            });\r\n            // 2、创建服务地址\r\n            var uri = new Uri(serviceRegistryOptions.ServiceAddress);\r\n            // 3、注册服务地址\r\n            //3.1、准备AgentServiceRegistration\r\n            var registration = new AgentServiceRegistration\r\n            {\r\n                ID = serviceRegistryOptions.ServiceID,\r\n                Name = serviceRegistryOptions.ServiceName,\r\n                Address = uri.Host, //IP地址\r\n                Port = uri.Port, //端口号\r\n                Tags = new string[] { },\r\n                Check = new AgentServiceCheck //心跳焦侧机制： 检测微服务是否正常\r\n                {\r\n                    // 3.2、设置consul健康检查超时间10秒\r\n                    Timeout = TimeSpan.FromSeconds(10),\r\n                    // 3.3、服务停止30秒后注销服务\r\n                    DeregisterCriticalServiceAfter = TimeSpan.FromSeconds(30),\r\n                    // 3.4、consul健康检查地址\r\n                    HTTP = serviceRegistryOptions.HealthCheckAddress,\r\n                    // 3.5 consul健康检查间隔时间\r\n                    Interval = TimeSpan.FromSeconds(10),\r\n                }\r\n            };\r\n            //3.6、注册服务地址\r\n            consulClient.Agent.ServiceRegister(registration).Wait();\r\n            Console.WriteLine($\"微服务地址注册成功：{serviceRegistryOptions.ServiceAddress}\");\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 删除注册\r\n        /// &lt;/summary&gt;\r\n        public void DeRegistry()\r\n        {\r\n            // 1、创建consul服务器连接\r\n            var consulClient = new ConsulClient(configuration =&gt;\r\n            {\r\n                //1.1 填写consul服务地址（http://localhost:8500/）\r\n                configuration.Address = new Uri(serviceRegistryOptions.ConsulAddress);\r\n            });\r\n            //2、服务删除\r\n            consulClient.Agent.ServiceDeregister(serviceRegistryOptions.ServiceID).Wait();\r\n            Console.WriteLine($\"微服务地址删除成功：{serviceRegistryOptions.ServiceAddress}\");\r\n        }\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>服务注册入口-自动API注册</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">namespace SkyWalking.ProductService.Registrys;\r\n/// &lt;summary&gt;\r\n/// Host服务\r\n/// &lt;/summary&gt;\r\npublic class ServiceRegistryHostService : IHostedService\r\n{\r\n    public ConsulServiceRegistry consulServiceRegistry { get; set; }\r\n    public ServiceRegistryHostService(ConsulServiceRegistry consulServiceRegistry)\r\n    {\r\n        this.consulServiceRegistry = consulServiceRegistry;\r\n    }\r\n    /// &lt;summary&gt;\r\n    /// 项目启动时，调用服务注册方法\r\n    /// &lt;/summary&gt;\r\n    /// &lt;param name=\"cancellationToken\"&gt;&lt;/param&gt;\r\n    /// &lt;returns&gt;&lt;/returns&gt;\r\n    /// &lt;exception cref=\"NotImplementedException\"&gt;&lt;/exception&gt;\r\n    public Task StartAsync(CancellationToken cancellationToken)\r\n    {\r\n        consulServiceRegistry.Registry();\r\n        return Task.CompletedTask;  \r\n    }\r\n    /// &lt;summary&gt;\r\n    /// 项目关闭时，调用服务删除方法\r\n    /// &lt;/summary&gt;\r\n    /// &lt;param name=\"cancellationToken\"&gt;&lt;/param&gt;\r\n    /// &lt;returns&gt;&lt;/returns&gt;\r\n    public Task StopAsync(CancellationToken cancellationToken)\r\n    {\r\n        consulServiceRegistry.DeRegistry();\r\n        return Task.CompletedTask;  \r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>2）在ProductServiceModule中集成Consul服务注册</p>\r\n                    <p>修改ProductServiceModule中的ConfigureService方法，添加服务注册</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">public override void ConfigureServices(ServiceConfigurationContext context)\r\n{\r\n    var hostingEnvironment = context.Services.GetHostingEnvironment();\r\n    var configuration = context.Services.GetConfiguration();\r\n    ConfigureMultiTenancy();\r\n    ConfigureUrls(configuration);\r\n    ConfigureAutoMapper(context);\r\n    ConfigureSwagger(context.Services, configuration);\r\n    ConfigureAutoApiControllers();\r\n    ConfigureVirtualFiles(hostingEnvironment);\r\n    ConfigureLocalization();\r\n    ConfigureCors(context, configuration);\r\n    ConfigureDataProtection(context);\r\n    ConfigureEfCore(context);\r\n    //取消防伪令牌验证\r\n    Configure&lt;AbpAntiForgeryOptions&gt;(options =&gt; { options.AutoValidate = false; });\r\n    //1、注册心跳检测\r\n    context.Services.AddHealthChecks();\r\n    //2、注入ConsulServiceRegistry类\r\n    context.Services.AddSingleton&lt;ConsulServiceRegistry&gt;();\r\n    //3、注入ServiceRegistryHostService类\r\n    context.Services.AddHostedService&lt;ServiceRegistryHostService&gt;();\r\n    //4、注册ServiceRegistryOptions类，从配置文件获取注入到IOC容器\r\n    context.Services.Configure&lt;ServiceRegistryOptions&gt;(configuration.GetSection(\"ServiceRegistry\"));\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>3）在OnApplicationInitialization方法中添加心跳检测</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">public override void OnApplicationInitialization(ApplicationInitializationContext context)\r\n{\r\n    。。。此处省略其他代码。。。\r\n    app.UseAuditing();\r\n    app.UseAbpSerilogEnrichers();\r\n    app.UseConfiguredEndpoints();  \r\n    \r\n    // 2、注册心跳检测中间件（类似于控制器）\r\n    app.UseHealthChecks(\"/HealthCheck\");\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>4）在appsettings.json中配置服务注册</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"json\">//服务注册\r\n\"ServiceRegistry\": {\r\n  \"ConsulAddress\": \"http://localhost:8500/\", //Consul地址\r\n  \"ServiceAddress\": \"http://localhost:44317/\",\r\n  \"ServiceName\": \"productservice\",\r\n  \"HealthCheckAddress\": \"http://localhost:44317/HealthCheck\"\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.2.5 集成Skywalking</h4>\r\n                    <p>1) 修改launchSettings.json，在执行环境environmentVariables下面添加\"ASPNETCORE_HOSTINGSTARTUPASSEMBLIES\": \"SkyAPM.Agent.AspNetCore\"</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"json\">{\r\n  \"SkyWalking.ProductService\": {\r\n   \"commandName\": \"Project\",\r\n   \"launchBrowser\": true,\r\n   \"applicationUrl\": \"http://localhost:44317\",\r\n   \"environmentVariables\": {\r\n     \"ASPNETCORE_ENVIRONMENT\": \"Development\",\r\n     \"ASPNETCORE_HOSTINGSTARTUPASSEMBLIES\": \"SkyAPM.Agent.AspNetCore\"\r\n   }\r\n }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.2.6 启动商品微服务</h4>\r\n                    <div class=\"command\">\r\n                        D:\\Workspace\\DotNet\\netCoreDemos\\dev\\36-Skywalking\\SkyWalking.ProductService>dotnet run\r\n                        [12:32:15 INF] Loaded ABP modules:\r\n                        [12:32:15 INF] - SkyWalking.ProductService.ProductServiceModule\r\n                        微服务地址注册成功：http://localhost:44317/\r\n                        [12:32:17 INF] Now listening on: http://localhost:44317\r\n                        [12:32:17 INF] Application started. Press Ctrl+C to shut down.\r\n                        [12:32:17 INF] Hosting environment: Development\r\n                        [12:32:17 INF] Content root path: D:\\Workspace\\DotNet\\netCoreDemos\\dev\\36-Skywalking\\SkyWalking.ProductService\r\n                        [12:32:20 INF] Request starting HTTP/1.1 GET http://localhost:44317/HealthCheck - null null\r\n                        [12:32:20 INF] Request finished HTTP/1.1 GET http://localhost:44317/HealthCheck - 200 null text/plain 108.798ms\r\n                    </div>\r\n                    \r\n                    <h4>4.2.7 查看consul ui界面</h4>\r\n                    <p>当productservice为绿色表示注册成功，为红色时检查心跳检测地址配置是否正确。</p>\r\n                    <div class=\"image-placeholder\">\r\n                        [Consul服务注册成功界面]\r\n                    </div>\r\n                </article>\r\n                \r\n                <article id=\"section4-3\">\r\n                    <h3>4.3 创建网关层</h3>\r\n                    \r\n                    <h4>4.3.1 命令行创建基于.net8的网关层项目</h4>\r\n                    <div class=\"command\">\r\n                        D:\\Workspace\\DotNet\\netCoreDemos\\dev\\36-Skywalking>abp new SkyWalking.GateWay -t app-nolayers --dbms mysql -u none -csf -v 8.1.4 --framework net8.0\r\n                    </div>\r\n                    \r\n                    <h4>4.3.2 添加Ocelot相关模块的nuget包</h4>\r\n                    <p>删除其余的包，配置如下：</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"xml\">&lt;ItemGroup&gt;\r\n  &lt;!--Ocelot网关技术--&gt;\r\n  &lt;PackageReference Include=\"Ocelot\" Version=\"23.3.3\" /&gt;\r\n  &lt;PackageReference Include=\"Ocelot.Cache.CacheManager\" Version=\"23.3.3\" /&gt;\r\n  &lt;PackageReference Include=\"Ocelot.Provider.Consul\" Version=\"23.3.3\" /&gt;\r\n  &lt;PackageReference Include=\"Ocelot.Provider.Polly\" Version=\"23.3.3\" /&gt;\r\n  &lt;!--Skywalking链路监控模块--&gt;\r\n  &lt;PackageReference Include=\"SkyAPM.Agent.AspNetCore\" Version=\"2.2.0\" /&gt;\r\n&lt;/ItemGroup&gt;\r\n&lt;ItemGroup&gt;\r\n  &lt;!--Abp框架相关包--&gt;\r\n  &lt;PackageReference Include=\"Serilog.AspNetCore\" Version=\"8.0.0\" /&gt;\r\n  &lt;PackageReference Include=\"Serilog.Sinks.Async\" Version=\"1.5.0\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AspNetCore.Mvc\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.Autofac\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AutoMapper\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.Swashbuckle\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AspNetCore.Authentication.JwtBearer\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AspNetCore.Serilog\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.EntityFrameworkCore.MySQL\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Microsoft.Extensions.FileProviders.Embedded\" Version=\"8.0.0\" /&gt;\r\n  &lt;PackageReference Include=\"Microsoft.EntityFrameworkCore.Tools\" Version=\"8.0.0\"&gt;\r\n    &lt;IncludeAssets&gt;runtime; build; native; contentfiles; analyzers&lt;/IncludeAssets&gt;\r\n    &lt;PrivateAssets&gt;compile; contentFiles; build; buildMultitargeting; buildTransitive; analyzers; native&lt;/PrivateAssets&gt;\r\n  &lt;/PackageReference&gt;\r\n&lt;/ItemGroup&gt;</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.3.3 配置appsettings.json</h4>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"json\">{\r\n  。。。省略其他配置。。。\r\n\"Routes\": [\r\n   {\r\n     \"UpstreamPathTemplate\": \"/api/app/product/{everything}\",\r\n     \"UpstreamHttpMethod\": [ \"Put\", \"Delete\", \"Get\", \"Post\" ],\r\n     \"DownstreamPathTemplate\": \"/api/app/product/{everything}\",\r\n     \"DownstreamScheme\": \"http\",\r\n     \"LoadBalancerOptions\": {\r\n       \"Type\": \"RoundRobin\" //\"RoundRobin\" // \"LeastConnection\"\r\n     },\r\n     // 直连模式核心配置：手动配置，直接指定下游服务地址\r\n     \"DownstreamHostAndPorts\": [\r\n       {\r\n         \"Host\": \"localhost\", // 替换为实际下游服务 IP 或域名\r\n         \"Port\": 44317 // 替换为实际下游服务端口\r\n       }\r\n     ]\r\n   }\r\n],\r\n\"GlobalConfiguration\": {\r\n   \"BaseUrl\": \"http://localhost:44316\", //API网关项目地址\r\n   \"ServiceDiscoveryProvider\": {\r\n     \"Scheme\": \"http\",\r\n     \"Host\": \"localhost\",\r\n     \"Port\": 8500,\r\n     \"Type\": \"Consul\"\r\n   }\r\n}\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.3.4 复制SkyWalking.ProductService项目中的IProductService.cs和ProductDto到Services目录下</h4>\r\n                    \r\n                    <h4>4.3.5 在GateWayModule.cs中集成Ocelot</h4>\r\n                    <p>修改ConfigureServices</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">public override void ConfigureServices(ServiceConfigurationContext context)\r\n{\r\n     var hostingEnvironment = context.Services.GetHostingEnvironment();\r\n     var configuration = context.Services.GetConfiguration();\r\n     ConfigureUrls(configuration);\r\n     ConfigureAutoMapper(context);\r\n     ConfigureSwagger(context.Services, configuration);\r\n     ConfigureAutoApiControllers();\r\n     ConfigureVirtualFiles(hostingEnvironment);\r\n     ConfigureLocalization();\r\n     ConfigureCors(context, configuration);\r\n     ConfigureDataProtection(context);\r\n     ConfigureEfCore(context);\r\n\r\n     // 1、集成Ocelot，集成Ocelot.Provider.Polly实现熔断效果：当某个微服务出现故障或响应过慢时，熔断器会快速失败并停止对该服务的请求，\r\n     //避免系统资源被耗尽或雪崩效应发生。\r\n     context.Services.AddOcelot(context.Services.GetConfiguration())\r\n                      .AddConsul()\r\n                      .AddPolly()\r\n                      .AddCacheManager(x => x.WithDictionaryHandle());\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>在OnApplicationInitialization中集成Ocelot</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">public override void OnApplicationInitialization(ApplicationInitializationContext context)\r\n{\r\n    var app = context.GetApplicationBuilder();\r\n    var env = context.GetEnvironment();\r\n    if (env.IsDevelopment())\r\n    {\r\n        app.UseDeveloperExceptionPage();\r\n    }\r\n    app.UseAbpRequestLocalization();\r\n    app.UseCorrelationId();\r\n    app.UseStaticFiles();\r\n    app.UseRouting();\r\n    app.UseCors();\r\n    app.UseAuthentication();\r\n    app.UseUnitOfWork();\r\n    app.UseAuthorization();\r\n    app.UseSwagger();\r\n    app.UseAbpSwaggerUI(options =>\r\n    {\r\n        options.SwaggerEndpoint(\"/swagger/v1/swagger.json\", \"WebGateway API\");\r\n        var configuration = context.GetConfiguration();\r\n        options.OAuthClientId(configuration[\"AuthServer:SwaggerClientId\"]);\r\n        options.OAuthScopes(\"WebGateway\");\r\n    });\r\n    app.UseAuditing();\r\n    app.UseAbpSerilogEnrichers();\r\n    //app.UseConfiguredEndpoints();\r\n    //修改网关层的路由规则\r\n    app.MapWhen(\r\n        ctx =>\r\n            ctx.Request.Path.ToString().StartsWith(\"/api/abp/\") ||\r\n            ctx.Request.Path.ToString().StartsWith(\"/Abp/\") ||\r\n            ctx.Request.Path.ToString().StartsWith(\"/swagger/\"),\r\n        app2 =>\r\n        {\r\n            app2.UseRouting();\r\n            app2.UseConfiguredEndpoints();\r\n        }\r\n    );\r\n    //  2、集成Ocelot\r\n    app.UseOcelot().Wait();\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.3.6 创建ProductController.cs</h4>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using SkyWalking.ProductService.Services;\r\nusing SkyWalking.ProductService.Services.Dtos;\r\nusing Microsoft.AspNetCore.Mvc;\r\nusing Volo.Abp.Application.Dtos;\r\nusing Volo.Abp.AspNetCore.Mvc;\r\nnamespace SkyWalking.GateWay.Controllers\r\n{\r\n    /// &lt;summary&gt;\r\n    /// 商城首页控制器\r\n    /// &lt;/summary&gt;\r\n    [ApiController]\r\n    [Route(\"api/app/product\")]\r\n    public class ProductController : AbpController,IProductService\r\n    {\r\n        public IProductService productService { set; get; }\r\n        /// &lt;summary&gt;\r\n        /// 创建商品数据\r\n        /// &lt;/summary&gt;\r\n        /// &lt;param name=\"input\"&gt;&lt;/param&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        [HttpPost(\"create\")]\r\n        public async Task&lt;ProductDto&gt; CreateAsync([FromBody] ProductDto input)\r\n        {\r\n            try\r\n            {\r\n                var dto = await productService.CreateAsync(input);\r\n                return dto;\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                throw;\r\n            }\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 删除商品数据\r\n        /// &lt;/summary&gt;\r\n        /// &lt;param name=\"id\"&gt;&lt;/param&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        /// &lt;exception cref=\"NotImplementedException\"&gt;&lt;/exception&gt;\r\n        [HttpDelete(\"id\")]\r\n        public Task DeleteAsync(Guid id)\r\n        {\r\n            throw new NotImplementedException();\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 获取单个商品数据\r\n        /// &lt;/summary&gt;\r\n        /// &lt;param name=\"id\"&gt;&lt;/param&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        /// &lt;exception cref=\"NotImplementedException\"&gt;&lt;/exception&gt;\r\n        [HttpGet(\"id\")]\r\n        public Task&lt;ProductDto&gt; GetAsync(Guid id)\r\n        {\r\n            throw new NotImplementedException();\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 获取商品列表\r\n        /// &lt;/summary&gt;\r\n        /// &lt;param name=\"input\"&gt;&lt;/param&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        [HttpGet(\"GetList\")]\r\n        public Task&lt;PagedResultDto&lt;ProductDto&gt;&gt; GetListAsync(PagedAndSortedResultRequestDto input)\r\n        {\r\n            return productService.GetListAsync(input);\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 获取所有商品  \r\n        /// &lt;/summary&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        [HttpGet(\"GetProducts\")]\r\n        public Task&lt;List&lt;ProductDto&gt;&gt; GetProductsAsync()\r\n        {\r\n            Console.WriteLine(\"执行查询...GetProductsAsync\");\r\n            return productService.GetProductsAsync();\r\n        }\r\n        /// &lt;summary&gt;\r\n        /// 编辑商品数据\r\n        /// &lt;/summary&gt;\r\n        /// &lt;param name=\"id\"&gt;&lt;/param&gt;\r\n        /// &lt;param name=\"input\"&gt;&lt;/param&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        [HttpPut]\r\n        public Task&lt;ProductDto&gt; UpdateAsync(Guid id, ProductDto input)\r\n        {\r\n            return productService.UpdateAsync(id, input);\r\n        }\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.3.7 在根目录下创建skyapm.json</h4>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"json\">{\r\n  \"SkyWalking\": {\r\n    \"ServiceName\": \"GateWay\",\r\n    \"Namespace\": \"\",\r\n    \"HeaderVersions\": [\r\n      \"sw8\"\r\n    ],\r\n    \"Sampling\": {\r\n      \"SamplePer3Secs\": -1,\r\n      \"Percentage\": -1.0\r\n    },\r\n    \"Logging\": {\r\n      \"Level\": \"Information\",\r\n      \"FilePath\": \"logs\\\\skyapm-{Date}.log\"\r\n    },\r\n    \"Transport\": {\r\n      \"Interval\": 3000,\r\n      \"ProtocolVersion\": \"v8\",\r\n      \"QueueSize\": 30000,\r\n      \"BatchSize\": 3000,\r\n      \"gRPC\": {\r\n        \"Servers\": \"localhost:11800\",\r\n        \"Timeout\": 10000,\r\n        \"ConnectTimeout\": 10000,\r\n        \"ReportTimeout\": 600000,\r\n        \"Authentication\": \"\"\r\n      }\r\n    }\r\n  }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.3.8 启动网关项目，通过网关调用商品微服务</h4>\r\n                    <div class=\"command\">\r\n                        D:\\Workspace\\DotNet\\netCoreDemos\\dev\\36-Skywalking\\SkyWalking.GateWay>dotnet run\r\n                    </div>\r\n                    <div class=\"image-placeholder\">\r\n                        [网关启动界面]\r\n                    </div>\r\n                </article>\r\n                \r\n                <article id=\"section4-4\">\r\n                    <h3>4.4 创建网站聚合服务</h3>\r\n                    <p>通过网站聚合服务-调用网关项目-网关调用商品微服务实现整个调用链。</p>\r\n                    \r\n                    <h4>4.4.1 使用命令行创建站点</h4>\r\n                    <div class=\"command\">\r\n                        D:\\Workspace\\DotNet\\netCoreDemos\\dev\\36-Skywalking>abp new SkyWalking.WebApiTest -t app-nolayers --dbms mysql -u none -csf -v8.1.4 --framework net8.0\r\n                    </div>\r\n                    <p>简化webapi-参考AbpVnext项目改造</p>\r\n                    \r\n                    <h4>4.4.2 修改csproj</h4>\r\n                    <p>默认保留以下的nuget包，其余删除</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"xml\">&lt;ItemGroup&gt;\r\n  &lt;PackageReference Include=\"SkyAPM.Agent.AspNetCore\" Version=\"2.2.0\" /&gt;\r\n&lt;/ItemGroup&gt;\r\n&lt;ItemGroup&gt;\r\n  &lt;PackageReference Include=\"Serilog.AspNetCore\" Version=\"8.0.0\" /&gt;\r\n  &lt;PackageReference Include=\"Serilog.Sinks.Async\" Version=\"1.5.0\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AspNetCore.Mvc\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.Autofac\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AutoMapper\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.Swashbuckle\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.Http.Client\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.Caching.StackExchangeRedis\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AspNetCore.Authentication.JwtBearer\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.AspNetCore.Serilog\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Volo.Abp.EntityFrameworkCore.MySQL\" Version=\"8.1.4\" /&gt;\r\n  &lt;PackageReference Include=\"Microsoft.Extensions.FileProviders.Embedded\" Version=\"8.0.0\" /&gt;\r\n  &lt;PackageReference Include=\"Microsoft.EntityFrameworkCore.Tools\" Version=\"8.0.0\"&gt;\r\n    &lt;IncludeAssets&gt;runtime; build; native; contentfiles; analyzers&lt;/IncludeAssets&gt;\r\n    &lt;PrivateAssets&gt;compile; build; native; contentfiles; analyzers; buildtransitive&lt;/PrivateAssets&gt;\r\n  &lt;/PackageReference&gt;\r\n&lt;/ItemGroup&gt;</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.4.3 改造WebApiTestModule.cs文件</h4>\r\n                    <p>1）删除报错using</p>\r\n                    <p>2）DependsOn保留如下：</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">[DependsOn(\r\n    // ABP Framework packages\r\n    typeof(AbpAspNetCoreMvcModule),\r\n    typeof(AbpAutofacModule),\r\n    typeof(AbpAutoMapperModule),\r\n    typeof(AbpEntityFrameworkCoreMySQLModule),\r\n    typeof(AbpSwashbuckleModule),\r\n    typeof(AbpAspNetCoreSerilogModule),\r\n    //远程调用模块\r\n    typeof(AbpHttpClientModule),\r\n    typeof(AbpCachingStackExchangeRedisModule)\r\n)]</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>3）ConfigureServices保留如下，删除所有报错的代码</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">/// &lt;summary&gt;\r\n/// 服务配置\r\n/// &lt;/summary&gt;\r\n/// &lt;param name=\"context\"&gt;&lt;/param&gt;\r\npublic override void ConfigureServices(ServiceConfigurationContext context)\r\n{\r\n     var hostingEnvironment = context.Services.GetHostingEnvironment();\r\n     var configuration = context.Services.GetConfiguration();\r\n     ConfigureMultiTenancy();\r\n     ConfigureUrls(configuration);\r\n     ConfigureAutoMapper(context);\r\n     ConfigureSwagger(context.Services, configuration);\r\n     ConfigureAutoApiControllers();\r\n     ConfigureVirtualFiles(hostingEnvironment);\r\n     ConfigureLocalization();\r\n     ConfigureCors(context, configuration);\r\n     ConfigureDataProtection(context);\r\n     ConfigureEfCore(context);\r\n     // 1、加载IProductService\r\n     context.Services.AddHttpClientProxies(\r\n         typeof(WebApiTestModule).Assembly, // 1、使用程序集加载\r\n         \"ProductGateway\" // 2、对应appsettings.json的RemoteServices配置\r\n     );\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <p>修改OnApplicationInitialization</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">public override void OnApplicationInitialization(ApplicationInitializationContext context)\r\n{\r\n     var app = context.GetApplicationBuilder();\r\n     var env = context.GetEnvironment();\r\n     if (env.IsDevelopment())\r\n     {\r\n         app.UseDeveloperExceptionPage();\r\n     }\r\n     app.UseAbpRequestLocalization();\r\n     app.UseCorrelationId();\r\n     app.UseStaticFiles();\r\n     app.UseRouting();\r\n     app.UseCors();\r\n     app.UseAuthentication();\r\n     app.UseUnitOfWork();\r\n     //app.UseDynamicClaims();\r\n     app.UseAuthorization();\r\n     app.UseSwagger();\r\n     app.UseAbpSwaggerUI(options =>\r\n     {\r\n         options.SwaggerEndpoint(\"/swagger/v1/swagger.json\", \"WebApiTest API\");\r\n         var configuration = context.GetConfiguration();\r\n         options.OAuthClientId(configuration[\"AuthServer:SwaggerClientId\"]);\r\n         options.OAuthScopes(\"WebApiTest\");\r\n     });\r\n     app.UseAuditing();\r\n     app.UseAbpSerilogEnrichers();\r\n     app.UseConfiguredEndpoints();\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.4.4 修改Properties目录下launchSettings.json增加配置：</h4>\r\n                    <p>在环境变量中添加： \"ASPNETCORE_HOSTINGSTARTUPASSEMBLIES\": \"SkyAPM.Agent.AspNetCore\" 这个是固定写法。</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"json\">{\r\n  \"iisSettings\": {\r\n    \"windowsAuthentication\": false,\r\n    \"anonymousAuthentication\": true,\r\n    \"iisExpress\": {\r\n      \"applicationUrl\": \"https://localhost:44376\",\r\n      \"sslPort\": 44376\r\n    }\r\n  },\r\n  \"profiles\": {\r\n    \"SkyWalking.WebApiTest\": {\r\n      \"commandName\": \"Project\",\r\n      \"launchBrowser\": true,\r\n      \"applicationUrl\": \"http://localhost:44375\",\r\n      \"environmentVariables\": {\r\n        \"ASPNETCORE_ENVIRONMENT\": \"Development\",\r\n        \"ASPNETCORE_HOSTINGSTARTUPASSEMBLIES\": \"SkyAPM.Agent.AspNetCore\" //增加链路监控SkyAPM配置\r\n      }\r\n    }\r\n  }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.4.5 在项目添加skyapm.json配置文件：</h4>\r\n                    <p>在skyapm.json配置中添加如下内容：</p>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"json\">{\r\n  \"SkyWalking\": {\r\n    \"ServiceName\": \"WebApiTest\",\r\n    \"Namespace\": \"\",\r\n    \"HeaderVersions\": [\r\n      \"sw8\"\r\n    ],\r\n    \"Sampling\": {\r\n      \"SamplePer3Secs\": -1,\r\n      \"Percentage\": -1.0\r\n    },\r\n    \"Logging\": {\r\n      \"Level\": \"Information\",\r\n      \"FilePath\": \"logs\\\\skyapm-{Date}.log\"\r\n    },\r\n    \"Transport\": {\r\n      \"Interval\": 3000,\r\n      \"ProtocolVersion\": \"v8\",\r\n      \"QueueSize\": 30000,\r\n      \"BatchSize\": 3000,\r\n      \"gRPC\": {\r\n        \"Servers\": \"localhost:11800\",\r\n        \"Timeout\": 10000,\r\n        \"ConnectTimeout\": 10000,\r\n        \"ReportTimeout\": 600000,\r\n        \"Authentication\": \"\"\r\n      }\r\n    }\r\n  }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.4.6 创建一个控制器（UserController）和接口（ GetUserInfoAsync），用于测试Skywalking</h4>\r\n                    <div class=\"code-block\">\r\n                        <pre><code class=\"csharp\">using Microsoft.AspNetCore.Mvc;\r\nusing SkyWalking.ProductService.Services;\r\nusing SkyWalking.ProductService.Services.Dtos;\r\nusing Volo.Abp.AspNetCore.Mvc;\r\nnamespace SkyWalking.WebApiTest.Controllers\r\n{\r\n    /// &lt;summary&gt;\r\n    /// 商品控制器\r\n    /// &lt;/summary&gt;\r\n    [ApiController]\r\n    [Route(\"api/pcwebsite\")]\r\n    public class IndexController : AbpController\r\n    {\r\n        /// &lt;summary&gt;\r\n        /// 此处IProductService服务中的命名空间需要保持与微服务Shop.ProductService一致\r\n        /// &lt;/summary&gt;\r\n        public IProductService productService { get; set; }\r\n        \r\n        /// &lt;summary&gt;\r\n        /// 查询商品\r\n        /// &lt;/summary&gt;\r\n        /// &lt;returns&gt;&lt;/returns&gt;\r\n        [HttpGet(\"GetProducts\")]\r\n        public async Task&lt;List&lt;ProductDto&gt;&gt; GetProduct()\r\n        {\r\n            //1、查询商品\r\n            Console.WriteLine(\"查询商品\");\r\n            var list = await productService.GetProductsAsync();\r\n            return list;\r\n        }\r\n    }\r\n}</code></pre>\r\n                    </div>\r\n                    \r\n                    <h4>4.4.7 启动SkyWalking.WebApiTest</h4>\r\n                    <div class=\"command\">\r\n                        D:\\Workspace\\SkyWalking.WebApiTest>dotnet run\r\n                        [21:04:47 INF] Now listening on: http://localhost:44315\r\n                        [21:04:47 INF] Application started. Press Ctrl+C to shut down.\r\n                        [21:04:47 INF] Hosting environment: Development\r\n                    </div>\r\n                    <p>访问WebApiTest：<a href=\"http://localhost:44315\">http://localhost:44315</a></p>\r\n                </article>\r\n            </section>\r\n            \r\n            <section id=\"section5\">\r\n                <h2>5. 启动Skywalking客户端</h2>\r\n                <p>进入skywalking安装目录下的bin目录，执行webappService.bat</p>\r\n                <div class=\"command\">\r\n                    PS D:\\itools\\apache-skywalking-apm-bin-es7\\bin> .\\webappService.bat\r\n                </div>\r\n                \r\n                <p>设置启动端口，修改webapp.yml,默认端口8080</p>\r\n                \r\n                <p>浏览器访问http://localhost:8080,查看客户端监控页面</p>\r\n                <div class=\"image-placeholder\">\r\n                    [Skywalking监控界面]\r\n                </div>\r\n                \r\n                <p>分析Skywalking拓扑图，在拓扑图中，点击一个服务，查看所有的接口</p', '1', 1, '服务器监控', 1, 1, 16, 0, 90, 3, '1900-01-01 00:00:00', 1, 1, '2025-10-11 06:43:08', '归海一刀', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (5, 'Vue 3.0 性能优化实践', '发的那看来是付了定金失蜡法较大山卡拉激发溜达鸡索拉卡飞机的卡拉生发剂算啦', '2222222222', '1', 1, NULL, 1, 1, 90, 2, 40, 3, NULL, 1, 4, '2025-10-11 06:43:08', '海棠', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (6, 'Spring Boot 微服务架构', '放假了电视剧丽枫酒店山卡拉发撒', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', '1', 1, NULL, 1, 1, 1, 5, 2, 1, NULL, 1, 2, '2025-10-12 07:39:09', '不败金身', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (7, 'React Native 移动应用开发', '1', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', '1', 1, NULL, 1, 1, 11, 4, 50, 1, NULL, 1, 3, '2025-10-12 07:39:09', '计菩提', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (8, 'MySQL 数据库优化技巧', '1', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', '1', 1, NULL, 1, 1, 2, 31, 3, 1, NULL, 1, 2, '2025-10-12 07:39:09', 'summary', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (9, 'Python 数据分析实践', '1', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', '1', 1, NULL, 1, 1, 11, 2, 50, 1, NULL, 1, 3, '2025-10-12 07:39:09', '天使四骑士', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (10, 'Docker 容器化部署', '1', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', '1', 1, NULL, 1, 1, 3, 1, 3, 1, NULL, 1, 4, '2025-10-12 07:39:09', '乔治沃克', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (11, 'Docker 网络配置', '1', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', '1', 1, NULL, 1, 1, 11, 5, 50, 1, NULL, 1, 4, '2025-10-12 07:39:09', '尼科沃克', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (12, 'Docker Swarm集群部署', '1', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', '1', 1, NULL, 1, 1, 4, 6, 60, 1, NULL, 1, 3, '2025-10-12 07:39:09', '拉蒙', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (13, 'Docker Compose 多容器应用', 'Docker Compose 是一个用于定义和运行多容器 Docker 应用的工具...', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', '1', 1, NULL, 1, 1, 115, 80, 2, 1, NULL, 1, 4, '2025-10-12 07:39:09', '火箭', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (14, 'Docker 镜像优化', 'Docker 镜像优化是指通过减少镜像大小、使用多阶段构建等技术来优化 Docker 镜像...', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', '1', 1, NULL, 1, 1, 6, 45, 1, 1, NULL, 1, 4, '2025-10-12 07:39:09', '朱可夫', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (15, '微服务架构', 'Docker 容器化部署是指将应用程序及其依赖项打包到一个容器中，然后在任何支持 Docker 的环境中运行..', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', '1', 1, NULL, 1, 1, 3, 22, 33, 1, NULL, 1, 1002, '2025-10-12 07:39:09', '纳扎尔巴耶夫', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (16, '1111111111111', '22', '<!DOCTYPE html>\r\n<html lang=\"zh-CN\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>分布式中间件-Kafka</title>\r\n    <style>\r\n        :root {\r\n            --primary-color: #2c3e50;\r\n            --secondary-color: #3498db;\r\n            --accent-color: #e74c3c;\r\n            --light-color: #ecf0f1;\r\n            --dark-color: #2c3e50;\r\n            --text-color: #333;\r\n            --border-color: #ddd;\r\n            --code-bg: #f8f9fa;\r\n            --success-color: #2ecc71;\r\n            --warning-color: #f39c12;\r\n        }\r\n        \r\n        * {\r\n            margin: 0;\r\n            padding: 0;\r\n            box-sizing: border-box;\r\n        }\r\n        \r\n        body {\r\n            font-family: \'Segoe UI\', Tahoma, Geneva, Verdana, sans-serif;\r\n            line-height: 1.6;\r\n            color: var(--text-color);\r\n            background-color: #f5f7fa;\r\n            padding: 0;\r\n            margin: 0;\r\n        }\r\n        \r\n        .container {\r\n            max-width: 1200px;\r\n            margin: 0 auto;\r\n            padding: 0 20px;\r\n        }\r\n        \r\n        header {\r\n            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\r\n            color: white;\r\n            padding: 2rem 0;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        .header-content {\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n        \r\n        .blog-title {\r\n            font-size: 2.5rem;\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        .blog-subtitle {\r\n            font-size: 1.2rem;\r\n            opacity: 0.9;\r\n        }\r\n        \r\n        .meta-info {\r\n            display: flex;\r\n            gap: 20px;\r\n            font-size: 0.9rem;\r\n            margin-top: 1rem;\r\n            color: rgba(255, 255, 255, 0.8);\r\n        }\r\n        \r\n        .content-wrapper {\r\n            display: flex;\r\n            gap: 30px;\r\n            margin: 30px 0;\r\n        }\r\n        \r\n        main {\r\n            flex: 3;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 30px;\r\n        }\r\n        \r\n        aside {\r\n            flex: 1;\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            height: fit-content;\r\n        }\r\n        \r\n        h1, h2, h3, h4 {\r\n            color: var(--primary-color);\r\n            margin-top: 1.5rem;\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        h1 {\r\n            font-size: 2rem;\r\n            border-bottom: 2px solid var(--secondary-color);\r\n            padding-bottom: 0.5rem;\r\n        }\r\n        \r\n        h2 {\r\n            font-size: 1.6rem;\r\n            padding-left: 10px;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        h3 {\r\n            font-size: 1.3rem;\r\n        }\r\n        \r\n        h4 {\r\n            font-size: 1.1rem;\r\n        }\r\n        \r\n        p {\r\n            margin-bottom: 1rem;\r\n        }\r\n        \r\n        ul, ol {\r\n            margin-left: 1.5rem;\r\n            margin-bottom: 1.5rem;\r\n        }\r\n        \r\n        li {\r\n            margin-bottom: 0.5rem;\r\n        }\r\n        \r\n        code {\r\n            background-color: var(--code-bg);\r\n            padding: 2px 6px;\r\n            border-radius: 4px;\r\n            font-family: \'Courier New\', Courier, monospace;\r\n            font-size: 0.9rem;\r\n        }\r\n        \r\n        pre {\r\n            background-color: var(--code-bg);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            overflow-x: auto;\r\n            margin: 1.5rem 0;\r\n            border-left: 4px solid var(--secondary-color);\r\n        }\r\n        \r\n        pre code {\r\n            background: none;\r\n            padding: 0;\r\n        }\r\n        \r\n        table {\r\n            width: 100%;\r\n            border-collapse: collapse;\r\n            margin: 1.5rem 0;\r\n            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\r\n        }\r\n        \r\n        th, td {\r\n            padding: 12px 15px;\r\n            text-align: left;\r\n            border-bottom: 1px solid var(--border-color);\r\n        }\r\n        \r\n        th {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            font-weight: 600;\r\n        }\r\n        \r\n        tr:nth-child(even) {\r\n            background-color: #f8f9fa;\r\n        }\r\n        \r\n        .note {\r\n            background-color: #e8f4fd;\r\n            border-left: 4px solid var(--secondary-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .warning {\r\n            background-color: #fef9e7;\r\n            border-left: 4px solid var(--warning-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .success {\r\n            background-color: #eafaf1;\r\n            border-left: 4px solid var(--success-color);\r\n            padding: 15px;\r\n            margin: 1.5rem 0;\r\n            border-radius: 0 4px 4px 0;\r\n        }\r\n        \r\n        .toc {\r\n            background-color: #f8f9fa;\r\n            padding: 20px;\r\n            border-radius: 6px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .toc h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        .toc ul {\r\n            list-style-type: none;\r\n            margin-left: 0;\r\n        }\r\n        \r\n        .toc li {\r\n            margin-bottom: 8px;\r\n        }\r\n        \r\n        .toc a {\r\n            text-decoration: none;\r\n            color: var(--text-color);\r\n            transition: color 0.3s;\r\n        }\r\n        \r\n        .toc a:hover {\r\n            color: var(--secondary-color);\r\n        }\r\n        \r\n        .card {\r\n            background: white;\r\n            border-radius: 8px;\r\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\r\n            padding: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n        \r\n        .card h3 {\r\n            margin-top: 0;\r\n            color: var(--primary-color);\r\n        }\r\n        \r\n        footer {\r\n            background-color: var(--primary-color);\r\n            color: white;\r\n            text-align: center;\r\n            padding: 20px 0;\r\n            margin-top: 40px;\r\n        }\r\n        \r\n        .code-block {\r\n            position: relative;\r\n        }\r\n        \r\n        .code-header {\r\n            background-color: var(--dark-color);\r\n            color: white;\r\n            padding: 8px 15px;\r\n            border-radius: 6px 6px 0 0;\r\n            font-size: 0.9rem;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n        \r\n        .copy-btn {\r\n            background: none;\r\n            border: none;\r\n            color: white;\r\n            cursor: pointer;\r\n            font-size: 0.8rem;\r\n        }\r\n        \r\n        @media (max-width: 768px) {\r\n            .content-wrapper {\r\n                flex-direction: column;\r\n            }\r\n            \r\n            .header-content {\r\n                flex-direction: column;\r\n                text-align: center;\r\n            }\r\n            \r\n            .meta-info {\r\n                justify-content: center;\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <header>\r\n        <div class=\"container\">\r\n            <div class=\"header-content\">\r\n                <div>\r\n                    <h1 class=\"blog-title\">分布式中间件-Kafka</h1>\r\n                    <p class=\"blog-subtitle\">高吞吐量分布式流处理平台详解</p>\r\n                </div>\r\n            </div>\r\n            <div class=\"meta-info\">\r\n                <span>作者：技术团队</span>\r\n                <span>发布时间：2024-01-15</span>\r\n                <span>点赞量：<span id=\"likeCount\">128</span></span>\r\n            </div>\r\n        </div>\r\n    </header>\r\n\r\n    <div class=\"container\">\r\n        <div class=\"content-wrapper\">\r\n            <main>\r\n                <article>\r\n                    <h1>分布式中间件-Kafka</h1>\r\n                    \r\n                    <section>\r\n                        <h2>1、Kafka相关概念</h2>\r\n                        \r\n                        <h3>1.1、Kafka是什么？</h3>\r\n                        <p>Kafka是一个分布式事件流平台，最初由LinkedIn开发，后成为Apache顶级开源项目，其核心设计基于发布/订阅模式，支持高吞吐量的实时数据传输和持久化存储，广泛应用与大数据处理、日志收集、实时流处理等领域。</p>\r\n                        <p>Kafka的核心架构包括以下组件：</p>\r\n                        <ul>\r\n                            <li><strong>生产者(Producer)</strong>：向kafka主题(Topic)发布消息的客户端。</li>\r\n                            <li><strong>消费者(Consumer)</strong>：从主题拉取消息进行处理的客户端。</li>\r\n                            <li><strong>代理(Broker)</strong>：Kafka服务器节点，负责存储和管理消息。</li>\r\n                            <li><strong>主题与分区(Topic&Partition)</strong>：主题是消息的逻辑分类，每个主题可以划分为多个分区以实现并行处理和高扩张性。</li>\r\n                            <li><strong>副本(Replica)</strong>：每个分区有多个副本，确保数据高可用性。</li>\r\n                        </ul>\r\n                        \r\n                        <h3>1.2、Kafka与传统消息队列的区别及优势</h3>\r\n                        \r\n                        <h4>1.2.1、设计理念与适用场景：</h4>\r\n                        <p>传统消息队列（如RabbitMQ、ActiveMQ）面向点对点或简单发布/订阅模式，适用于任务调度、异步处理等场景、支持事务、消息优先级等特性。</p>\r\n                        <p>Kafka设计为分布式流处理平台、专注于高吞吐量、低延迟的实时数据流，适合日志收集、事件驱动架构、实时分析等大数据场景。</p>\r\n                        \r\n                        <h4>1.2.2、性能与扩展</h4>\r\n                        <ul>\r\n                            <li><strong>高吞吐、低延迟</strong>：Kafka利用顺序磁盘写入、零拷贝技术（直接发送文件缓存至网络）和批量处理，实现每秒数十万条消息的处理能力，延迟可低至毫秒级。</li>\r\n                            <li><strong>水平扩展</strong>：Kafka通过分区机制，数据可分散到多个代理（Broker），支持动态添加节点，扩展性远超传统队列。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.3、存储与消费模型：</h4>\r\n                        <ul>\r\n                            <li><strong>持久化与可靠性</strong>：Kafka将消息持久化到磁盘，支持多副本机制，即使节点故障也能保证数据不丢失，传统队列虽然提供持久化选型，但存储策略灵活性较低。</li>\r\n                            <li><strong>消费者自主控制</strong>：消费者通过偏移量（Offset）主动拉取消息（Pull模式），支持多消费者组并行消费，而传统队列通常采用推送(Pusl)模式，可能因为消费者处理能力不足而导致消息堆积。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.2.4、灵活性与生态集成：</h4>\r\n                        <p>Kafka支持多种编程语言和协议，并与Hadoop、Spark、FLink等大数据工具深度集成，适合构建复杂的数据管道。</p>\r\n                        \r\n                        <h3>1.3、Kafka的局限性</h3>\r\n                        \r\n                        <h4>1.3.1、实时性限制：</h4>\r\n                        <ul>\r\n                            <li><strong>消息堆积延迟</strong>：当生产速度远超消费速度时，消息堆积可能导致处理延迟，尤其在高峰时段或故障恢复期间。</li>\r\n                            <li><strong>分区再平衡</strong>：消费者组增减分区变动时，再平衡操作可能暂停消费数秒至数分钟，影响实时性。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.2、数据一致性</h4>\r\n                        <ul>\r\n                            <li><strong>语义限制</strong>：默认仅支持【至少一次】(At-Last-Once)和【最多一次】(At-Most-Once)传递，需要精确配置才能实现【恰好一次】(Exactly-once）语义。</li>\r\n                            <li><strong>副本同步延迟</strong>：Leader切换时，若Follower未完全同步，可能导致短暂数据不一致。</li>\r\n                        </ul>\r\n                        \r\n                        <h4>1.3.3、性能瓶颈：</h4>\r\n                        <p><strong>网络与磁盘I/O</strong>:跨数据中心传输或高吞吐场景下，网络带宽和磁盘读写可能会成为瓶颈。</p>\r\n                        \r\n                        <h4>1.3.4、管理与维护复杂度：</h4>\r\n                        <p>集群配置涉及分区、副本因子、消费者组调优等，版本升级可能引发兼容性问题，需谨慎操作。</p>\r\n                        \r\n                        <h3>1.4、Kafka与传统消息队列差异对比：</h3>\r\n                        \r\n                        <table>\r\n                            <thead>\r\n                                <tr>\r\n                                    <th>对比维度</th>\r\n                                    <th>RabbitMQ</th>\r\n                                    <th>Kafka</th>\r\n                                    <th>RocketMQ</th>\r\n                                </tr>\r\n                            </thead>\r\n                            <tbody>\r\n                                <tr>\r\n                                    <td>设计定位</td>\r\n                                    <td>通用消息代理，支持复杂路由和多种消息模式（如任务队列、RPC）</td>\r\n                                    <td>分布式流处理平台，专注高吞吐、持久化日志场景（如日志采集、实时分析）</td>\r\n                                    <td>分布式消息中间件，强调高吞吐、低延迟和事务支持（如金融交易、订单系统）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>架构模型</td>\r\n                                    <td>基于 AMQP 协议，采用 Exchange-Queue 路由机制</td>\r\n                                    <td>发布/订阅模式，基于 Topic 和 Partition 的分布式日志存储</td>\r\n                                    <td>类似 Kafka，但优化了事务消息和顺序消费，支持 Topic 和 Queue 的分区设计</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>吞吐量</td>\r\n                                    <td>单机万级 QPS，适合中小规模场景</td>\r\n                                    <td>单机百万级 QPS，支持海量数据流</td>\r\n                                    <td>单机约 7 万~12 万 TPS，支持高并发场景</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息延迟</td>\r\n                                    <td>微秒级延迟，适合实时任务调度</td>\r\n                                    <td>毫秒级延迟（批量处理优化吞吐，堆积时可能增加延迟）</td>\r\n                                    <td>毫秒级延迟，针对在线业务优化</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息顺序性</td>\r\n                                    <td>单队列内有序，多消费者需拆分队列</td>\r\n                                    <td>单 Partition 内有序，跨 Partition 无序</td>\r\n                                    <td>单 Queue 内有序，支持全局顺序（需牺牲扩展性）</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>消息可靠性</td>\r\n                                    <td>通过持久化、手动 ACK、镜像队列保证，但高负载下可能丢消息</td>\r\n                                    <td>多副本机制 + ACK=all 配置，数据可靠性高</td>\r\n                                    <td>同步刷盘 + Dledger 主从架构，金融级可靠性</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>高级功能</td>\r\n                                    <td>支持优先级队列、延迟队列、死信队列、事务消息</td>\r\n                                    <td>功能较简单，支持消息回溯、幂等性，无延迟队列</td>\r\n                                    <td>支持事务消息、延迟消息、消息过滤，兼容 Kafka 协议</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>扩展性</td>\r\n                                    <td>集群扩展复杂，镜像队列性能有限</td>\r\n                                    <td>水平扩展性强，支持动态分区扩容</td>\r\n                                    <td>分布式架构，支持弹性扩展，适合大规模集群</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>协议支持</td>\r\n                                    <td>AMQP、MQTT、STOMP 等</td>\r\n                                    <td>自定义协议</td>\r\n                                    <td>自定义协议，兼容部分 Kafka 功能</td>\r\n                                </tr>\r\n                                <tr>\r\n                                    <td>生态集成</td>\r\n                                    <td>多语言支持广泛，适合轻量级应用</td>\r\n                                    <td>与大数据工具（如 Spark、Flink）深度集成</td>\r\n                                    <td>与阿里生态（如双十一系统）紧密集成</td>\r\n                                </tr>\r\n                            </tbody>\r\n                        </table>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>2、安装运行Kafka</h2>\r\n                        \r\n                        <h3>2.1、下载kafka安装包：</h3>\r\n                        <p>官网下载地址：<a href=\"https://kafka.apache.org/downloads\" target=\"_blank\">https://kafka.apache.org/downloads</a></p>\r\n                        \r\n                        <h3>2.2、安装环境</h3>\r\n                        <ol>\r\n                            <li>\r\n                                <p><strong>安装Java运行环境</strong></p>\r\n                                <p>官网下载地址：<a href=\"https://www.oracle.com/cn/java/technologies/downloads/#java17-windows\" target=\"_blank\">https://www.oracle.com/cn/java/technologies/downloads/#java17-windows</a></p>\r\n                            </li>\r\n                            <li>\r\n                                <p><strong>安装kafkatool_64bit.exe工具</strong></p>\r\n                                <p>下载地址：<a href=\"https://www.kafkatool.com/download.html\" target=\"_blank\">https://www.kafkatool.com/download.html</a></p>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.3、Zookeeper与Kafka的关系：</h3>\r\n                        <ol>\r\n                            <li>Zookeeper是一个分布式协调服务，用于维护配置信息，命名，提供分布式同步以及群组服务。</li>\r\n                            <li>\r\n                                <p>Zookeeper是Kafka的中\"中枢神经系统\",其核心功能包括如下：</p>\r\n                                <ul>\r\n                                    <li><strong>元数据管理</strong>：Zookeeper存储Kafka集群的全局元数据，包括：\r\n                                        <ul>\r\n                                            <li>Broker信息：包含节点ID、IP、状态信息。</li>\r\n                                            <li>Topic和Partition：分区数量、副本分布、Leader副本位置。</li>\r\n                                            <li>Consumer Group：消费者偏移量（Offset），确保重启后继续消费。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>集群协调与选举</strong>：\r\n                                        <ul>\r\n                                            <li>Controller选举：Kafka集群通过Zookeeper选举唯一的Controller节点，负责分区Leader分配、Broker故障处理等关键任务。</li>\r\n                                            <li>Leader选举：当某个Partition和Leader副本宕机时，Zookeeper从ISR中快速选出新的Leader，避免服务中断。</li>\r\n                                        </ul>\r\n                                    </li>\r\n                                    <li><strong>状态监控与通知</strong>\r\n                                        <p>通过Watch机制实时监听Broker或Topic的状态变化，并通知Controller节点触发故障转移。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                            <li>\r\n                                <p>Kafka如何与Zookeeper交互？</p>\r\n                                <ul>\r\n                                    <li><strong>Broker启动时</strong>：\r\n                                        <p>向Zookeeper注册自身信息（IP、端口等），创建临时节点，若临时节点消失（如Broker宕机），Zookeeper通知Controller启动故障恢复。</p>\r\n                                    </li>\r\n                                    <li><strong>Producer/Consumer连接时</strong>：\r\n                                        <p>从Zookeeper获取Topic的Partition-Leader映射，直接与Leader Broker通信；Consumer提交Offset到Kafka内部Topic。</p>\r\n                                    </li>\r\n                                    <li><strong>分区扩容或重新分配</strong>：\r\n                                        <p>新增Partition时，Controller通过Zookeeper协调副本同步，并更新元数据。</p>\r\n                                    </li>\r\n                                </ul>\r\n                            </li>\r\n                        </ol>\r\n                        \r\n                        <h3>2.4 运行Kafka</h3>\r\n                        \r\n                        <h4>2.4.1、运行kafka之前要先运行zookeeper，这个是kafka的注册中心</h4>\r\n                        \r\n                        <h4>2.4.2、修改zookeeper配置</h4>\r\n                        <p>找到在config目录下的zookeeper.properties配置文件</p>\r\n                        \r\n                        <div class=\"code-block\">\r\n                            <div class=\"code-header\">\r\n                                <span>zookeeper.properties</span>\r\n                                <button class=\"copy-btn\">复制代码</button>\r\n                            </div>\r\n                            <pre><code># 编辑zookeeper.properties，修改数据存放目录\r\n# Licensed to the Apache Software Foundation (ASF) under one or more\r\n# contributor license agreements.  See the NOTICE file distributed with\r\n# this work for additional information regarding copyright ownership.\r\n# The ASF licenses this file to You under the Apache License, Version 2.0\r\n# (the \"License\"); you may not use this file except in compliance with\r\n# the License.  You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# the directory where the snapshot is stored.\r\ndataDir=D:\\\\devtools\\\\kafka\\\\kafka_data\r\n# the port at which the clients will connect\r\nclientPort=2181\r\n# disable the per-ip limit on the number of connections since this is a non-production config\r\nmaxClientCnxns=100\r\n# Disable the adminserver by default to avoid port conflicts.\r\n# Set the port to something non-conflicting if choosing to enable this\r\nadmin.enableServer=false\r\n# admin.serverPort=8080\r\ntickTime=2000\r\nsyncLimit=5\r\ninitLimit=10\r\n# 增加快照保留数量\r\nautopurge.snapRetainCount=10\r\nautopurge.purgeInterval=24</code></pre>\r\n                        </div>\r\n                        \r\n                        <h4>2.4.3、进入kafka的bin目录，进入windows目录，执行bat文件</h4>\r\n                        <p>运行zookeeper，zookeeper是kafka的注册中心，且依赖java环境</p>\r\n                        <pre><code>D:\\kafka\\kafka_2.12-2.8.1\\bin\\windows>zookeeper-server-start.bat ../../config/zookeeper.properties\r\n[2025-05-28 19:48:11,201] INFO Reading configuration from: ../../config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></pre>\r\n                        \r\n                        <p>由于内容较长，此处仅展示部分内容...</p>\r\n                        \r\n                        <div class=\"note\">\r\n                            <p><strong>注意：</strong> 以上内容仅为示例展示，完整内容包含更多配置和代码示例。</p>\r\n                        </div>\r\n                    </section>\r\n                    \r\n                    <section>\r\n                        <h2>写在最后...</h2>\r\n                        <p>综上所述，掌握Kafka不仅在于API调用，更在于深入理解其分布式、高吞吐、持久化与水平扩展的核心设计理念。其真正价值在于为大型分布式系统和海量消息处理场景提供坚实支撑。因此，针对具体业务的消息模式、数据规模、容错与延迟要求，并结合底层硬件资源（如磁盘I/O、网络带宽、CPU）进行精细化的配置与优化，才是发挥Kafka极致效能的关键所在。</p>\r\n                    </section>\r\n                </article>\r\n            </main>\r\n            \r\n            <aside>\r\n                <div class=\"toc\">\r\n                    <h3>目录</h3>\r\n                    <ul>\r\n                        <li><a href=\"#section1\">1、Kafka相关概念</a>\r\n                            <ul>\r\n                                <li><a href=\"#section1-1\">1.1、Kafka是什么？</a></li>\r\n                                <li><a href=\"#section1-2\">1.2、Kafka与传统消息队列的区别及优势</a></li>\r\n                                <li><a href=\"#section1-3\">1.3、Kafka的局限性</a></li>\r\n                                <li><a href=\"#section1-4\">1.4、Kafka与传统消息队列差异对比</a></li>\r\n                            </ul>\r\n                        </li>\r\n                        <li><a href=\"#section2\">2、安装运行Kafka</a>\r\n                            <ul>\r\n                                <li><a href=\"#section2-1\">2.1、下载kafka安装包</a></li>\r\n                                <li><a href=\"#section2-2\">2.2、安装环境</a></li>\r\n                                <li><a href=\"#section2-3\">2.3、Zookeeper与Kafka的关系</a></li>\r\n                                <li><a href=\"#section2-4\">2.4、运行Kafka</a></li>\r\n                            </ul>\r\n                        </li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>相关资源</h3>\r\n                    <ul>\r\n                        <li><a href=\"https://kafka.apache.org/documentation/\" target=\"_blank\">Kafka官方文档</a></li>\r\n                        <li><a href=\"https://github.com/apache/kafka\" target=\"_blank\">Kafka GitHub仓库</a></li>\r\n                        <li><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Index\" target=\"_blank\">Kafka Wiki</a></li>\r\n                    </ul>\r\n                </div>\r\n                \r\n                <div class=\"card\">\r\n                    <h3>推荐阅读</h3>\r\n                    <ul>\r\n                        <li><a href=\"#\">Kafka性能优化指南</a></li>\r\n                        <li><a href=\"#\">Kafka在微服务架构中的应用</a></li>\r\n                        <li><a href=\"#\">Kafka与Spark Streaming集成</a></li>\r\n                    </ul>\r\n                </div>\r\n            </aside>\r\n        </div>\r\n    </div>\r\n    \r\n    <footer>\r\n        <div class=\"container\">\r\n            <p>&copy; 2024 技术博客 | 分布式中间件-Kafka</p>\r\n        </div>\r\n    </footer>\r\n\r\n    <script>\r\n        // 点赞功能\r\n        document.addEventListener(\'DOMContentLoaded\', function() {\r\n            const likeCount = document.getElementById(\'likeCount\');\r\n            let count = parseInt(likeCount.textContent);\r\n            \r\n            // 模拟点赞功能\r\n            likeCount.addEventListener(\'click\', function() {\r\n                count++;\r\n                likeCount.textContent = count;\r\n                \r\n                // 添加简单的动画效果\r\n                likeCount.style.transform = \'scale(1.2)\';\r\n                setTimeout(() => {\r\n                    likeCount.style.transform = \'scale(1)\';\r\n                }, 300);\r\n            });\r\n            \r\n            // 代码复制功能\r\n            const copyButtons = document.querySelectorAll(\'.copy-btn\');\r\n            copyButtons.forEach(button => {\r\n                button.addEventListener(\'click\', function() {\r\n                    const codeBlock = this.parentElement.nextElementSibling;\r\n                    const codeText = codeBlock.textContent;\r\n                    \r\n                    navigator.clipboard.writeText(codeText).then(() => {\r\n                        const originalText = this.textContent;\r\n                        this.textContent = \'已复制!\';\r\n                        \r\n                        setTimeout(() => {\r\n                            this.textContent = originalText;\r\n                        }, 2000);\r\n                    }).catch(err => {\r\n                        console.error(\'复制失败:\', err);\r\n                    });\r\n                });\r\n            });\r\n            \r\n            // 为标题添加ID以便目录跳转\r\n            const headings = document.querySelectorAll(\'h1, h2, h3, h4\');\r\n            headings.forEach((heading, index) => {\r\n                if (!heading.id) {\r\n                    heading.id = \'heading-\' + index;\r\n                }\r\n            });\r\n            \r\n            // 更新目录链接\r\n            const tocLinks = document.querySelectorAll(\'.toc a\');\r\n            tocLinks.forEach(link => {\r\n                const href = link.getAttribute(\'href\');\r\n                if (href.startsWith(\'#\')) {\r\n                    const targetId = href.substring(1);\r\n                    const targetElement = document.getElementById(targetId);\r\n                    if (!targetElement) {\r\n                        link.style.display = \'none\';\r\n                    }\r\n                }\r\n            });\r\n        });\r\n    </script>\r\n</body>\r\n</html>', NULL, 1, '22', 1, 0, 0, 0, 0, 0, '2025-10-21 00:00:00', 0, 0, '2025-10-21 16:43:39', '纳扎尔巴耶夫', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (17, 'DevOps-微服务项目Jenkins自动化方案', '本文详细介绍了在CentOS7环境下配置Jenkins自动化部署微服务项目的完整方案，包括环境配置、Jenkins安装、Gitee集成、Docker容器化部署以及智能热更新脚本的实现。', '<h1>DevOps-微服务项目Jenkins自动化方案</h1>\n\n<h2>1、安装centos7，配置网络环境</h2>\n\n<h3>1.1、centos7网卡配置</h3>\n<pre><code>[root@localhost ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens33\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=none\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nNAME=ens33\nUUID=f7841869-1aea-4a25-9091-3922e86ab643\nDEVICE=ens33\nONBOOT=yes\nIPADDR=192.168.72.131\nPREFIX=24\nGATEWAY=192.168.72.2\nDNS1=114.114.114.114\nIPV6_PRIVACY=no</code></pre>\n\n<pre><code># DNS配置：\n[root@localhost ~]# vi /etc/resolv.conf\nsearch masternode\nDNS1=8.8.8.8\nDNS2=114.114.114.114\n\n# 重新加载配置文件\n[root@localhost ~]# systemctl daemon-reload\n\n# 重启网络\n[root@localhost ~]# systemctl restart network</code></pre>\n\n<h3>1.2、更新插件</h3>\n<pre><code># 1 切换yum源\n[root@localhost ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo\n# 2 更新yum\n[root@localhost ~]# sudo yum update\n# 3 安装网络工具\n[root@localhost ~]# yum install net-tools\n# 4 安装wget\n[root@localhost ~]# yum install -y wget</code></pre>\n\n<h3>1.3、安装Java</h3>\n<p>1）Jenkins依赖java17版本</p>\n<pre><code>#卸载旧的java版本（可选）\n# 查找并卸载所有已安装的 OpenJDKsudo dnf remove -y java-*openjdk*\n# 清理残留配置sudo rm -rf /usr/lib/jvm/*\nsudo rm -f /etc/alternatives/java\n#安装java17\n[root@localhost ~]# sudo dnf install -y java-17-openjdk-devel\nsudo alternatives --config java</code></pre>\n\n<p>2）验证安装</p>\n<pre><code>[root@node01 jenkins]# java -version</code></pre>\n\n<h3>1.4、安装Jenkins</h3>\n<pre><code>[root@localhost jenkins]# sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo\n[root@localhost jenkins]# sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key\n[root@localhost jenkins]# sudo dnf install jenkins\n[root@localhost jenkins]# sudo systemctl start jenkins\n[root@localhost jenkins]# sudo systemctl enable jenkins\n\nsudo journalctl -u jenkins -b --no-pager\njava -version\nsudo cat /var/log/jenkins/jenkins.log\nsudo systemctl stop jenkins\nsudo -u jenkins java -jar /usr/share/java/jenkins.war\nsudo systemctl daemon-reload\nsudo systemctl start jenkins\nsudo systemctl status jenkins</code></pre>\n\n<h3>1.5 设置Jenkins开机启动</h3>\n<pre><code>[root@localhost ~]# sudo systemctl daemon-reload\n[root@localhost ~]# sudo systemctl enable jenkins</code></pre>\n\n<h3>1.6、查看Jenkins启动</h3>\n\n<h2>2、配置Jenkins</h2>\n\n<h3>2.1、访问Jenkins http://192.168.72.131:8080/</h3>\n\n<h3>2.2、安装git</h3>\n<pre><code>[root@node01 jenkins]# yum install git\n#查看安装版本\n[root@node01 jenkins]# git --version\ngit version 2.27.0</code></pre>\n\n<h3>2.3、在Jenkins上安装gitee插件</h3>\n<p>点击Manage Jenkins -> Manage Plugins -> Available</p>\n<p>快捷访问地址 http://192.168.72.131:8080/manage/pluginManager/available</p>\n\n<h3>2.4、配置gitee令牌</h3>\n<p>1）生成Gitee私人令牌</p>\n<p>登录Gitee->个人设置->安全设置->私人令牌</p>\n\n<p>保存私人令牌秘钥： 152077d351565e99f833951235f5f58f</p>\n<p>高级权限令牌：b94e54f50187c5c1ae2a6706dcbb7860</p>\n\n<p>2）在Jenkins管理控制台增加令牌凭证</p>\n<p>Manage Jenkins → Credentials → System → Global credentials → Add Credentials</p>\n<p>快捷访问地址：http://192.168.72.131:8080/manage/credentials/store/system/domain/_/newCredentials</p>\n\n<p>添加成功后列表 显示</p>\n\n<p>3）全局配置Gitee链接</p>\n<p>Manage Jenkins → Configure System → Gitee Configuration</p>\n<p>快捷访问地址：http://192.168.72.131:8080/manage/configure</p>\n<p>链接名称随意，证书令牌选择前面创建的令牌，点击测试链接即可</p>\n\n<h2>3、创建任务并集成Gitee仓库</h2>\n\n<h3>3.1、创建自由风格任务</h3>\n<p>首页→ New Item → 输入任务名 → 选择 Freestyle project</p>\n<p>快捷访问：http://192.168.72.131:8080/view/all/newJob</p>\n\n<h3>3.2、配置源码管理</h3>\n<p>快捷访问：http://192.168.72.131:8080/job/myproject-test/configure</p>\n<p>配置具体的开源项目，保存</p>\n\n<h3>3.3、手动执行构建：</h3>\n<p>在具体的构建项目左侧点击Build Now</p>\n\n<h3>3.4、查看项目存储路径</h3>\n<p>默认存放位置：/var/lib/jenkins/workspace/</p>\n<pre><code>[root@node01 jenkins]# cd /var/lib/jenkins/workspace/\n[root@node01 workspace]# ls\nmyproject-test</code></pre>\n\n<h2>4、配置自动触发</h2>\n\n<h3>4.1、创建Dockerfile</h3>\n<pre><code>FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base\nWORKDIR /app\nEXPOSE 80\nEXPOSE 443\nFROM mcr.microsoft.com/dotnet/sdk:8.0 AS build\nWORKDIR /src\nCOPY [\"FEShop.AdminWebSite.csproj\", \"./\"]\nRUN dotnet restore \"./FEShop.AdminWebSite.csproj\" \\\n    --verbosity detailed \\\n    --disable-parallel \\\n    --ignore-failed-sources \\\n    --no-cache\nCOPY . .\nARG BUILD_CONFIGURATION=Release\nRUN dotnet build \"FEShop.AdminWebSite.csproj\" -c $BUILD_CONFIGURATION -o /app/build\nFROM build AS publish\nARG BUILD_CONFIGURATION=Release\nRUN dotnet publish \"FEShop.AdminWebSite.csproj\" \\\n    -c $BUILD_CONFIGURATION \\\n    -o /app/publish \\\n    --no-restore  \nFROM base AS final\nWORKDIR /app\nCOPY --from=publish --chown=appuser:appuser /app/publish .\nENV TZ=Asia/Shanghai\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone\nENTRYPOINT [\"dotnet\", \"FEShop.AdminWebSite.dll\"]</code></pre>\n\n<h3>4.2、创建构建脚本docker-compose.yaml</h3>\n<pre><code>version: \'3.8\'\nservices:\n  dapr-adminwebsite:\n    build:\n      context: .  \n      dockerfile: Dockerfile #基于dockerfile文件来构建镜像\n      args:\n        BUILD_VERSION: v1.0.1  \n    image: dapr-adminwebsite:v1.0.1  \n    container_name: dapr-adminwebsite\n    restart: unless-stopped\n    ports:\n      - \"8071:80\"  # 映射外部使用8071端口访问\n    environment:\n      - ASPNETCORE_ENVIRONMENT=Production\n      - TZ=Asia/Shanghai\n      -  DOTNET_RESTORE_SOURCES=https://api.nuget.org/v3/index.json;https://nuget.cdn.azure.cn/v3/index.json\n      - ASPNETCORE_URLS=http://+:80 #固定80端口，kestrel默认监听的是5000端口\n    networks:\n      - feshop-network\nnetworks:\n  feshop-network: #创建容器网络，使用桥接模式\n    driver: bridge</code></pre>\n\n<h3>4.3、将Jenkins用户添加到Docker组</h3>\n<pre><code># 把Jenkins账号加入docker组\n[root@node01 jenkins]# sudo usermod -aG docker jenkins\n# 重启jenkins\n[root@node01 jenkins]# sudo systemctl restart jenkins</code></pre>\n\n<h3>4.4、在Jenkins控制面板添加自动构建脚本</h3>\n<p>快捷访问：http://192.168.72.131:8080/job/zlj.dapr.microserviceproject/configure#Environment</p>\n<pre><code>cd /var/lib/jenkins/workspace/zlj.dapr.microserviceproject/06-FEShop.WebSite/FEShop.AdminWebSite\nsudo docker stop dapr-adminwebsite || true\nsudo docker rm dapr-adminwebsite || true\nsudo docker rmi dapr-adminwebsite:v1.0.1 || true\ndocker-compose up -d --build</code></pre>\n\n<h3>4.5、宿主机访问</h3>\n\n<h2>5、微服务架构子模块热更新</h2>\n\n<h3>5.1、假设你的架构设计是我这样，</h3>\n<p>这里面需要更新的包括类库、webapi和站点，其中类库应该往nexus上面推，其他更新到docker，接下来处理微服务更新到Docker。</p>\n<p>当有代码提交时需要区别是公共模块的提交还是子系统的提交，公共模块更新时，所有微服务子系统都需要更新，否则只需要单独更新即可。</p>\n\n<pre><code>├── 01-FEShop.Common\n│   ├── FEShop.Core (类库)        # 基础工具、扩展方法、通用模型\n│   └── FEShop.Contracts (类库)   # 合并到Common，重命名为FEShop.Shared\n├── 02-FEShop.Infrastructure\n│   └── FEShop.Infrastructure (类库) # 基础设施通用实现\n├── 03-FEShop.Microservices\n│   ├── FEShop.UserService (ASP.NET Core Web API)\n│   │   ├── docker-compose.yaml\n│   │   ├── Dockerfile\n│   ├── FEShop.ProductService (ASP.NET Core Web API)\n│   │   ├── docker-compose.yaml\n│   │   ├── Dockerfile\n│   ├── FEShop.OrderService (ASP.NET Core Web API)\n│   │   ├── docker-compose.yaml\n│   │   ├── Dockerfile\n│   └── FEShop.PaymentService (ASP.NET Core Web API)\n│   │   ├── docker-compose.yaml\n│   │   ├── Dockerfile\n├── 04-FEShop.Shared\n│   └── FEShop.OpenModel (类库)  \n├── 05-FEShop.Gateway\n│   └── FEShop.Gateway (ASP.NET Core 网关)\n├── 06-FEShop.WebSite\n│   ├── FEShop.AdminWebSite (Razor Pages 或 MVC)\n│   └── FEShop.PCShop (ASP.NET Core Web应用)\n└── docker-compose.yml</code></pre>\n\n<h3>5.4、自动化部署脚本，根据需要部署的微服务，对比git提交是否有变动，如果变动的文件匹配来目录就更新相关站点</h3>\n<pre><code>[root@node01 deploy-scripts]# cat deploy.sh\n#!/bin/bash\n\n# 仓库根目录\nREPO_ROOT=\"/var/lib/jenkins/workspace/zlj.dapr.microserviceproject\"\n\n# 获取最近两次提交的变更文件\nCHANGED_FILES=$(git diff --name-only HEAD~1 HEAD 2>/dev/null)\n\n# 定义服务目录映射\ndeclare -A SERVICE_PATHS=(\n    [\"FEShop.Infrastructure\"]=\"02-FEShop.Infrastructure/02-FEShop.Infrastructure\"\n    [\"FEShop.UserService\"]=\"03-FEShop.Microservices/FEShop.AppUserService\"\n    [\"FEShop.ProductService\"]=\"03-FEShop.Microservices/FEShop.ProductService\"\n    [\"FEShop.OrderService\"]=\"03-FEShop.Microservices/FEShop.OrderService\"\n    [\"FEShop.PaymentService\"]=\"03-FEShop.Microservices/FEShop.PaymentService\"\n    [\"FEShop.AdminWebSite\"]=\"06-FEShop.WebSite/FEShop.AdminWebSite\"\n    [\"FEShop.PCShop\"]=\"06-FEShop.WebSite/FEShop.PCShop\"\n    [\"FEShop.Gateway\"]=\"05-FEShop.Gateway/FEShop.GatewayApi\"\n)\n\n# 定义公共库（变更时触发所有服务）\nCOMMON_LIBS=(\"01-FEShop.Common\" \"02-FEShop.Infrastructure\" \"04-FEShop.Shared\")\n\n# 存储需要更新的服务\ndeclare -A SERVICES_TO_UPDATE\n\n# 1. 检查公共库是否变更\nfor lib in \"${COMMON_LIBS[@]}\"; do\n    if echo \"$CHANGED_FILES\" | grep -q \"^$lib\"; then\n        echo \"公共库 $lib 变更，将部署所有微服务\"\n        for service in \"${!SERVICE_PATHS[@]}\"; do\n            SERVICES_TO_UPDATE[\"$service\"]=1\n        done\n        break\n    fi\ndone\n\n# 2. 检查各微服务变更\nif [ ${#SERVICES_TO_UPDATE[@]} -eq 0 ]; then\n    for service in \"${!SERVICE_PATHS[@]}\"; do\n        service_path=\"${SERVICE_PATHS[$service]}\"\n\n        # 检查该服务目录或其子目录是否有变更\n        if echo \"$CHANGED_FILES\" | grep -q \"^$service_path\"; then\n            echo \"检测到变更: $service\"\n            SERVICES_TO_UPDATE[\"$service\"]=1\n        fi\n    done\nfi\n\n# 3. 执行部署\ndeploy_service() {\n    local service_name=$1\n    local service_path=\"${REPO_ROOT}/${SERVICE_PATHS[$service_name]}\"\n    local container_name=\"dapr-${service_name,,}\"  # 转换为小写\n\n    echo \"========================================\"\n    echo \"开始部署 $service_name\"\n    echo \"目录: $service_path\"\n    echo \"========================================\"\n\n    cd \"$service_path\" || { echo \"❌ 无法进入目录: $service_path\"; exit 1; }\n\n    # 停止并移除旧容器\n    sudo docker stop \"$container_name\" >/dev/null 2>&1 || true\n    sudo docker rm \"$container_name\" >/dev/null 2>&1 || true\n\n    # 移除旧镜像\n    sudo docker rmi \"${container_name}:v1.0.1\" >/dev/null 2>&1 || true\n\n    # 构建并启动新容器\n    docker-compose up -d --build\n\n    echo \"✅ $service_name 部署完成\"\n    echo \"\"\n}\n\n# 部署所有变更的服务\nif [ ${#SERVICES_TO_UPDATE[@]} -gt 0 ]; then\n    echo \"需要更新的服务: ${!SERVICES_TO_UPDATE[@]}\"\n    for service in \"${!SERVICES_TO_UPDATE[@]}\"; do\n        deploy_service \"$service\"\n    done\nelse\n    echo \"⚠️ 未检测到需要更新的微服务\"\nfi</code></pre>\n\n<h3>5.5、将上面的脚本放置在源码目录指定位置，如：/var/lib/jenkins/workspace/zlj.dapr.microserviceproject/deploy-scripts</h3>\n<p>当我的Jenkins执行后，只需要执行相关的sh脚本即可</p>\n<pre><code>cd /var/lib/jenkins/workspace/zlj.dapr.microserviceproject/deploy-scripts\nsudo ./deploy.sh</code></pre>\n\n<h4>5.5.1、比如当我执行这个脚本时，检测到PaymentService项目没有代码更新，则自动跳过，当OrderService中有代码更新则重新编译</h4>\n\n<h4>5.5.2、更新前的容器列表：</h4>\n\n<h4>5.5.3、更新后只有相关的容器被重建，其余的不处理。</h4>\n\n<h4>5.5.4、查看镜像列表</h4>\n<pre><code>[root@node01 deploy-scripts]# docker images\nREPOSITORY                                           TAG               IMAGE ID       CREATED          SIZE\ndapr-adminwebsite                                    v1.0.1            2cf49dc68db6   30 minutes ago   226MB\ndapr-pcwebsite                                       v1.0.1            e1b1992d5d12   30 minutes ago   226MB\ndapr-gatewayapi                                      v1.0.1            ff3b76c2a527   31 minutes ago   220MB\ndapr-productservice                                  v1.0.1            300c3cbd19d5   31 minutes ago   220MB\ndapr-orderservice                                    v1.0.1            45377058c4c7   31 minutes ago   220MB\ndapr-appuserservice                                  v1.0.1            98a161c47343   31 minutes ago   220MB\n&lt;none&gt;                                               &lt;none&gt;            483cb9b7f0f7   8 hours ago      226MB\n&lt;none&gt;                                               &lt;none&gt;            834ff729e0b0   8 hours ago      226MB\n&lt;none&gt;                                               &lt;none&gt;            63931c20f6da   8 hours ago      220MB\n&lt;none&gt;                                               &lt;none&gt;            f690f1b1d732   8 hours ago      220MB\n&lt;none&gt;                                               &lt;none&gt;            09aaf5cac089   8 hours ago      220MB\n&lt;none&gt;                                               &lt;none&gt;            7ad5805e66bc   8 hours ago      220MB\n&lt;none&gt;                                               &lt;none&gt;            566fb3ac0d33   8 hours ago      220MB\n&lt;none&gt;                                               &lt;none&gt;            08c5cfa9b0fa   12 hours ago     226MB\n&lt;none&gt;                                               &lt;none&gt;            8b7504556987   13 hours ago     220MB</code></pre>\n\n<h3>附：Docker批量操作</h3>\n<pre><code>[root@node01 ~]#  docker image prune\n删除未被使用的镜像（包括非none镜像）\n[root@node01 ~]# docker image prune -a\n停止所有容器\n[root@node01 ~]# docker stop $(docker ps -aq)\n停止指定容器，比如以dapr开头的\n[root@node01 ~]# docker ps -q --no-trunc | grep -E \'^(dapr|test)\' | xargs docker stop\n删除所有停止的容器,-f表示跳过确认\n[root@node01 ~]# docker container prune -f</code></pre>', NULL, 1, '微服务,DevOps,Jenkins,Docker,自动化部署', 1, 0, 2, 0, 0, 0, '2025-10-21 00:00:00', 0, 1, '2025-10-21 17:00:35', '拉里', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (869707427840, '1112222', '444444444444', '# 技术文档示例\n\n## 简介\n\n这是一篇技术文章的示例模板，展示了 **Markdown** 的常用语法和排版效果。您可以参考这个模板来编写自己的文章。\n\n### 文本格式\n\n- **加粗文本**：使用 `**文本**`\n- *斜体文本*：使用 `*文本*`\n- <u>下划线</u>：使用 `<u>文本</u>`\n- ~~删除线~~：使用 `~~文本~~`\n\n### 列表\n\n**无序列表：**\n- 第一项\n- 第二项\n  - 子项 1\n  - 子项 2\n- 第三项\n\n**有序列表：**\n1. 第一步\n2. 第二步\n3. 第三步\n\n## 代码示例\n\n### JavaScript 代码块\n\n```javascript\n// React 函数组件示例\nfunction HelloWorld({ name }) {\n  const [count, setCount] = useState(0);\n  \n  return (\n    <div className=\"hello\">\n      <h1>Hello, {name}!</h1>\n      <button onClick={() => setCount(count + 1)}>\n        Clicked {count} times\n      </button>\n    </div>\n  );\n}\n```\n\n### Python 代码块\n\n```python\ndef fibonacci(n):\n    \"\"\"计算斐波那契数列\"\"\"\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\n# 输出前 10 个数\nfor i in range(10):\n    print(f\"F({i}) = {fibonacci(i)}\")\n```\n\n### 行内代码\n\n在文本中使用 `const x = 10;` 这样的行内代码。\n\n## 图片展示\n\n![React Logo](https://upload.wikimedia.org/wikipedia/commons/a/a7/React-icon.svg)\n\n*图片说明：React 官方 Logo*\n\n## 链接\n\n- [React 官方文档](https://react.dev)\n- [MDN Web Docs](https://developer.mozilla.org)\n- [GitHub](https://github.com)\n\n## 表格\n\n| 特性 | React | Vue | Svelte |\n|------|-------|-----|--------|\n| 虚拟DOM | ✓ | ✓ | ✗ |\n| TypeScript | ✓ | ✓ | ✓ |\n| 生态系统 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ |\n| 学习曲线 | 中 | 低 | 低 |\n\n## 引用\n\n> “代码质量不仅仅是关于功能，更是关于可读性和可维护性。”\n> \n> —— Robert C. Martin\n\n## 注意事项\n\n⚠️ **重要：**请确保代码的安全性和性能。\n\n✅ **提示：**使用 ESLint 和 Prettier 保持代码风格统一。\n\n## 总结\n\n本文展示了 Markdown 的常用语法，包括：\n\n1. 标题和段落\n2. 文本格式化\n3. 列表和代码块\n4. 图片和链接\n5. 表格和引用\n\n希望这个示例能帮助您快速上手 Markdown 编写！', NULL, 1, '333', 1, 0, 0, 0, 0, 0, '1900-01-01 00:00:00', 0, 2, '2025-10-22 07:24:55', '刘海', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (945790648320, 'Ollama大模型本地部署', '使用Ollama部署本地大模型', '1111111111111', NULL, 1, 'Ollama', 1, 0, 0, 0, 0, 0, '1900-01-01 00:00:00', 0, 1, '2025-10-21 22:04:55', '佩奇', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (29220692461072, 'Dapr微服务框架（一）初识Dapr', 'Dapr（Distributed Application Runtime）是一个开源的、事件驱动的分布式应用运行时，由微软与2019年推出，旨在简化云和边缘环境中弹性、可移植微服务的开发。它通过边车（Sidcar）提供标准化构建块，抽象分布式系统的复杂性，让开发者聚焦业务逻辑。', '### 1、Dapr的定义\n   Dapr 以Sidecar进程或容器形式与应用共存，通过HTTP/gRPC API 暴露分布式能力，无需应用代码耦合特定SDK。其设计遵循“构建块”（Building Blocks）理念，将微服务通用能力模块化\n### 2、Dapr解决的核心问题\n  1）分布式复杂性：简化服务调用、状态管理、消息传递等分布式模式实现。\n  2）环境锁定：通过抽象基础设施（如数据库、消息队列），实现应用与运行环境（云、边缘、Kubernetes/虚拟机）解耦\n  3）多语言支持：避免框架绑定语言，支持 Go、Java、.NET\n### 3、Dapr核心组件构成\n1）SideCar（边车）：与应用程序协同部署的轻量级进程，提供HTTP/gRPC API。\n  2）构建块：提供标准化的分布式系统功能抽象,如服务调用、状态管理、发布订阅、Actors、秘钥管理、绑定组件\n  3）组件（components）：可插拔的后端实现，如状态存储(statestore.yaml)、发布订阅实现(pubsub.yaml)、秘钥存储（secrets.yaml）\n  4）控制平面：管理Dapr运行时\n    a. Placement服务：\n      功能：用作Actor位置协调器\n      职责：维护Actor分布表，处理Actor分区，负载均衡以及管理集群节点和注册。\n    b.Sentry服务\n      功能：证书颁发机构\n      职责：管理服务间mTLS证书，自动证书轮换以及提供身份认证\n    c.Operator：\n      功能：Kubernetes集群管理\n      职责：管理Dapr组件CRD、处理Sidecar注入、监控Dapr系统服务，\n5）可观测性组件\n    a.Zipkin/Jaeger\n      功能：分布式追踪系统\n      职责：追踪数据：客户端发送(cs)、服务端接收(sr)、服务端发送(ss)、客户端接收(cr)\n    b.Prometheus:\n      功能：核心指标监控与可观测性引擎。\n      职责：提供性能分析与优化参考，为服务稳定运行提供可靠性保障\n      \n  6）配置管理：基于配置文件configuration.yaml\n\n### 1.5、Dapr各组件关系结构图\n\n## 2、Dapr安装\n  ### 2.1、Dapr-Cli（客户端）\n  1）Dapr-Cli是Dapr的命令行工具，用于管理和操作Dapr运行时，它提供了一系列命令，帮助开发者完成以下任务：\n    a. 安装和初始化Dapr：通过Dapr init命令可以快速启动Dapr运行时环境。\n    b. 部署和管理组件：例如通过dapr component create来创建和管理状态存储、消息代理等组件。\n    c. 运行和调试应用： 会用dapr run命令可以启动一个服务，并自动绑定dapr的功能。\n    d. 状态检查：dapr status命令查看dapr的运行状态。\n    Dapr-Cli是开发者与Dapr交互的主要入口，简化了本地开发和部署流程\n    \n ### 2.2、在线下载：\n```\n切换到bin目录\n[root@node01 ~]# cd /bin/\n直接下载运行，默认安装\n[root@masternode bin]# wget -q https://raw.githubusercontent.com/dapr/cli/master/install/install.sh -O - | /bin/bash -s 1.15.1\n指定安装在$HOME目录下\n[root@masternode bin]# wget -q https://raw.githubusercontent.com/dapr/cli/master/install/install.sh -O - | DAPR_INSTALL_DIR=\"$HOME/dapr\" /bin/bash -s 1.15.1\n```\n### 2.3、查看是否安装成功\n``` \n验证安装\n[root@masternode bin]# dapr -h\n         __\n    ____/ /___ _____  _____\n   / __  / __ \'/ __ \\/ ___/\n  / /_/ / /_/ / /_/ / /\n  \\__,_/\\__,_/ .___/_/\n              /_/\n===============================\n分布式应用程序运行时\n用法：\n  dapr [命令]\n可用命令：\n  completion     生成 shell 补全脚本\n  components     列出所有 Dapr 组件。支持的平台：Kubernetes\n  configurations 列出所有 Dapr 配置。支持的平台：Kubernetes\n  dashboard      启动 Dapr 仪表板。支持的平台：Kubernetes 和自托管\n  help           获取任何命令的帮助\n  init           在支持的托管平台上安装 Dapr。支持的平台：Kubernetes 和自托管\n  invoke         调用给定 Dapr 应用程序上的方法。支持的平台：自托管\n  list           列出所有 Dapr 实例。支持的平台：Kubernetes 和自托管\n  logs           获取应用程序的 Dapr 边车日志。支持的平台：Kubernetes\n  mtls           检查是否启用了 mTLS。支持的平台：Kubernetes\n  publish        发布一个 pub-sub 事件。支持的平台：自托管\n  run            运行 Dapr 并（可选）与您的应用程序并排运行。支持的平台：自托管\n  status         显示 Dapr 服务的健康状态。支持的平台：Kubernetes\n  stop           停止 Dapr 实例及其关联的应用程序。支持的平台：自托管\n  uninstall      卸载 Dapr 运行时。支持的平台：Kubernetes 和自托管\n  upgrade        升级集群中的 Dapr 控制平面安装。支持的平台：Kubernetes\n  version        打印 Dapr 运行时和 CLI 版本\n\n\n标志：\n  -h, --help      获取 dapr 的帮助\n  -v, --version   获取 dapr 的版本\n\n```\n### 2.4、初始化Dapr,初始化之后才会显示运行时版本\n```\n[root@masternode dapr]# dapr init\n⌛  Making the jump to hyperspace...\nℹ️  Container images will be pulled from Docker Hub\nℹ️  Installing runtime version 1.15.8\n\n初始化成功会生成一些镜像，并成功运行容器\n[root@masternode dapr]# ls $HOME/.dapr\nbin  components  config.yaml\n\n[root@masternode opt]# dapr --version\nCLI version: 1.15.1  客户端版本\nRuntime version: 1.15.8  运行时版本\n\n#查看Dapr容器\n[root@masternode opt]# ps aux | grep daprd\nroot      106566  0.0  0.0  12348  1136 pts/0    S+   02:01   0:00 grep --color=auto daprd\n\n```\n## 3、使用Dapr Api\n  ### 3.1、Dapr SIdeCar\n  1）启动一个SideCar，在3500端口上监听一个应用程序\n```\n#确保hosts有localhost的配置\n[root@masternode opt]# cat /etc/hosts\n127.0.0.1   localhost localhost.localdomain\n::1         localhost6 localhost6.localdomain\n\n[root@masternode opt]# dapr run --app-id myapp --dapr-http-port 3500\nWARNING: no application command found.\nℹ️  Starting Dapr with id myapp. HTTP Port: 3500. gRPC Port: 38251\n\n```\n### 3.2、查看运行的dapr容器\n  1）命令行查看dapr相关的容器\n```\n[root@masternode ~]# ps aux | grep daprd\n\n[root@masternode ~]# docker ps --filter \"name=dapr_\" --filter \"name=daprio/daprd\"\n\n```\n  2）浏览器访问http://192.168.72.140:3500查看运行的容器', NULL, 1, 'Dapr，后端开发', 1, 0, 16, 0, 0, 0, '1900-01-01 00:00:00', 0, 2, '2025-10-22 21:14:25', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (29242385344528, '图文博客测试001', '看起来就很棒', '# 技术文档示例\n![image](https://localhost:7235/ArticleFiles/30xodv2pa4f_20251023080957564.jpg)\n## 简介\n[个人博客地址](https://gitee.com/inc-zz)\n这是一篇技术文章的示例模板，展示了 **Markdown** 的常用语法和排版效果。您可以参考这个模板来编写自己的文章。\n\n### 文本格式\n\n- **加粗文本**：使用 `**文本**`\n- *斜体文本*：使用 `*文本*`\n- <u>下划线</u>：使用 `<u>文本</u>`\n- ~~删除线~~：使用 `~~文本~~`\n\n### 列表\n\n**无序列表：**\n- 第一项\n- 第二项\n  - 子项 1\n  - 子项 2\n- 第三项\n\n**有序列表：**\n1. 第一步\n2. 第二步\n3. 第三步\n\n## 代码示例\n\n### JavaScript 代码块\n\n```javascript\n// React 函数组件示例\nfunction HelloWorld({ name }) {\n  const [count, setCount] = useState(0);\n  \n  return (\n    <div className=\"hello\">\n      <h1>Hello, {name}!</h1>\n      <button onClick={() => setCount(count + 1)}>\n        Clicked {count} times\n      </button>\n    </div>\n  );\n}\n```\n\n### Python 代码块\n\n```python\ndef fibonacci(n):\n    \"\"\"计算斐波那契数列\"\"\"\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\n# 输出前 10 个数\nfor i in range(10):\n    print(f\"F({i}) = {fibonacci(i)}\")\n```\n\n### 行内代码\n\n在文本中使用 `const x = 10;` 这样的行内代码。\n\n## 图片展示\n\n![React Logo](https://upload.wikimedia.org/wikipedia/commons/a/a7/React-icon.svg)\n\n*图片说明：React 官方 Logo*\n\n## 链接\n\n- [React 官方文档](https://react.dev)\n- [MDN Web Docs](https://developer.mozilla.org)\n- [GitHub](https://github.com)\n\n## 表格\n\n| 特性 | React | Vue | Svelte |\n|------|-------|-----|--------|\n| 虚拟DOM | ✓ | ✓ | ✗ |\n| TypeScript | ✓ | ✓ | ✓ |\n| 生态系统 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ |\n| 学习曲线 | 中 | 低 | 低 |\n\n## 引用\n\n> “代码质量不仅仅是关于功能，更是关于可读性和可维护性。”\n> \n> —— Robert C. Martin\n\n## 注意事项\n\n⚠️ **重要：**请确保代码的安全性和性能。\n\n✅ **提示：**使用 ESLint 和 Prettier 保持代码风格统一。\n\n## 总结\n\n本文展示了 Markdown 的常用语法，包括：\n\n1. 标题和段落\n2. 文本格式化\n3. 列表和代码块\n4. 图片和链接\n5. 表格和引用\n\n希望这个示例能帮助您快速上手 Markdown 编写！', NULL, 1, '图文', 1, 0, 16, 0, 0, 0, '1900-01-01 00:00:00', 0, 2, '2025-10-23 09:00:34', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (29246433072656, 'Dapr微服务框架（二）服务调用与订阅发布', '在 .NET 开发环境中，Dapr 主要通过在服务旁注入 Sidecar 容器/进程，将服务通信的通用能力（如服务发现、重试、安全、追踪等）下沉到基础设施层，从而简化微服务间的调用。下面这个表格概括了其核心机制和关键配置', '## 1、服务调用相关概念\n### 1.1、Dapr服务调用（Service-to-Service Invocation）\n  1）允许通过服务名而非  IP地址安全调用其他服务，自动处理重试、熔断、mTLS加密和跨命名空间通信。\n  2）相关组件：\n    > a. Dapr Sidecar：每个服务旁部署的轻量代理，监听3500端口，业务服务通过localhost:3500与本机Sidecar通信，无需感知目标服务位置。\n    > b. 服务调用API：\n      调用者：向Sidecar发送HTTP/gRPC请求。\n      被调用者：Sidecar将请求转发至本机业务服务的真实端口（如8080）\n    > c. 名称解析组件：\n      作用：将服务名解析为实际Endpoint（IP列表）\n    > d. 负载均衡与重试：Sidecar自动对目标服务的多个实例进行轮询负载均衡，可配置重试策略。\n    > e. 安全通信（mTLS):Sentry服务自动办法证书，Sidecar间通信强制TLS加密。d\n### 1.2、发布订阅（Pub/Sub）\n  1）目的：实现服务间基于主题（Topic）的异步消息传递，支持至少一次语义，解耦生产者与消费者。\n  2）相关组件：\n   > a. 发布端(Publisher):服务向Sidecar发送消息：\n   > b. 订阅端(Subscriber):服务声明订阅关系\n      声明式：通过subscription.yaml定义\n      编程式：服务暴露/dapr/subscribe返回订阅列表。\n    > c. Pub/Sub组件（Pluggable Components）\n      作用：对接具体消息中间件（Kafka，Redis，RabbitMQ等）\n    > d.消息处理流程：\n![image](https://localhost:7235/ArticleFiles/111_20251023102309588.png)\n    > e. 可靠性保障机制\n        死信队列（DLQ）：处理失败的消息可转发只DLQ。\n        重试策略：自定义退避间隔和重试次数。\n        消息去重：支持幂等处理\n### 1.3、跨组件协同设计\n  1）可观测性贯穿：服务调用和Pub/Sub全链路追踪通过Zpikin/Jaeger自动关联。 Prometheus收集消息延迟、错误率等指标。\n  2）安全与策略：通过配置限制服务间调用权限实现访问控制，限制主题的消费速率。\n  3）与Actor模型集成：Actor可通过服务调用被触发，也可作为Pub/Sub的消费者。\n### 1.4、关键协作组件\n![image](https://localhost:7235/ArticleFiles/383f6768-4271-4007-9006-0c61944fe0d7_20251023102646858.png)\n## 2、用户微服务项目集成\n### 2.1、使用Dapr服务调用模块实现客户端网站调用用户微服务\n  用户注册逻辑：网关API提交用户注册->用户微服务处理注册->注册成功发送注册邮件->发送注册短信\n![image](https://localhost:7235/ArticleFiles/Image_20251023103320666.png)\n\n### 2.2、创建Demos.UserMicroservice的webapi项目\n  1）创建项目 Demos.DaprUserMicroservice\n  2）添加nuget包\n\n```xml\n  <ItemGroup>\n      <PackageReference Include=\"Dapr.Actors\" Version=\"1.15.4\" />\n      <PackageReference Include=\"Dapr.Actors.AspNetCore\" Version=\"1.15.4\" />\n      <PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.15.4\" />\n      <PackageReference Include=\"Dapr.Client\" Version=\"1.15.4\" />\n      <PackageReference Include=\"Dapr.Extensions.Configuration\" Version=\"1.15.4\" />\n      <PackageReference Include=\"Mapster\" Version=\"7.4.0\" />\n      <PackageReference Include=\"Microsoft.VisualStudio.Azure.Containers.Tools.Targets\"  Version=\"1.21.0\" />\n      <PackageReference Include=\"Newtonsoft.Json\" Version=\"13.0.3\" />\n      <PackageReference Include=\"SqlSugarCore\" Version=\"5.1.4.198\" />\n      <PackageReference Include=\"Swashbuckle.AspNetCore\" Version=\"6.6.2\" />\n      <PackageReference Include=\"Microsoft.Extensions.Caching.StackExchangeRedis\"  Version=\"9.0.7\" />\n  </ItemGroup>\n```\n 4）在Program中集成Dapr\n  //2、集成Dapr Client\n``` charp\nbuilder.Services.AddDaprClient(option =>\n{\n    var daprConfig = builder.Configuration.GetSection(\"Dapr\");\n    //配置Dapr客户端(HTTP和gRPC端点)\n    var defaultEndpoints = daprConfig.GetSection(\"UserMicroservice\");\n    var httpEndpoint = defaultEndpoints.GetSection(\"HttpEndpoint\").Get<string>();\n    option.UseHttpEndpoint(httpEndpoint);\n    var grpcEndpoint = defaultEndpoints.GetSection(\"GrpcEndpoint\").Get<string>();\n    option.UseGrpcEndpoint(grpcEndpoint);\n});\n```\n\n5）创建控制器AppUserController.cs\n``` charp\nusing Dapr.Actors;\nusing Dapr.Actors.Client;\nusing Dapr.Client;\nusing Demos.DaprUserMicroservice.Common;\nusing Demos.DaprUserMicroservice.DbContexts;\nusing Demos.DaprUserMicroservice.Entities;\nusing Demos.DaprUserMicroservice.Models.Requests;\nusing Demos.DaprUserMicroservice.Models.Responses;\nusing Demos.DaprUserMicroservice.Services;\nusing Microsoft.AspNetCore.Mvc;\nusing SqlSugar;\nnamespace Demos.DaprUserMicroservice.Controllers\n{\n    /// <summary>\n    /// 用户控制器\n    /// </summary>\n    [ApiController]\n    [Route(\"api/[controller]\")]\n    public class AppUserController : ControllerBase\n    {\n        private ILogger<AppUserController> _logger;\n        private DaprClient _daprClient;\n        private readonly IConfiguration _configuration;\n        public AppUserController(ILogger<AppUserController> logger,\n            DaprClient daprClient,\n            IConfiguration configuration)\n        {\n            _logger = logger;\n            _daprClient = daprClient;\n            _configuration = configuration;\n        }\n        /// <summary>\n        /// 注册用户\n        /// </summary>\n        /// <param name=\"dto\"></param>\n        /// <returns></returns>\n        [HttpPost(\"register\")]\n        public async Task<IActionResult> RegisterUserAsync([FromBody] RegisterUserDto dto)\n        {\n            var db = SqlSugarDbContext.GetInstance(_configuration);\n            Random random = new Random();\n            var user = new AppUserInfo\n            {\n                UserId = random.Next(100000, 999999),\n                UserName = dto.UserName,\n                Password = dto.Password,\n                Email = dto.Email,\n                Phone = dto.Phone,\n                CreateTime = DateTime.Now,\n                UpdateTime = DateTime.Now\n            };\n            var userAddress = new AppUserAddress\n            {\n                AreaName = \"\",\n                AreaCode = \"\",\n                Address = \"\",\n                ContactNumber = user.Phone,\n                Contacts = user.UserName\n            };\n            user.AppUserAddresses = userAddress;\n            db.InsertNav(user)\n               .Include(it => it.AppUserAddresses)\n               .ExecuteCommand();\n            var result = new ResultObject\n            {\n                Code = 200,\n                Message=\"注册成功\"\n            };\n            return Ok(result);\n        }\n        /// <summary>\n        /// 获取分页列表\n        /// </summary>\n        /// <param name=\"paging\"></param>\n        /// <returns></returns>\n        [HttpPost(\"pager\")]\n        public async Task<IActionResult> PagerUserAsync([FromBody]  PagingByFilter<QueryUserFilter> paging)\n        {\n            var db = SqlSugarDbContext.GetInstance(_configuration);\n            int totalCount = 0;\n            var list = db.Queryable<AppUserInfo>()\n                .WhereIF(!string.IsNullOrEmpty(paging.Filter?.UserName), u =>  u.UserName.Contains(paging.Filter.UserName))\n                .OrderBy(u => u.CreateTime, OrderByType.Desc)\n                .ToPageList(paging.PageIndex, paging.PageSize, ref totalCount);\n            var result = new ResultPagerObject<PageAppUserDto>\n            {\n                Code = 200,\n                Count = totalCount,\n                Items = new List<PageAppUserDto>()\n            };\n            var userList = list.Select(it=>new PageAppUserDto\n            {\n                UserId = it.UserId,\n                UserName = it.UserName,\n                Email = it.Email,\n                Phone = it.Phone,\n                CreateTime = it.CreateTime\n            }).ToList();\n            result.Items = userList;\n            return Ok(result);\n        }\n    }\n}\n``` \n## 3、发布用户微服务\npublish目录为发布后的文件目录\n![image](https://localhost:7235/ArticleFiles/Image2_20251023103649078.png)\n### 3.1、使用dapr启动项目\n``` charp\n#随机端口启动\n[root@masternode publish]# dapr run --app-id usermicroservice --app-port 5001 -- dotnet Demos.DaprUserMicroservice.dll --urls \"http://0.0.0.0:5000\"\n\nℹ️  Starting Dapr with id daprusermicroservice. HTTP Port: 40957. gRPC Port: 43393\nFlag --components-path has been deprecated, use --resources-path\n......\n```\n3.2、指定Http和Grpc端口启动\n  使用dapr run命令启动前提是placement，zipkin，redis组件都已经启动。这个在dapr init初始化的时候启动。如果是部署环境，这些组件应该都放置在docker-compose.yaml中去配置，不需要dapr init来启动。\n``` shell\n[root@masternode publish]# dapr run --app-id usermicroservice --dapr-http-port 8085 --dapr-grpc-port 9095 --app-port 5001 -- dotnet Demos.DaprUserMicroservice.dll --urls \"http://0.0.0.0:5001\"\n\n指定8085为http端口，9095为gRpc端口，提供给dapr客户端连接，比如网关层调用用户微服务时。\n![image](https://localhost:7235/ArticleFiles/Image3_20251023103800958.png)\n```\n3.3、查看运行的dapr应用列表\n  当你使用docker-compose运行项目时，在dapr list中不会显示应用\n[root@masternode publish]# dapr list\n``` shell\n暴露两种端口HTTP端口为40957，GRPC端口为43393\n[root@node01 usermicroservice]# dapr list\nAPP ID            HTTP PORT  GRPC PORT  APP PORT  COMMAND               AGE  CREATED              DAPRD PID  CLI PID  APP PID ......\nusermicroservice  8085       9095       5001      dotnet Demos.Dapr...  3m   2025-08-16 20:30.54  519143     519122   519144  \n```\n### 3.4、使用浏览器测试连通性\n1）命令格式：\nIP地址:HTTP端口/v1.0/invoke/APP ID/method/微服务控制器/具体方法\n如：http://192.168.72.131:8085/v1.0/invoke/usermicroservice/method/apitest/getEnvironment\n\n2）浏览器访问：swagger地址http://192.168.72.131:5001/swagger/index.html\n## 4、调用端项目集成\n  \n### 4.1、创建网关项目，使用网关调用用户微服务\n  \n### 4.2、添加dapr客户端nuget包引用\n``` csharp\n<ItemGroup>\n  <PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.15.4\" />\n  <PackageReference Include=\"Dapr.Client\" Version=\"1.15.4\" />\n  <PackageReference Include=\"Swashbuckle.AspNetCore\" Version=\"6.6.2\" />\n</ItemGroup>\n```\n### 4.3、集成对接\n  1）修改Progarm.cs\n``` csharp\n   ...省略其他代码...\n    //集成Dapr客户端,如果是内部调用，不需要调用其他Sidecar则不需要配置options。只需要使用前面的\n    builder.Services.AddDaprClient(options =>\n    {\n        //配置Dapr客户端\n        options.UseHttpEndpoint(\"http://192.168.72.131:7257\");\n        options.UseGrpcEndpoint(\"http://192.168.72.131:5004\");\n    });\n    var app = builder.Build();\n    ...省略其他代码...\n``` \n 2）创建IndexController控制器，实现调用用户微服务（普通的服务调用都使用此类，对于并发要求比较高的接口推荐使用Actor模式）\n``` csharp\nusing Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nnamespace Demos.DaprWebSite.Controllers\n{\n    /// <summary>\n    ///\n    /// </summary>\n    [ApiController]\n    [Route(\"[controller]\")]\n    public class IndexController : ControllerBase\n    {\n        private readonly ILogger<IndexController> _logger;\n        private readonly DaprClient _daprClient;\n        /// <summary>\n        ///\n        /// </summary>\n        /// <param name=\"logger\"></param>\n        /// <param name=\"daprClient\"></param>\n        public IndexController(ILogger<IndexController> logger,\n            DaprClient daprClient)\n        {\n            _logger = logger;\n            _daprClient = daprClient;\n        }\n        /// <summary>\n        /// 调用用户数据\n        /// </summary>\n        /// <returns></returns>\n        [HttpGet]\n        public void Get()\n        {\n            _logger.LogDebug(\"======调用用户数据======\");\n            //数据调用地址：http://192.168.72.140:43759/v1.0/invoke/daprusermicroservice/method/api/usercenter/users\n            // 调用用户微服务\n            var result = _daprClient.InvokeMethodAsync<List<string>>(HttpMethod.Get,\n                \"daprusermicroservice\",\n                \"api/usercenter/users\");\n            _logger.LogDebug($\"调用结果：{result.Result}\");\n        }\n    }\n}\n``` \n ### 4.4、使用发布订阅模式处理Post数据\n1）创建Demos.DaprEmailMicroservice项目，添加如下nuget包引用\n``` xml\n<ItemGroup>\n  <PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.15.4\" />\n  <PackageReference Include=\"Swashbuckle.AspNetCore\" Version=\"6.6.2\" />\n</ItemGroup>\n``` \n2）创建控制器UserController.cs\n``` csharp\nusing Dapr;\nusing Demos.DaprEmailMicroservice.Dtos;\nusing Microsoft.AspNetCore.Mvc;\nusing System.Text.Json;\nusing System.Text.Json.Serialization;\nnamespace Demos.DaprEmailMicroservice.Controllers\n{\n    /// <summary>\n    /// 邮件服务-消息消费端\n    /// </summary>\n    [Route(\"[controller]\")]\n    [ApiController]\n    public class UserController:ControllerBase\n    {\n        private readonly ILogger<UserController> _logger;\n        public UserController(ILogger<UserController> logger)\n        {\n            _logger = logger;\n        }\n        /// <summary>\n        /// 用户注册-发送邮件通知(消费用户注册接口) Topic(\"组件名\",\"主题\")\n        /// </summary>\n        [Topic(\"pubsub\", \"registeruser\")] //订阅用户注册\n        [HttpPost(\"register\")]\n        public string RegisterSendEmailAsync(UserInfoDto dto)\n        {\n           Console.WriteLine(\"=======接收用户注册请求参数======\");\n           Console.WriteLine(JsonSerializer.Serialize(dto));\n           _logger.LogDebug(\"=====================已发送注册成功邮件==========================\");\n           _logger.LogDebug(JsonSerializer.Serialize(dto));\n           var result = $\"欢迎您，{dto.UserName}，您的注册邮箱是：{dto.Email}\";\n           Console.WriteLine(result);\n           return result;\n        }\n    }\n}\n``` \n3）查找订阅主题，在dapr服务器上执行以下命令\n\n``` csharp\n[root@masternode components]# cat /root/.dapr/components/pubsub.yaml\n  apiVersion: dapr.io/v1alpha1\n  kind: Component\n  metadata:\n  name: pubsub\n  spec:\n    type: pubsub.redis\n    version: v1\n    metadata:\n      - name: redisHost\n    value: localhost:6379\n      - name: redisPassword\n    value: \"\"\n``` \n\n4）修改Program.cs|\n\n``` csharp\n//1、集成Dapr，在原来的AddControllers方法之后\nbuilder.Services.AddControllers().AddDapr();\n\n//2、集成Dapr客户端\nbuilder.Services.AddDaprClient();\nvar app = builder.Build();\n\n\n//3、集成Dapr中间件，在app.MapControllers之前\n\napp.UseCloudEvents();\napp.MapSubscribeHandler();\napp.MapControllers();\n```\n\n 5）发布emailmicroservice到Linux，使用Dapr运行。\n\n``` shell\n#测试运行\n[root@masternode emailmicroservice]# dotnet Demos.DaprEmailMicroservice.dll\ninfo: Microsoft.Hosting.Lifetime[14]\n      Now listening on: http://localhost:5000\ninfo: Microsoft.Hosting.Lifetime[0]\n      Application started. Press Ctrl+C to shut down.\ninfo: Microsoft.Hosting.Lifetime[0]\n      Hosting environment: Production\ninfo: Microsoft.Hosting.Lifetime[0]\n      Content root path: /opt/dapr/publish_files/emailmicroservice\n^Cinfo: Microsoft.Hosting.Lifetime[0]\n      Application is shutting down...\n#使用Dapr运行-使用固定端口的方式\n[root@masternode emailmicroservice]# dapr run --app-id emailmicroservice --dapr-http-port 5003 --dapr-grpc-port 5004 --app-port 5000 -- dotnet Demos.DaprEmailMicroservice.dll\n\n#查看运行的项目\n[root@masternode ~]# dapr list\n  APP ID             HTTP PORT  GRPC PORT  APP PORT  COMMAND               AGE  CREATED              DAPRD PID  CLI PID  APP\n  emailmicroservice  5003       5004       5000      dotnet Demos.Dapr...  8s   2025-07-21 01:25.16  31278      31239    31279\n\n#数据调用地址\nhttp://192.168.72.140:5003/v1.0/invoke/emailmicroservice/method/user/register\n\n```\n\n6）使用website测试\n  再websiteIndexController控制器添加调用emailmicroservice服务\n``` csharp\nusing Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nnamespace Demos.DaprWebSite.Controllers\n{\n    /// <summary>\n    /// 用户网站-消息生产端\n    /// </summary>\n    [ApiController]\n    [Route(\"[controller]\")]\n    public class IndexController : ControllerBase\n    {\n        private readonly ILogger<IndexController> _logger;\n        private readonly DaprClient _daprClient;\n        /// <summary>\n        ///\n        /// </summary>\n        /// <param name=\"logger\"></param>\n        /// <param name=\"daprClient\"></param>\n        public IndexController(ILogger<IndexController> logger,\n            DaprClient daprClient)\n        {\n            _logger = logger;\n            _daprClient = daprClient;\n        } \n\n        /// <summary>\n        /// 注册用户\n        /// </summary>\n        [HttpPost]\n        public async Task<string> Post(UserInfoDto dto)\n        {\n            _logger.LogDebug(\"======调用用户注册=====\");\n            //数据调用地址：http://192.168.72.140:5003/v1.0/invoke/emailmicroservice/method/user/register\n            //创建元数据\n            Dictionary<string, string> metadata = new Dictionary<string, string>();\n            metadata.Add(\"dapr-app-id\", \"emailmicroservice\");\n            // 调用用户微服务\n            await _daprClient.PublishEventAsync<UserInfoDto>(\n                \"pubsub\",\n                \"registeruser\",\n                dto,\n                metadata);\n            _logger.LogDebug($\"事件发布成功\");\n            return \"事件发布成功\";\n        }\n    }\n}\n```\n在website站点添加数据 \n![image](https://localhost:7235/ArticleFiles/Image111_20251023105808925.png)\n在emailmicroservice微服务中接收请求数据\n![image](https://localhost:7235/ArticleFiles/Image222_20251023105818559.png)\n在使用Dapr启动emailmicroservice微服务后，Dapr通过Sidecar监听请求，在客户端（web站点）使用DaprClient发送请求后，邮件微服务通过订阅相应的主题和Action实现消费\n\n## 4、云原生开发linux部署\n  使用容器部署Dapr项目和使用dapr部署是有区别的，docker-compose部署时，由于Sidecar容器不是通过主机上的dapr run命令启动，所以dapr list不会显示，推荐使用Kubernetes并使用Dapr的自动注入功能。\n  ### 4.1、创建docker-compose.yaml，这里包含来zipkin，placement，mysql等dapr运行的基础插件，这些插件以容器的方式运行\n``` shell\nversion: \'3.8\'\nservices:\n  usermicroservice:\n    build: .\n    ports:\n      - \"5000:8080\"\n      - \"8085:8085\"\n      - \"9095:9095\"\n    networks:\n      - dapr-network\n    environment:\n      ConnectionStrings__MySQL:  \"Server=mysql;Port=3306;Database=dapr_db;Uid=dapruser;Pwd=123456;\"\n    depends_on:\n      mysql:\n        condition: service_healthy\n  usermicroservice-dapr:\n    image: \"daprio/daprd:1.15.5\"\n    command: [\n        \"./daprd\",\n        \"-app-id\", \"usermicroservice\",\n        \"-app-port\", \"8080\",\n        \"-dapr-http-port\", \"8085\",\n        \"-dapr-grpc-port\", \"9095\",\n        \"-components-path\", \"/components\",\n        \"-config\", \"/config/config.yaml\",\n        \"-placement-host-address\", \"dapr-placement:50005\",\n        \"--log-level\", \"debug\"\n    ]\n    volumes:\n      - ./components:/components\n      - ./config.yaml:/config/config.yaml\n    networks:\n      - dapr-network\n    healthcheck:\n      test: [\"CMD\", \"nc\", \"-z\", \"127.0.0.1\", \"50005\"]\n      interval: 5s\n      timeout: 5s\n      retries: 10\n    depends_on:\n      usermicroservice:\n        condition: service_started\n  redis:\n    container_name: \"demos_redis\"\n    image: \"redis:7-alpine\"\n    ports:\n      - \"6379:6379\"\n    networks:\n      - dapr-network\n  mysql:\n    container_name: \"demos_mysql\"\n    image: mysql:8.0.21\n    ports:\n      - \"3307:3306\"\n    environment:\n      MYSQL_ROOT_PASSWORD: \"zlj@1323\"\n      MYSQL_DATABASE: dapr_db\n      MYSQL_USER: dapruser\n      MYSQL_PASSWORD: \"123456\"\n    volumes:\n      - ./data/mysql_data:/var/lib/mysql\n    networks:\n      - dapr-network\n    healthcheck:\n      test: [\"CMD-SHELL\", \"mysqladmin ping -u root -p$$MYSQL_ROOT_PASSWORD\"]\n      interval: 5s\n      timeout: 5s\n      retries: 10\n  zipkin:\n    container_name: \"demos_zipkin\"\n    image: \"openzipkin/zipkin\"\n    ports:\n      - \"9411:9411\"\n    networks:\n      - dapr-network\n  dapr-placement:\n    container_name: \"demos_dapr_placement\"\n    image: \"daprio/placement:1.15.5\"\n    command: [\"./placement\", \"-port\", \"50005\"]\n    ports:\n      - \"50005:50005\"\n    healthcheck:\n      test: [\"CMD\", \"nc\", \"-z\", \"localhost\", \"50005\"]\n      interval: 5s\n      timeout: 10s\n      retries: 10\n    networks:\n      - dapr-network\nnetworks:\n  dapr-network:\n    driver: bridge\n```\n###   4.2、执行docker-compose\n``` shell\n 生成镜像、运行容器\n docker-compose up \n 构建镜像、运行容器\n  docker-compose up --build\n 停止所有容器\n  docker stop $(docker ps -aq)\n  删除所有停止的容器\n  docker container prune -f (-f表示强制删除、跳过确认）\n```', NULL, 1, 'Dapr，微服务', 1, 0, 45, 0, 0, 0, '1900-01-01 00:00:00', 0, 1002, '2025-10-23 11:12:20', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (29247929175568, 'F1历史上的传奇车手-舒马赫', 'F1世界汇聚了众多传奇车手，他们以辉煌战绩、非凡勇气和独特魅力，在赛车史上留下了深刻印记', '## 初露锋芒与首冠：\n  舒马赫在1991年首次亮相F1，次年便在比利时斯帕赛道拿下了他的第一个分站赛冠军。在贝纳通车队时期，他于1994和1995年连续夺得两次世界冠军，正式开启了他的冠军之路。关于他早年冠军的具体竞争对手，目前的搜索结果中没有非常明确的记载。\n\n## 法拉利的辉煌王朝：\n转投法拉利后，经过几年的磨合，舒马赫从2000年至2004年实现了史无前例的车手五连冠，这无疑是他职业生涯中最鼎盛的时期。其中，2000年的冠军可以看作是他为法拉利重新夺回荣耀的里程碑。在法拉利时期，舒马赫曾与多位优秀车手激烈竞争，例如在2006赛季，他与当时效力雷诺车队的费尔南多·阿隆索争夺年度总冠军，最终阿隆索成功卫冕。\n\n## 两次退役与接替者\n\n###第一次退役（2006年）：\n舒马赫在2006赛季结束后首次宣布退役。法拉利车队确认由来自迈凯伦车队的基米·莱科宁接替他的车手席位，莱科宁也在次年（2007年）为法拉利赢得了车手总冠军。\n\n### 复出与再次退役（2012年）：\n在休息了三年后，舒马赫于2010年复出，加盟梅赛德斯GP车队。经过三个赛季，他于2012年赛季结束后再次、也是永久地退出了F1。他退役后，梅赛德斯车队的席位由刘易斯·汉密尔顿接任。', NULL, 1, 'F1赛车', 1, 0, 31, 0, 0, 0, '1900-01-01 00:00:00', 0, 4, '2025-10-23 12:01:02', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (29251842130960, '田径短跑传奇-博尔特', '博尔特是牙买加运动员', '## 锋芒与首冠：\n  舒在1991年首次亮相F1，次年便在比利时斯帕赛道拿下了他的第一个分站赛冠军。在贝纳通车队时期，他于1994和1995年连续夺得两次世界冠军，正式开启了他的冠军之路。关于他早年冠军的具体竞争对手，目前的搜索结果中没有非常明确的记载。', NULL, 2, '博尔特，田径', 1, 0, 61, 0, 0, 0, '1900-01-01 00:00:00', 0, 1006, '2025-10-23 14:08:24', 'zhenglijun', '2025-10-23 14:35:49', 'zhenglijun', 0);
INSERT INTO `blogs_article` VALUES (29311946392080, '微服务链路监控！', '链路监控是微服务项目研发中重要的一环', '# 技术文档示例\n\n## 简介\n\n这是一篇技术文章的示例模板，展示了 **Markdown** 的常用语法和排版效果。您可以参考这个模板来编写自己的文章。\n\n### 文本格式\n\n- **加粗文本**：使用 `**文本**`\n- *斜体文本*：使用 `*文本*`\n- <u>下划线</u>：使用 `<u>文本</u>`\n- ~~删除线~~：使用 `~~文本~~`\n\n### 列表\n\n**无序列表：**\n- 第一项\n- 第二项\n  - 子项 1\n  - 子项 2\n- 第三项\n\n**有序列表：**\n1. 第一步\n2. 第二步\n3. 第三步\n\n## 代码示例\n\n### JavaScript 代码块\n\n```javascript\n// React 函数组件示例\nfunction HelloWorld({ name }) {\n  const [count, setCount] = useState(0);\n  \n  return (\n    <div className=\"hello\">\n      <h1>Hello, {name}!</h1>\n      <button onClick={() => setCount(count + 1)}>\n        Clicked {count} times\n      </button>\n    </div>\n  );\n}\n```\n\n### Python 代码块\n\n```python\ndef fibonacci(n):\n    \"\"\"计算斐波那契数列\"\"\"\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\n# 输出前 10 个数\nfor i in range(10):\n    print(f\"F({i}) = {fibonacci(i)}\")\n```\n\n### 行内代码\n\n在文本中使用 `const x = 10;` 这样的行内代码。\n\n## 图片展示\n\n![React Logo](https://upload.wikimedia.org/wikipedia/commons/a/a7/React-icon.svg)\n\n*图片说明：React 官方 Logo*\n\n## 链接\n\n- [React 官方文档](https://react.dev)\n- [MDN Web Docs](https://developer.mozilla.org)\n- [GitHub](https://github.com)\n\n## 表格\n\n| 特性 | React | Vue | Svelte |\n|------|-------|-----|--------|\n| 虚拟DOM | ✓ | ✓ | ✗ |\n| TypeScript | ✓ | ✓ | ✓ |\n| 生态系统 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ |\n| 学习曲线 | 中 | 低 | 低 |\n\n## 引用\n\n> “代码质量不仅仅是关于功能，更是关于可读性和可维护性。”\n> \n> —— Robert C. Martin\n\n## 注意事项\n\n⚠️ **重要：**请确保代码的安全性和性能。\n\n✅ **提示：**使用 ESLint 和 Prettier 保持代码风格统一。\n\n## 总结\n\n本文展示了 Markdown 的常用语法，包括：\n\n1. 标题和段落\n2. 文本格式化\n3. 列表和代码块\n4. 图片和链接\n5. 表格和引用\n\n希望这个示例能帮助您快速上手 Markdown 编写！', NULL, 2, 'Skywallking', 1, 0, 28, 0, 0, 0, '1900-01-01 00:00:00', 0, 1002, '2025-10-24 22:44:55', 'zhenglijun', '2025-10-28 19:46:11', 'zhenglijun', 0);
INSERT INTO `blogs_article` VALUES (29528043178000, 'Golang学习第一天', 'Go语言简介，环境搭建，第一个Hello World，了解Go的工具链', '## 1. Go语言简介\n### Go vs C#\n|特性	|Go	 |C#\n编译方式	静态编译为单个二进制文件	编译为IL，需要运行时\n并发模型	Goroutine + Channel	async/await + Task\n类型系统	结构体 + 接口(隐式)	类 + 接口(显式)\n继承	组合替代继承	类继承\n错误处理	多返回值错误处理	异常机制\n依赖管理	Go Modules	NuGet\n## 2. 环境搭建\nWindows环境安装\n``` bash\n1-下载Go安装包 https://golang.org/dl/\n2- 安装到 C:\\Go\n3- 验证安装\ngo version \n4-配置环境变量(可选)\nsetx GOPATH C:\\Users\\YourName\\go\nsetx PATH \"%PATH%;C:\\Go\\bin\"\n开发工具推荐\nVSCode: 安装Go扩展\nGoLand: JetBrains的专门IDE\nVS: 安装Go扩展\n```\n## 3. 第一个Hello World\n项目结构\n```\ntext\nhello-world/\n├── go.mod          # 模块定义文件(类似.csproj)\n├── main.go         # 主程序文件\n└── README.md\n创建项目\nbash\n创建项目目录\nmkdir hello-world\ncd hello-world\n初始化Go模块(重要!)\ngo mod init hello-world\n编写第一个程序: main.go\ngo\npackage main  // 包声明，main包表示可执行程序\nimport (\n    \"fmt\"      // 导入包，类似C#的using\n    \"time\"\n)\n// main函数是程序入口，类似C#的Main方法\nfunc main() {\n    // 基本的Hello World\n    fmt.Println(\"Hello, World! Welcome to Go!\")\n    \n    // 对比C#的DateTime.Now\n    currentTime := time.Now()\n    fmt.Printf(\"Current time: %s\\n\", currentTime.Format(\"2006-01-02 15:04:05\"))\n    \n    // 调用自定义函数\n    showDotNetComparison()\n}\n// 自定义函数演示\nfunc showDotNetComparison() {\n    fmt.Println(\"\\n--- Go vs C# 对比 ---\")\n    \n    // 变量声明对比\n    var message string = \"Hello from Go\"\n    shortMessage := \"Short declaration\"  // 类型推断，类似C#的var\n    \n    fmt.Println(message)\n    fmt.Println(shortMessage)\n    \n    // 数组/切片演示\n    numbers := []int{1, 2, 3, 4, 5}  // 类似C#的List<int>\n    fmt.Printf(\"Numbers: %v\\n\", numbers)\n    \n    // 循环演示\n    fmt.Println(\"Looping through numbers:\")\n    for i, num := range numbers {  // 类似C#的foreach\n        fmt.Printf(\"Index: %d, Value: %d\\n\", i, num)\n    }\n}\n运行程序\nbash\n方式1: 直接运行(类似dotnet run)\ngo run main.go\n方式2: 编译后运行(类似dotnet build + 运行exe)\ngo build\n./hello-world.exe  # Windows\n./hello-world      # Linux/Mac\n```\n## 4. Go工具链详解\n核心命令对比\n``` \nGo命令	C#对应命令	功能描述\ngo run	dotnet run	编译并运行\ngo build	dotnet build	编译项目\ngo mod init	dotnet new	创建新项目\ngo get	dotnet add package	添加依赖\ngo test	dotnet test	运行测试\n实践练习：深入了解工具链\n创建更完整的示例项目\n创建文件 utils/calculator.go:\n\ngo\npackage utils\n\nimport \"fmt\"\n\n// 公开函数(首字母大写)\nfunc Add(a, b int) int {\n    return a + b\n}\n\nfunc Multiply(a, b int) int {\n    return a * b\n}\n\n// 私有函数(首字母小写)\nfunc printResult(result int) {\n    fmt.Printf(\"Result: %d\\n\", result)\n}\n\n// 演示多返回值(Go特色)\nfunc Divide(a, b int) (int, error) {\n    if b == 0 {\n        return 0, fmt.Errorf(\"division by zero\")\n    }\n    return a / b, nil\n}\n修改 main.go 添加新功能:\n\ngo\npackage main\n\nimport (\n    \"fmt\"\n    \"hello-world/utils\"  // 导入本地包\n)\n\nfunc main() {\n    fmt.Println(\"=== Go工具链演示 ===\")\n    \n    // 使用自定义包\n    sum := utils.Add(10, 5)\n    product := utils.Multiply(4, 3)\n    \n    fmt.Printf(\"10 + 5 = %d\\n\", sum)\n    fmt.Printf(\"4 * 3 = %d\\n\", product)\n    \n    // 多返回值错误处理\n    result, err := utils.Divide(10, 2)\n    if err != nil {\n        fmt.Printf(\"Error: %v\\n\", err)\n    } else {\n        fmt.Printf(\"10 / 2 = %d\\n\", result)\n    }\n    \n    // 错误情况\n    _, err = utils.Divide(10, 0)\n    if err != nil {\n        fmt.Printf(\"Expected error: %v\\n\", err)\n    }\n}\n工具链命令实践\nbash\n1. 查看Go环境配置\ngo env\n 2. 格式化代码(类似C#的格式化文档)\ngo fmt ./...\n3. 查看模块信息\ngo mod tidy    # 整理依赖\ngo list -m all # 查看所有依赖\n4. 获取外部包(演示)\ngo get -v github.com/gin-gonic/gin\n5. 编译为不同平台\nGOOS=windows GOARCH=amd64 go build  # 交叉编译到Windows\n完整的go.mod文件示例\nmod\nmodule hello-world\ngo 1.21\nrequire (\n    github.com/gin-gonic/gin v1.9.1\n)\n```\n// 类似C#的.csproj文件，但更简洁\n## 5. 今日练习任务\n基础任务\n✅ 成功安装Go并验证版本\n✅ 创建第一个Hello World程序并运行\n✅ 使用go build生成可执行文件\n✅ 理解go.mod文件的作用\n进阶挑战\ngo\n``` \n// 尝试将以下C#代码转换为Go\n// C#代码:\n/*\nusing System;\nusing System.Collections.Generic;\n\nclass Program {\n    static void Main() {\n        List<string> names = new List<string> { \"Alice\", \"Bob\", \"Charlie\" };\n        foreach (var name in names) {\n            if (name.Length > 4) {\n                Console.WriteLine($\"Hello, {name}!\");\n            }\n        }\n    }\n}\n*/\n\n// 你的Go实现:\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    // 在这里实现Go版本\n    names := []string{\"Alice\", \"Bob\", \"Charlie\"}\n    \n    // 实现过滤和打印逻辑\n    for _, name := range names {\n        if len(name) > 4 {\n            fmt.Printf(\"Hello, %s!\\n\", name)\n        }\n    }\n}\n``` \n## 6. 常见问题解决\n环境问题\n``` bash\n如果go命令找不到\nWindows: 检查PATH是否包含C:\\Go\\bin\nMac/Linux: 检查是否在PATH中\n模块初始化失败\ngo env -w GO111MODULE=on\n导入问题\ngo\n// 本地包导入注意\nimport \"your-module-name/utils\"  // 使用go mod init的名称\n学习要点总结\n环境搭建: Go安装简单，不需要复杂的运行时配置\n模块系统: Go Modules是现代Go项目的标准依赖管理\n工具链: Go命令简洁一致，学习曲线平缓\n语法特点: 注意与C#的主要差异，特别是错误处理和并发模型\n```', NULL, 2, 'Golang', 1, 0, 19, 0, 0, 0, '1900-01-01 00:00:00', 0, 1001, '2025-10-29 19:59:19', 'zhenglijun', '2025-10-30 07:53:01', 'zhenglijun', 0);
INSERT INTO `blogs_article` VALUES (29562454879760, '领域通知在CQRS项目中的实战', '收集命令模型和查询执行器中抛出的异常、领域通知、错误信息等，将其归并为统一的格式并返还给前端', '## 使用中间件处理领域通知错误，统一返回格式', NULL, 1, 'DDD，领域通知，异常处理', 1, 0, 6, 0, 0, 0, '1900-01-01 00:00:00', 0, 1001, '2025-10-30 14:39:30', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (29604489367568, '关于发散性思维以及推导关联性思维', '想法瞬息万变，但是能抓住并逐步延伸思考下去很难，可以通过片段、阶段性提示来延伸思维', '#  关于发散性思维和专注性思维\n## 第一部分：人脑思考的基本模式\n\n人脑的思考不是一个单一的、线性的过程，而是一个复杂的、动态的网络活动。它大致可以看作两种基本思维模式的交替与协作：\n\n为了理解它们，我们可以用一个经典的比喻：手电筒的光束。\n\n专注模式 就像一束聚焦、明亮的光柱。它直接照射在一个明确的目标上，光线集中，视野清晰但狭窄。你用这种模式进行逻辑推理、数学计算、执行已知步骤。\n\n发散模式 就像一束散射、柔和的光。它照亮一大片区域，光线微弱但范围广。它让你能够连接看似不相关的想法，产生新奇的联想，是灵感和创造力的源泉。\n\n关键点在于： 我们的大脑会在这两种模式之间不断切换，你无法同时高效地使用它们。\n\n## 第二部分：深度解析两种思维模式\n### 1. 发散性思维\n定义：一种“天马行空”、非线性的思考方式。它的目标是产生尽可能多的、多样的想法和可能性，而不急于判断对错。\n\n特点：\n\n自由联想：从一个点出发，想到什么就是什么，允许思维“跑题”。\n\n延迟评判：在产生想法阶段，不进行批判，追求数量而非质量。\n\n非线性：想法之间是网状连接，而非直线连接。\n\n神经基础：当大脑处于放松、走神的状态时（比如洗澡、散步、做梦），默认模式网络会被激活。这个网络广泛连接大脑的不同区域，是发散思维的主要神经基础。它允许距离很远的脑区进行“对话”。\n\n应用场景：\n\n头脑风暴会议。\n\n寻找创作灵感（写作、艺术、设计）。\n\n解决开放式问题（“我们如何改善用户体验？”）。\n\n思考人生方向等宏大议题。\n\n### 2. 专注性思维\n定义：一种“目标导向”、集中的思考方式。它调用你的注意力、知识和逻辑，朝着一个明确的解决方案前进。\n\n特点：\n\n高度集中：注意力资源被集中在特定任务上，屏蔽外界干扰。\n\n逻辑与序列：遵循已知的规则和步骤，一步接一步。\n\n批判性判断：对信息和方案进行分析、评估和筛选。\n\n神经基础：主要与前额叶皮层相关，这是大脑的“指挥中心”，负责执行功能，如计划、决策和注意力控制。\n\n应用场景：\n\n解数学题或进行逻辑推理。\n\n学习新知识并理解其内在逻辑。\n\n执行一个熟悉的流程（如开车、做饭）。\n\n在考试中答题。\n\n## 第三部分：两种思维的动态协作——创造性解决问题的核心\n真正强大的思考能力，不在于单独使用哪一种模式，而在于如何巧妙地让它们协同工作。这个过程通常遵循一个清晰的循环：\n\n### 1. 准备阶段 -> 专注模式\n你首先需要深入理解问题，收集信息，并尝试用已有的知识和逻辑（专注模式）去解决它。这相当于“努力思考”。\n\n### 2. 僵局与酝酿阶段 -> 切换到发散模式\n当专注模式走入死胡同时，你会感到“卡住了”。此时，最好的策略是主动停止思考这个问题。去散步、洗澡、听音乐、睡觉。这实际上是将问题从意识层面交给了潜意识，切换到了发散模式。你的大脑开始在后台默默地、广泛地连接各种信息。\n\n### 3. 顿悟阶段 -> 发散模式的成果\n突然间，一个意想不到的灵感或解决方案“灵光一现”地闯入你的脑海。这就是著名的“尤里卡时刻”（阿基米德在浴缸里发现浮力定律的时刻）。这是发散模式工作的成果，它建立了一个你之前从未想到过的神经连接。\n\n### 4. 验证与完善阶段 -> 回归专注模式\n你捕捉到那个灵感后，需要再次回到专注模式。用逻辑和批判性思维去验证这个想法的可行性，打磨细节，将其变成一个切实可行的方案。\n\n一个经典的例子：阿基米德与皇冠\n\n准备/专注：国王交给阿基米德一个任务：检验皇冠是否是纯金的，不能破坏皇冠。他苦苦思索（专注模式），尝试了各种已知的密度测量方法，都失败了。\n\n僵局/酝酿：他感到疲惫，决定去洗个澡（切换到发散模式）。当他躺进浴缸时，看到水溢出来。\n\n顿悟：在放松的状态下，他瞬间将“身体浸入浴缸”和“排开的水的体积”联系了起来（发散模式建立连接），从而发现了浮力原理，并大喊“尤里卡！”（我发现了！）。\n\n验证/专注：他回到实验室，用这个新原理进行严谨的实验（回归专注模式），最终证明了皇冠并非纯金。\n\n## 第四部分：如何善用这两种思维，提升思考力？\n有意识地安排“专注时间”和“发散时间”\n\n专注时间：使用“番茄工作法”（25分钟专注，5分钟休息）。在专注时段内，屏蔽所有干扰。\n\n发散时间：主动安排休息。散步、冥想、从事一些不需要动脑的重复性活动（如整理房间、织毛衣）。创造力往往诞生于“不思考”的时刻。\n\n为发散思维创造土壤\n\n广泛涉猎：阅读不同领域的书籍，接触不同文化。你拥有的知识“积木”越多，发散思维能搭建出的新奇组合就越多。\n\n记录灵感：随时用笔记App或小本子记录下任何突如其来的想法，无论它当时看起来多么荒谬。\n\n遇到难题时，懂得“放手”\n\n当你对一个难题绞尽脑汁也无解时，请告诉自己：“是时候切换到发散模式了。” 去睡一觉，这往往是解决问题最有效的方法之一。\n\n利用身体活动\n\n运动，尤其是散步和跑步，被证明能极大地促进发散性思维。很多伟大的思想家（如乔布斯、贝多芬）都有散步思考的习惯。\n\n## 总结\n人类的思考是一个精妙的双模式系统：\n\n发散性思维是探索者，它漫游于未知领域，负责“产生想法”。\n\n专注性思维是执行者，它在已知领域深耕，负责“验证和执行想法”。\n\n真正的智慧，不在于永远保持专注，而在于懂得何时该专注攻坚，何时该放松放手，让潜意识里的广阔网络为你工作。理解并驾驭这两种思维的节奏，是提升创造力、学习效率和解决问题能力的关键。', NULL, 1, '思维', 1, 0, 2, 0, 0, 0, '1900-01-01 00:00:00', 0, 1006, '2025-10-31 13:27:48', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (29697471143952, '111', '222', '# 技术文档示例\n\n## 简介\n\n这是一篇技术文章的示例模板，展示了 **Markdown** 的常用语法和排版效果。您可以参考这个模板来编写自己的文章。\n\n### 文本格式\n\n- **加粗文本**：使用 `**文本**`\n- *斜体文本*：使用 `*文本*`\n- <u>下划线</u>：使用 `<u>文本</u>`\n- ~~删除线~~：使用 `~~文本~~`\n\n### 列表\n\n**无序列表：**\n- 第一项\n- 第二项\n  - 子项 1\n  - 子项 2\n- 第三项\n\n**有序列表：**\n1. 第一步\n2. 第二步\n3. 第三步\n\n## 代码示例\n\n### JavaScript 代码块\n\n```javascript\n// React 函数组件示例\nfunction HelloWorld({ name }) {\n  const [count, setCount] = useState(0);\n  \n  return (\n    <div className=\"hello\">\n      <h1>Hello, {name}!</h1>\n      <button onClick={() => setCount(count + 1)}>\n        Clicked {count} times\n      </button>\n    </div>\n  );\n}\n```\n\n### Python 代码块\n\n```python\ndef fibonacci(n):\n    \"\"\"计算斐波那契数列\"\"\"\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\n# 输出前 10 个数\nfor i in range(10):\n    print(f\"F({i}) = {fibonacci(i)}\")\n```\n\n### 行内代码\n\n在文本中使用 `const x = 10;` 这样的行内代码。\n\n## 图片展示\n\n![React Logo](https://upload.wikimedia.org/wikipedia/commons/a/a7/React-icon.svg)\n\n*图片说明：React 官方 Logo*\n\n## 链接\n\n- [React 官方文档](https://react.dev)\n- [MDN Web Docs](https://developer.mozilla.org)\n- [GitHub](https://github.com)\n\n## 表格\n\n| 特性 | React | Vue | Svelte |\n|------|-------|-----|--------|\n| 虚拟DOM | ✓ | ✓ | ✗ |\n| TypeScript | ✓ | ✓ | ✓ |\n| 生态系统 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ |\n| 学习曲线 | 中 | 低 | 低 |\n\n## 引用\n\n> “代码质量不仅仅是关于功能，更是关于可读性和可维护性。”\n> \n> —— Robert C. Martin\n\n## 注意事项\n\n⚠️ **重要：**请确保代码的安全性和性能。\n\n✅ **提示：**使用 ESLint 和 Prettier 保持代码风格统一。\n\n## 总结\n\n本文展示了 Markdown 的常用语法，包括：\n\n1. 标题和段落\n2. 文本格式化\n3. 列表和代码块\n4. 图片和链接\n5. 表格和引用\n\n希望这个示例能帮助您快速上手 Markdown 编写！', NULL, 1, '333', 1, 0, 7, 0, 0, 0, '1900-01-01 00:00:00', 0, 1002, '2025-11-02 15:54:33', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (29700677308944, '111111', '22222', 'bb', NULL, 1, 'aa', 1, 0, 3, 0, 0, 0, '1900-01-01 00:00:00', 0, 10001, '2025-11-02 17:38:55', 'admin', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (29712124994064, 'AAAAAAAAA', '11111111111111', '<pre class=\"ql-syntax\" spellcheck=\"false\">## 冈仁波齐山\n</pre><p>11111111111</p><p><br></p><p><br></p><p>2</p><p><br></p><p><br></p><p>33</p><p>3</p><p>4</p><p>4</p><p>4</p><p>5</p><p>5</p><p><br></p><p>66</p>', NULL, 1, 'NetCore', 1, 0, 17, 0, 0, 0, '1900-01-01 00:00:00', 0, 1003, '2025-11-02 23:51:35', 'admin', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (29713320001040, 'AbpVnext日志模块ELK存储搭建', '999999999999999999', '<h1>AbpVnext 日志模块</h1><h2>1、概念：</h2><p>&nbsp;&nbsp;日志组件通过<span style=\"color: rgb(51, 51, 51);\">使用MMicrosoft.Extensions.Logging将日志输出到控制台、文件、数据库等，同时进行自定义日志输出。</span></p><p><br></p><h2><span style=\"color: rgb(51, 51, 51);\">2、日志组件集成</span></h2><p><span style=\"color: rgb(51, 51, 51);\">&nbsp;2.1、创建控制台项目</span></p><pre class=\"ql-syntax\" spellcheck=\"false\">PS D:\\workspace\\code\\ZLJ.DotNetDemos\\03-loggers&gt; dotnet new console -n Demo_Logging_MongoDbTest&nbsp;&nbsp;&nbsp;\n已成功创建模板“控制台应用”。\n\n\n正在处理创建后操作...\n正在还原 D:\\workspace\\code\\ZLJ.DotNetDemos\\03-loggers\\Demo_Logging_MongoDbTest\\Demo_Logging_MongoDbTest.csproj:\n&nbsp;&nbsp;Determining projects to restore...\n&nbsp;&nbsp;已还原 D:\\workspace\\code\\ZLJ.DotNetDemos\\03-loggers\\Demo_Logging_MongoDbTest\\Demo_Logging_MongoDbTest.csproj (用时 25.68 秒)。\n已成功还原。\n</pre><p><br></p><p><span style=\"color: rgb(51, 51, 51);\">2.2、安装nuget包</span></p><pre class=\"ql-syntax\" spellcheck=\"false\">&nbsp;1）使用命令dotnet add package xxx 依次安装 Microsoft.Extensions.Logging、Microsoft.Extensions.Logging.Console、MongoDB.Driver、Serilog 、Serilog.Sinks.MongoDB。\nPS D:\\workspace\\code\\ZLJ.DotNetDemos\\03-loggers\\Demo_Logging_MongoDbTest&gt; dotnet add package Microsoft.Extensions.Logging\n&nbsp;&nbsp;Determining projects to restore...\n&nbsp;&nbsp;Writing C:\\Users\\Administrator\\AppData\\Local\\Temp\\tmpeg2yt0.tmp\ninfo : X.509 证书链验证将使用 .NET 选择的默认信任存储进行代码签名。\n</pre><p><span style=\"color: rgb(51, 51, 51);\">&nbsp;&nbsp;</span></p><p><span style=\"color: rgb(51, 51, 51);\">&nbsp;2）直接修改Csproj文件实现安装</span></p><pre class=\"ql-syntax\" spellcheck=\"false\">&lt;ItemGroup&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&lt;PackageReference Include=\"Karambolo.Extensions.Logging.File\" Version=\"3.5.0\" /&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&lt;PackageReference Include=\"Microsoft.Extensions.Configuration\" Version=\"8.0.0\" /&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&lt;PackageReference Include=\"Microsoft.Extensions.Configuration.Binder\" Version=\"8.0.0\" /&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&lt;PackageReference Include=\"Microsoft.Extensions.Configuration.Json\" Version=\"8.0.0\" /&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&lt;PackageReference Include=\"Microsoft.Extensions.Logging\" Version=\"8.0.0\" /&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&lt;PackageReference Include=\"Microsoft.Extensions.Logging.Console\" Version=\"8.0.0\" /&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&lt;PackageReference Include=\"MongoDB.Driver\" Version=\"2.27.0\" /&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&lt;PackageReference Include=\"Serilog\" Version=\"4.0.0\" /&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&lt;PackageReference Include=\"Serilog.Sinks.MongoDB\" Version=\"5.4.1\" /&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&lt;PackageReference Include=\"MySqlConnector\" Version=\"2.3.7\" /&gt;\n&lt;/ItemGroup&gt;\n</pre><p><br></p><p><span style=\"color: rgb(51, 51, 51);\">2.3、修改appsettings.json配置文件，配置数据库连接</span></p><pre class=\"ql-syntax\" spellcheck=\"false\">{\n&nbsp;&nbsp;\"MySqlConn\":&nbsp;&nbsp;\"server=localhost;port=3306;database=zlj_dotnetdemos;user=root;password=123456;\",\n&nbsp;&nbsp;\"MongodbConn\":&nbsp;&nbsp;\"mongodb://localhost:27017/?readPreference=primary&amp;appname=MongoDB%20Compass&amp;ssl=false\",\n&nbsp;&nbsp;\"File\": {\n&nbsp;&nbsp;&nbsp;&nbsp;\"Path\": \"logs/log.txt\",\n&nbsp;&nbsp;&nbsp;&nbsp;\"MaxFileSize\": 10485760 // 10 MB in bytes\n&nbsp;&nbsp;}\n}\n</pre><p><br></p><h2><span style=\"color: rgb(51, 51, 51);\">3、集成MySQL，将日志保存到日志文件同时保存到MySQL</span></h2><p><span style=\"color: rgb(51, 51, 51);\">&nbsp;3.1、创建MySQL日志实现类MySQLogger.cs，实现ILogger接口</span></p><pre class=\"ql-syntax\" spellcheck=\"false\">namespace Demo_Logging_MongoDbTest.Extensions\n{\n&nbsp;&nbsp;&nbsp;&nbsp;public class MySQLogger: ILogger\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public string _connectionString { set; get; }\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public MySQLogger(string connectionString)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_connectionString = connectionString;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public IDisposable? BeginScope&lt;TState&gt;(TState state) where TState : notnull\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return null;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public bool IsEnabled(LogLevel logLevel)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return true;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;///&nbsp;&nbsp;1、将日志写到MySQL\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"TState\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"logLevel\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"eventId\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"state\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"exception\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"formatter\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;exception cref=\"NotImplementedException\"&gt;&lt;/exception&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public void Log&lt;TState&gt;(LogLevel logLevel, EventId eventId, TState state,&nbsp;&nbsp;Exception? exception, Func&lt;TState, Exception?, string&gt; formatter)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (!IsEnabled(logLevel))\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// 格式化日志消息\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var message = formatter(state, exception);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// 将日志消息写入MySQL数据库\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;using (var connection = new MySqlConnection(_connectionString))\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var command = connection.CreateCommand();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;command.CommandText = \"INSERT INTO Demo_Logs (Message, LogLevel,&nbsp;&nbsp;CreatedTime) VALUES (@message, @logLevel, @createdTime)\";\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;command.Parameters.AddWithValue(\"@message\", message);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;command.Parameters.AddWithValue(\"@logLevel\", logLevel.ToString());\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;command.Parameters.AddWithValue(\"@createdTime\", DateTime.UtcNow);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;connection.Open();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;command.ExecuteNonQuery();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;}\n}\n</pre><p><br></p><p><span style=\"color: rgb(51, 51, 51);\">&nbsp;3.2、创建日志组件提供者MySQLLoggerProvider.cs</span></p><pre class=\"ql-syntax\" spellcheck=\"false\">namespace Demo_Logging_MongoDbTest.Extensions\n{\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// MySQL日志组件提供者接口\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public class MySQLLoggerProvider : ILoggerProvider\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;private string _connectionString;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public MySQLLoggerProvider(string connectionString)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_connectionString = connectionString;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// 提供MySQL日志\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"categoryName\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public ILogger CreateLogger(string categoryName)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return new MySQLogger(_connectionString);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public void Dispose()\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;}\n}\n</pre><p><br></p><p><span style=\"color: rgb(51, 51, 51);\">&nbsp;3.3、创建日志扩展类</span></p><pre class=\"ql-syntax\" spellcheck=\"false\">namespace Demo_Logging_MongoDbTest.Extensions\n{\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// MySql日志扩展类\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public static class MySqlExtensions\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public static ILoggingBuilder AddMySQL(this ILoggingBuilder builder,string&nbsp;&nbsp;connectionString)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;builder.AddProvider(new MySQLLoggerProvider(connectionString));\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return builder;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;}\n}\n</pre><p><br></p><p>&nbsp;3.4、集成MySQL日志写入（Program.cs）</p><pre class=\"ql-syntax\" spellcheck=\"false\">static void Main(string[] args)\n{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#region 2、数据库日志存储\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//var configuration = new ConfigurationBuilder()\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;.SetBasePath(Directory.GetCurrentDirectory())\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;.AddJsonFile(\"appsettings.json\")\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;.Build();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//var mysqlConn = configuration.GetSection(\"MySqlConn\").Get&lt;string&gt;();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//var mongodbConn = configuration.GetSection(\"MongodbConn\").Get&lt;string&gt;();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//ILoggerFactory loggerFactory = LoggerFactory.Create(builder =&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;//1、控制台输入\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;builder.AddConsole().SetMinimumLevel(LogLevel.Warning);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;//2、日志文件输出\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;builder.AddFile(options =&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//2.1、配置文件目录\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;options.RootPath = AppContext.BaseDirectory;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//2.2、配置文件路径\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;options.Files = new[]\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new LogFileOptions\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path = \"logs/log.txt\"\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;};\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;});\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;//3、集成MySql\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;builder.AddMySQL(mysqlConn);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;//4、集成MongoDb\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;builder.AddMongoDB(mongodbConn);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//});\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//ILogger&lt;Program&gt; logger = loggerFactory.CreateLogger&lt;Program&gt;();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;////输出日志\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//logger.LogInformation(\"Hellorr MySql LogInformation...\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//logger.LogDebug(\"Hellorr MySql LogDebug...\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//logger.LogWarning(\"Hellorr MySql LogWarning...\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//logger.LogError(\"Hellorr MySql LogError...\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//Console.ReadKey();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#endregion\n&nbsp;&nbsp;\n}\n</pre><h2><br></h2><h2><span style=\"color: rgb(51, 51, 51);\">&nbsp;4、集成Mongodb日志写入</span></h2><p><span style=\"color: rgb(51, 51, 51);\">&nbsp;4.1、创建Mongodb数据库操作类MongoDBHelper.cs，这个类用于操作Mongodb数据库增删改查</span></p><pre class=\"ql-syntax\" spellcheck=\"false\">public class MongoDBHelper\n{\n&nbsp;&nbsp;&nbsp;&nbsp;private string databaseName = string.Empty;\n&nbsp;&nbsp;&nbsp;&nbsp;private IMongoClient client = null;\n&nbsp;&nbsp;&nbsp;&nbsp;private IMongoDatabase database = null;\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;public MongoDBHelper(string connectionString)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;client = new MongoClient(connectionString);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;public MongoDBHelper(string connectionString, string databaseName)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;client = new MongoClient(connectionString);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database = client.GetDatabase(databaseName);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;public string DatabaseName\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;get { return databaseName; }\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;set\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;databaseName = value;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database = client.GetDatabase(databaseName);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 执行命令，命令请参考MongoCommand,命令太多，不一一展示，传入的就是里面的字符串，有些命令执行需要连接到admin表\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"cmdText\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public BsonDocument RunCommand(string cmdText)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return database.RunCommand&lt;BsonDocument&gt;(cmdText);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;BsonDocument&gt; GetDatabase()\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return client.ListDatabases().ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;#region SELECT\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 判断文档存在状态\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filterexist\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public bool IsExistDocument&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return database.GetCollection&lt;T&gt;(documentname).Count(filter) &gt; 0;\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过条件得到查询的结果个数\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filter\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public long GetCount&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return database.GetCollection&lt;T&gt;(documentname).Count(filter);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过系统id(ObjectId)获取一个对象\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"id\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public T GetDocumentById&lt;T&gt;(string documentname, string id)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ObjectId oid = ObjectId.Parse(id);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var filter = Builders&lt;T&gt;.Filter.Eq(\"_id\", oid);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var result = database.GetCollection&lt;T&gt;(documentname).Find(filter);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return result.FirstOrDefault();\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过系统id(ObjectId)获取一个对象同时过滤字段\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"id\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"fields\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public T GetDocumentById&lt;T&gt;(string documentname, string id, ProjectionDefinition&lt;T&gt; fields)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ObjectId oid = ObjectId.Parse(id);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var filter = Builders&lt;T&gt;.Filter.Eq(\"_id\", oid);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return database.GetCollection&lt;T&gt;(documentname).Find(filter).Project&lt;T&gt;(fields).FirstOrDefault();\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过指定的条件获取一个对象，如果有多条，只取第一条，同时过滤字段\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filter\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"fields\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public T GetDocumentByUserFilter&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter, ProjectionDefinition&lt;T&gt; fields)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return database.GetCollection&lt;T&gt;(documentname).Find(filter).Project&lt;T&gt;(fields).FirstOrDefault();\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 获取全部文档\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;T&gt; GetAllDocuments&lt;T&gt;(string documentname)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var filter = Builders&lt;T&gt;.Filter.Empty;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return database.GetCollection&lt;T&gt;(documentname).Find(filter).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 获取全部文档同时过滤字段\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"fields\"&gt;要获取的字段&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;T&gt; GetAllDocuments&lt;T&gt;(string documentname, ProjectionDefinition&lt;T&gt; fields)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var filter = Builders&lt;T&gt;.Filter.Empty;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return database.GetCollection&lt;T&gt;(documentname).Find(filter).Project&lt;T&gt;(fields).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过一个条件获取对象\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"property\"&gt;字段名&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"value\"&gt;字段值&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;T&gt; GetDocumentsByFilter&lt;T&gt;(string documentname, string property, string value)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FilterDefinition&lt;T&gt; filter = Builders&lt;T&gt;.Filter.Eq(property, value);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return database.GetCollection&lt;T&gt;(documentname).Find(filter).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过条件获取对象\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filter\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;T&gt; GetDocumentsByFilter&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return database.GetCollection&lt;T&gt;(documentname).Find(filter).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过条件获取对象,同时过滤字段\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"property\"&gt;字段名&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"value\"&gt;字段值&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"fields\"&gt;要获取的字段&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;T&gt; GetDocumentsByFilter&lt;T&gt;(string documentname, string property, string value, ProjectionDefinition&lt;T&gt; fields)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FilterDefinition&lt;T&gt; filter = Builders&lt;T&gt;.Filter.Eq(property, value);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return database.GetCollection&lt;T&gt;(documentname).Find(filter).Project&lt;T&gt;(fields).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过条件获取对象,同时过滤数据和字段\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filter\"&gt;过滤器&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"fields\"&gt;要获取的字段&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;T&gt; GetDocumentsByFilter&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter, ProjectionDefinition&lt;T&gt; fields)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return database.GetCollection&lt;T&gt;(documentname).Find(filter).Project&lt;T&gt;(fields).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过条件获取分页的文档并排序\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filter\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"sort\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"pageIndex\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"pageSize\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;T&gt; GetPagedDocumentsByFilter&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter, ProjectionDefinition&lt;T&gt; fields, SortDefinition&lt;T&gt; sort, int pageIndex, int pageSize)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IList&lt;T&gt; result = new List&lt;T&gt;();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (pageIndex != 0 &amp;&amp; pageSize != 0)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result = database.GetCollection&lt;T&gt;(documentname).Find(filter).Project&lt;T&gt;(fields).Sort(sort).Skip(pageSize * (pageIndex - 1)).Limit(pageSize).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result = database.GetCollection&lt;T&gt;(documentname).Find(filter).Project&lt;T&gt;(fields).Sort(sort).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return result;\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过条件获取分页的文档并排序\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filter\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"sort\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"pageIndex\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"pageSize\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;T&gt; GetPagedDocumentsByFilter&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter, SortDefinition&lt;T&gt; sort, int pageIndex, int pageSize)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IList&lt;T&gt; result = new List&lt;T&gt;();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (pageIndex != 0 &amp;&amp; pageSize != 0)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result = database.GetCollection&lt;T&gt;(documentname).Find(filter).Sort(sort).Skip(pageSize * (pageIndex - 1)).Limit(pageSize).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result = database.GetCollection&lt;T&gt;(documentname).Find(filter).Sort(sort).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return result;\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过条件获取分页的文档\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filter\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"pageIndex\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"pageSize\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;T&gt; GetPagedDocumentsByFilter&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter, int pageIndex, int pageSize)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IList&lt;T&gt; result = new List&lt;T&gt;();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (pageIndex != 0 &amp;&amp; pageSize != 0)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result = database.GetCollection&lt;T&gt;(documentname).Find(filter).Skip(pageSize * (pageIndex - 1)).Limit(pageSize).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result = database.GetCollection&lt;T&gt;(documentname).Find(filter).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return result;\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 获取分页的文档\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"pageIndex\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"pageSize\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;T&gt; GetPagedDocumentsByFilter&lt;T&gt;(string documentname, SortDefinition&lt;T&gt; sort, int pageIndex, int pageSize)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IList&lt;T&gt; result = new List&lt;T&gt;();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var filter = Builders&lt;T&gt;.Filter.Empty;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (pageIndex != 0 &amp;&amp; pageSize != 0)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result = database.GetCollection&lt;T&gt;(documentname).Find(filter).Sort(sort).Skip(pageSize * (pageIndex - 1)).Limit(pageSize).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result = database.GetCollection&lt;T&gt;(documentname).Find(filter).Sort(sort).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return result;\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 获取分页的文档\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"pageIndex\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"pageSize\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public IList&lt;T&gt; GetPagedDocumentsByFilter&lt;T&gt;(string documentname, int pageIndex, int pageSize)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IList&lt;T&gt; result = new List&lt;T&gt;();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var filter = Builders&lt;T&gt;.Filter.Empty;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (pageIndex != 0 &amp;&amp; pageSize != 0)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result = database.GetCollection&lt;T&gt;(documentname).Find(filter).Skip(pageSize * (pageIndex - 1)).Limit(pageSize).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result = database.GetCollection&lt;T&gt;(documentname).Find(filter).ToList();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return result;\n&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;#endregion\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;#region INSERT\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 新增\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"document\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filter\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public void Insert&lt;T&gt;(string documentName, T document)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database.GetCollection&lt;T&gt;(documentName).InsertOne(document);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;catch (MongoWriteException me)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MongoBulkWriteException mbe = me.InnerException as MongoBulkWriteException;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (mbe != null &amp;&amp; mbe.HResult == -2146233088)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw new Exception(\"插入重复的键！\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw new Exception(mbe.Message);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;catch (Exception ep)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw ep;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 新增多个文档\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documents\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public void InsertMany&lt;T&gt;(string documentname, IList&lt;T&gt; documents)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database.GetCollection&lt;T&gt;(documentname).InsertMany(documents);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;catch (MongoWriteException me)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MongoBulkWriteException mbe = me.InnerException as MongoBulkWriteException;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (mbe != null &amp;&amp; mbe.HResult == -2146233088)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw new Exception(\"插入重复的键！\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw new Exception(mbe.Message);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;catch (Exception ep)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw ep;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;#endregion\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;#region UPDATE\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 修改\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filterexist\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"id\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"oldinfo\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public void UpdateReplaceOne&lt;T&gt;(string documentname, string id, T oldinfo)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ObjectId oid = ObjectId.Parse(id);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var filter = Builders&lt;T&gt;.Filter.Eq(\"_id\", oid);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database.GetCollection&lt;T&gt;(documentname).ReplaceOne(filter, oldinfo);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 只能替换一条，如果有多条的话\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filter\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"oldinfo\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public void UpdateReplaceOne&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter, T oldinfo)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database.GetCollection&lt;T&gt;(documentname).ReplaceOne(filter, oldinfo);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 更新指定属性值，按ID就只有一条，替换一条\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"id\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"setvalue\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public void Update&lt;T&gt;(string documentname, string id, string property, string value)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ObjectId oid = ObjectId.Parse(id);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var filter = Builders&lt;T&gt;.Filter.Eq(\"_id\", oid);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var update = Builders&lt;T&gt;.Update.Set(property, value);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database.GetCollection&lt;T&gt;(documentname).UpdateOne(filter, update);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;public void Update&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter, UpdateDefinition&lt;T&gt; update)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database.GetCollection&lt;T&gt;(documentname).UpdateOne(filter, update);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;public void UpdateMany&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter, UpdateDefinition&lt;T&gt; update)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database.GetCollection&lt;T&gt;(documentname).UpdateMany(filter, update);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;#endregion\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;#region DELETE\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 删除一个文档\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"id\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public void Delete&lt;T&gt;(string documentname, string id)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ObjectId oid = ObjectId.Parse(id);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var filterid = Builders&lt;T&gt;.Filter.Eq(\"_id\", oid);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database.GetCollection&lt;T&gt;(documentname).DeleteOne(filterid);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;public void Delete&lt;T&gt;(string documentname, string property, string value)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FilterDefinition&lt;T&gt; filter = Builders&lt;T&gt;.Filter.Eq(property, value);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database.GetCollection&lt;T&gt;(documentname).DeleteOne(filter);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过一个属性名和属性值删除多个文档\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"id\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public void DeleteMany&lt;T&gt;(string documentname, string property, string value)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FilterDefinition&lt;T&gt; filter = Builders&lt;T&gt;.Filter.Eq(property, value);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database.GetCollection&lt;T&gt;(documentname).DeleteMany(filter);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 通过一个属性名和属性值删除多个文档\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"documentname\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"filter\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;returns&gt;&lt;/returns&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public void DeleteMany&lt;T&gt;(string documentname, FilterDefinition&lt;T&gt; filter)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database.GetCollection&lt;T&gt;(documentname).DeleteMany(filter);\n&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;#endregion\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// 有些命令要求你连到系统库上才能执行\n&nbsp;&nbsp;&nbsp;&nbsp;/// You need to link to the admin table if you want to run system command;eg:listDatabases ,the following url show you the details\n&nbsp;&nbsp;&nbsp;&nbsp;/// https://docs.mongodb.com/manual/reference/command/listCommands/\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public sealed class MongoCommand\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public const string ListDatabases = \"{listDatabases:1}\";\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public const string ListCommands = \"{ listCommands: 1 }\";\n&nbsp;&nbsp;&nbsp;&nbsp;}\n}\n</pre><p><br></p><p><br></p><p><br></p><p><span style=\"color: rgb(51, 51, 51);\">&nbsp;4.2、创建Mongodb日志实现类MongoDBLogger.cs，实现ILogger接口</span></p><pre class=\"ql-syntax\" spellcheck=\"false\">namespace Demo_Logging_MongoDbTest.Extensions\n{\n&nbsp;&nbsp;&nbsp;&nbsp;public class MongoDBLogger : ILogger\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public string _connectionString { set; get; }\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public MongoDBLogger(string connectionString)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_connectionString = connectionString;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public IDisposable? BeginScope&lt;TState&gt;(TState state) where TState : notnull\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return null;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public bool IsEnabled(LogLevel logLevel)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return true;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// 实现接口，记录日志到mongodb\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;typeparam name=\"TState\"&gt;&lt;/typeparam&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"logLevel\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"eventId\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"state\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"exception\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;param name=\"formatter\"&gt;&lt;/param&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;exception cref=\"NotImplementedException\"&gt;&lt;/exception&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public void Log&lt;TState&gt;(LogLevel logLevel, EventId eventId, TState state,&nbsp;&nbsp;Exception? exception, Func&lt;TState, Exception?, string&gt; formatter)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (!IsEnabled(logLevel))\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var message = formatter(state, exception);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var logInfo = new LogInfo\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Message = message,\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LogLevel = logLevel.ToString(),\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CreatedTime = DateTime.UtcNow,\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;};\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var mongodbHelper = new MongoDBHelper(_connectionString);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mongodbHelper.DatabaseName = \"Demos_LogInfo\";\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var tableName = $\"MylogInfo\";\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mongodbHelper.Insert&lt;LogInfo&gt;(tableName, logInfo);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;}\n}\n</pre><p><br></p><p><span style=\"color: rgb(51, 51, 51);\">&nbsp;4.3、创建Mongodb日志实现提供者，实现</span>ILoggerProvider接口</p><pre class=\"ql-syntax\" spellcheck=\"false\">namespace Demo_Logging_MongoDbTest.Extensions\n{\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;/// MongoDB日志实现支撑服务\n&nbsp;&nbsp;&nbsp;&nbsp;/// &lt;/summary&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;public class MongoDBLoggerProvider : ILoggerProvider\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;private string _connectionString;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public MongoDBLoggerProvider(string connectionString)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_connectionString = connectionString;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public ILogger CreateLogger(string categoryName)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return new MongoDBLogger(_connectionString);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public void Dispose()\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;}\n}\n</pre><p><br></p><p><br></p><p><span style=\"color: rgb(51, 51, 51);\">&nbsp;4.4、创建Mongodb日志注册类MongoDBExtensions.cs</span></p><pre class=\"ql-syntax\" spellcheck=\"false\">namespace Demo_Logging_MongoDbTest.Extensions\n{\n&nbsp;&nbsp;&nbsp;&nbsp;public static class MongoDBExtensions\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;public static ILoggingBuilder AddMongoDB(this ILoggingBuilder builder,&nbsp;&nbsp;string connectionString)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;builder.AddProvider(new MongoDBLoggerProvider(connectionString));\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return builder;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;}\n}\n</pre><p><br></p><p><br></p><p><span style=\"color: rgb(51, 51, 51);\">&nbsp;4.5、集成Mongodb日志 记录（Program.cs）</span></p><pre class=\"ql-syntax\" spellcheck=\"false\">public class Program\n{\n&nbsp;&nbsp;&nbsp;&nbsp;static void Main(string[] args)\n&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#region 3、日志级别控制\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var configuration = new ConfigurationBuilder()\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.SetBasePath(Directory.GetCurrentDirectory())\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.AddJsonFile(\"appsettings.json\")\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.Build();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var mongodbConn = configuration.GetSection(\"MongodbConn\").Get&lt;string&gt;();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ILoggerFactory loggerFactory = LoggerFactory.Create(builder =&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//1、控制台输入\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;builder.AddConsole().SetMinimumLevel(LogLevel.Warning);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//2、日志文件输出\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;builder.AddFile(options =&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//2.1、配置文件目录\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;options.RootPath = AppContext.BaseDirectory;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//2.2、配置文件路径\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;options.Files = new[]\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new LogFileOptions\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path = \"logs/log1.txt\"\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;};\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//3、集成MongoDb,设置日志级别\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;builder.AddMongoDB(mongodbConn).SetMinimumLevel(LogLevel.Information);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ILogger&lt;Program&gt; logger = loggerFactory.CreateLogger&lt;Program&gt;();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//输出日志\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logger.LogInformation(\"Hellorr MogodbLog LogInformation...\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logger.LogError(\"Hellorr MogodbLog LogError...\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logger.LogDebug(\"Hellorr MogodbLog LogError...\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logger.LogCritical(\"Hellorr MogodbLog LogCritical...\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logger.LogTrace(\"Hellorr MogodbLog LogTrace...\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logger.LogWarning(\"Hellorr MogodbLog LogWarning...\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Console.ReadKey();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#endregion\n&nbsp;&nbsp;&nbsp;&nbsp;}\n}\n</pre>', NULL, 2, 'ELK,日志存储', 1, 0, 29, 0, 0, 0, '1900-01-01 00:00:00', 0, 1001, '2025-11-03 00:30:28', 'admin', '2025-11-03 00:33:53', 'admin', 0);
INSERT INTO `blogs_article` VALUES (29859536970256, '快速部署本地大模型，运行模型参数训练', 'API Playground 是扣⼦提供的在线 API 调试⼯具，集成了扣⼦所有 OpenAPI，⽀持可视化调试 API、查看帮助⽂档、⽰例代码，帮助开发者快速体验扣⼦ OpenAPI 的基本能⼒。', '## 1、 前置条件：\n    1.1、安装docker，docker-compose等工具\n## 2、目录D:\\docker\\data\\vikijs下创建docker-compose.yml文件，内容如下\n\n### 第一种配置：将mysql独立出来，直接连接\n``` version: \"3\"\nservices:\n  db:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_DB: wiki\n      POSTGRES_PASSWORD: wikijsrocks\n      POSTGRES_USER: wikijs\n    restart: unless-stopped\n    volumes:\n      - db-data:/var/lib/postgresql/data\n      # 添加一个卷来覆盖postgresql.conf和pg_hba.conf\n      - ./pg_config:/etc/postgresql/conf.d\n    ports:\n      # 将容器的5432端口映射到宿主机的5432端口\n      - \"5432:5432\"\n  wiki:\n    image: linuxserver/wikijs\n    depends_on:\n      - db\n    environment:\n      DB_TYPE: postgres\n      DB_HOST: db\n      DB_PORT: 5432\n      DB_USER: wikijs\n      DB_PASS: wikijsrocks\n      DB_NAME: wiki\n    restart: unless-stopped\n    ports:\n      - \"3000:3000\"\n\nvolumes:\n  db-data:\n```\n\n\n## 3、执行docker-compose\nPS D:\\docker\\data\\vikijs> docker-compose up -d\n\n## 4、下载安装pgAdmin4，登录viki数据库，使用上面ylm中配置的pgsql数据库信息\n\n\n## 5、使用http://localhost:3000/访问vikijs，完成初始化\n![image](https://localhost:7235/ArticleFiles/ceaWS5xBNMLhI_20251107115642715.jpg)', NULL, 2, 'Coze，大模型', 1, 0, 63, 0, 0, 0, '1900-01-01 00:00:00', 0, 1005, '2025-11-06 07:50:08', 'zhenglijun', '2025-11-07 11:57:01', 'zhenglijun', 0);
INSERT INTO `blogs_article` VALUES (29957411953168, '在Linux上使用Docker', '基于Centos部署docker，实现CICD', '# Linux安装Docker\n## 1、Docker简介\n** Docker 是一个开源的 应用容器引擎，基于 Go 语言 开发，并遵循 Apache 2.0 协议开源。它采用 操作系统级虚拟化 技术，允许开发者将应用及其依赖打包成一个 轻量级、可移植的容器，可在任何支持 Docker 的 Linux/Windows 环境中运行。**\n### 1.1、Docker核心机制： \n    **沙箱机制：容器之间完全隔离，互不影响，安全性高**\n    **轻量高效：相比传统虚拟机（VM），容器共享主机 OS 内核，资源占用极低，启动速度更快。**\n    **跨平台：支持 Linux、Windows、macOS 及主流云平台（AWS/Azure/GCP）。**\n    **标准化交付：通过镜像（Image）实现“一次构建，随处运行”。**\n    ** 与传统虚拟机的对比：**\n![image](https://localhost:7235/ArticleFiles/111_20251108113450604.png)\n\n### 1.2 微服务架构\n```    \n    场景：每个微服务（如订单服务、用户服务）运行在独立容器中，通过 Docker Compose/Kubernetes 编排。\n    优势：快速扩展、滚动更新、故障隔离。    \n```\n### 1.3 数据库与中间件部署\n```\n       场景：快速部署 MySQL、Redis、RabbitMQ 等，避免手动安装依赖。\n```    \n### 1.4、Docker基本组成\n```\n    1）容器： 镜像的运行实例，包含独立的文件系统、网络和进程空间。\n    2）镜像： 容器的只读模板，包含应用代码、运行时环境、库文件等。\n    3）仓库：存储镜像，如Dockerhub在线仓库，包括公共仓库和私有仓库。\n    4）docker主机： 运行 Docker 守护进程（dockerd）的物理/虚拟机，负责管理容器和镜像。\n    5）docker客户端： 通过命令行（docker）或 API 与 Docker 主机交互。\n```\n\n## 4、Docker安装\n\n### 1、安装方式一\n```\n  1.1、前置条件：centos7.0 及以上版本， centos8配置镜像源：\n1、备份镜像源：\n[root@cloud-sjr6tl-kncg yum.repos.d]# sudo cp -a /etc/yum.repos.d/ \n2、清理原有镜像仓库\n[root@cloud-sjr6tl-kncg yum.repos.d]# sudo rm -rf /etc/yum.repos.d/*.repo\n3、获取阿里云Centos-8镜像源配置\n[root@cloud-sjr6tl-kncg yum.repos.d]# sudo curl -o /etc/yum.repos.d/CentOS-Stream-BaseOS.repo http://mirrors.aliyun.com/repo/Centos-8.repo\n4、清楚缓存，\n[root@cloud-sjr6tl-kncg yum.repos.d]# sudo yum clean all\n5、生成新的缓存\n[root@cloud-sjr6tl-kncg yum.repos.d]# sudo yum makecache\n```\n    \n  1.2、安装依赖项\n```\n[root@cloud-sjr6tl-kncg yum.repos.d]# sudo yum install -y yum-utils device-mapper-persistent-data lvm2\nLast metadata expiration check: 0:07:43 ago on Wed 18 Sep 2024 01:30:02 PM CST.\nPackage yum-utils-4.0.21-3.el8.noarch is already installed.\nDependencies resolved.\n==============================================================================================\nInstall    6 Packages\nDowngrade  2 Packages\n```\n \n  ### 1.3、设置 docker repo 的 yum 位置\n```\n1）配置官方镜像地址\n [root@cloud-sjr6tl-kncg yum.repos.d]# sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\nAdding repo from: https://download.docker.com/linux/centos/docker-ce.repo\n\n2）配置aliyun镜像地址\n[root@cloud-sjr6tl-kncg yum.repos.d]# sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\nAdding repo from: https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n```\n \n### 1.4、安装docker\n1、安装最新版本 \n``` [root@cloud-sjr6tl-kncg yum.repos.d]# sudo yum install docker-ce docker-ce-cli containerd.io ``` \n\n2、安装指定版本\n 2.1、查看可安装的docker版本\n ```\n   yum list docker-ce --showduplicates | sort -r\n ```\n 2.2、指定版本安装\n``` \n  sudo yum install docker-ce-20.10.1 docker-ce-cli-20.10.1 containerd.io \n```\n ###  1.5、启动docker\n``` \n重新加载配置\n [root@cloud-sjr6tl-kncg yum.repos.d]# systemctl daemon-reload\n启动docker\n [root@cloud-sjr6tl-kncg yum.repos.d]# systemctl start docker\n查看安装版本\n [root@cloud-sjr6tl-kncg yum.repos.d]# docker --version\nDocker version 26.1.3, build b72abbb\n``` \n\n###  1.6、配置开机启动\n``` [root@cloud-sjr6tl-kncg yum.repos.d]# systemctl enable docker ```\n\n### 1.7 卸载docker\n```\n1、停止所有容器：\n    sudo docker stop $(docker ps -aq)\n2、删除所有容器\n    sudo docker rm $(docker ps -aq)\n3、删除所有已退出的容器\n    sudo docker rm $(sudo docker ps -qf status=exited)\n4、删除所有未运行的容器\n    sudo docker rm $(sudo docker ps -a -q) \n5、删除所有镜像\n   sudo docker rm $(docker ps -aq)\n6、卸载docker引擎\n   sudo yum remove docker \\\n       docker-client \\\n       docker-client-latest \\\n       docker-common \\\n       docker-latest \\\n       docker-latest-logrotate \\\n       docker-logrotate \\\n       docker-engine\n7、删除docker数据目录\n   sudo rm -rf /var/lib/docker\n8、查看是否有漏掉的docker依赖\n   yum list installed | grep docker \n      如果还有则删除，如：\n    yum remove docker-buildx-plugin.x86_64\n``` \n\n## 2、安装方式二\n  如果方式一安装不成功，卸载后可以使用此方式安装，前置条件： 配置好网络、安装wget\n``` 1、根据命令 rpm -qa | grep wget 如果安装了wget，可返回版本信息\n[root@localhost docker_rpm]# rpm -qa | grep wget\nwget-1.14-18.el7_6.1.x86_64\n2、如果wget版本过低，通过yum remove wget删除\n3、安装wget\n[root@node01 docker_rpm]# yum install wget\n``` \n\n###   2.1 配置镜像加速\n``` [root@node01 docker_rpm]# mkdir docker\n[root@node01 docker_rpm]# vi /etc/docker/daemon.json\n{\n\"registry-mirrors\": [\"https://mirror.aliyun.com\"]\n}\n``` \n\n ###  2.2 创建docker_rpm目录，将rpm包源下载到/opt/docker_rpm目录下\n``` mkdir -p /opt/docker_rpm \ncd /opt/docker_rpm\nwget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/containerd.io-1.4.3-3.1.el7.x86_64.rpm\nwget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-20.10.1-3.el7.x86_64.rpm\nwget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-cli-20.10.1-3.el7.x86_64.rpm\nwget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-rootless-extras-20.10.1-3.el7.x86_64.rpm\n```\n ### 2.3 依次安装上面的rpm包，安装成功查看在docker_rpm目录下是否有rpm包\n ### 2.4、安装依赖包，从 docker 安装包版本下载对应所有依赖包，docker_rpm与上面配置的目录对应\n```\nmkdir -p /opt/rpm_cache \nyum install --downloadonly --downloaddir=/opt/rpm_cache /opt/docker_rpm/*.rpm\n```\n\n  ### 2.5、将依赖包移动到安装包目录下：\n``` \n[root@localhost docker_rpm]# cd /opt/rpm_cache\n[root@localhost rpm_cache]# mv * /opt/docker_rpm\n[root@localhost rpm_cache]# cd /opt/docker_rpm\n[root@localhost docker_rpm]# ll\n总用量 106232\n-rw-r--r--. 1 root root    78256 8月  23 2019 audit-libs-python-2.8.5-4.el7.x86_64.rpm\n-rw-r--r--. 1 root root   302068 11月 12 2018 checkpolicy-2.5-8.el7.x86_64.rpm\n-rw-r--r--. 1 root root 34677436 7月  12 00:44 containerd.io-1.4.3-3.1.el7.x86_64.rpm\n-rw-r--r--. 1 root root    40816 7月   6 2020 container-selinux-2.119.2-1.911c772.el7_8.noarch.rpm\n-rw-r--r--. 1 root root 27890212 7月  12 00:44 docker-ce-20.10.1-3.el7.x86_64.rpm\n-rw-r--r--. 1 root root 34723732 7月  12 00:44 docker-ce-cli-20.10.1-3.el7.x86_64.rpm\n-rw-r--r--. 1 root root  9486464 7月  12 00:44 docker-ce-rootless-extras-20.10.1-3.el7.x86_64.rpm\n-rw-r--r--. 1 root root    83764 4月  29 2020 fuse3-libs-3.6.1-4.el7.x86_64.rpm\n-rw-r--r--. 1 root root    55796 4月  29 2020 fuse-overlayfs-0.7.2-6.el7_8.x86_64.rpm\n-rw-r--r--. 1 root root    67720 8月  23 2019 libcgroup-0.41-21.el7.x86_64.rpm\n-rw-r--r--. 1 root root   115284 11月 12 2018 libsemanage-python-2.5-14.el7.x86_64.rpm\n-rw-r--r--. 1 root root   468316 4月   4 2020 policycoreutils-python-2.5-34.el7.x86_64.rpm\n-rw-r--r--. 1 root root    32880 7月   4 2014 python-IPy-0.75-6.el7.noarch.rpm\n-rw-r--r--. 1 root root   635184 11月 12 2018 setools-libs-3.3.8-4.el7.x86_64.rpm\n-rw-r--r--. 1 root root    83452 4月  29 2020 slirp4netns-0.4.3-4.el7_8.x86_64.rpm\n\n如果别的服务器已经下载好，可以直接拷贝\n[root@localhost docker_rpm]# scp root@192.168.190.129:/opt/docker_rpm/*.rpm /opt/docker_rpm/\n``` \n\n###   2.6、进入opt/docker_rpm目录，安装\n```\n[root@localhost docker_rpm]# rpm -ivh *.rpm\n警告：containerd.io-1.4.3-3.1.el7.x86_64.rpm: 头V4 RSA/SHA512 Signature, 密钥 ID 621e9f35: NOKEY\n准备中...                          ################################# [100%]\n正在升级/安装... \n```\n\n###  2.7、配置Docker作为服务启动\n```\n  服务启动配置/usr/lib/systemd/system/docker.service，配置内容如下：\n  如果此文件未生成，就手动创建，否则不需要处理此步骤。\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network-online.target docker.socket firewalld.service containerd.service time-set.target\nWants=network-online.target containerd.service\nRequires=docker.socket\n\n\n[Service]\nType=notify\n`#the default is not to use systemd for cgroups because the delegate issues still\n`# exists and systemd currently does not support the cgroup feature set required\n`# for containers run by docker\nExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\nExecReload=/bin/kill -s HUP $MAINPID\nTimeoutStartSec=0\nRestartSec=2\nRestart=always\n\n\n`# Note that StartLimit* options were moved from \"Service\" to \"Unit\" in systemd 229.\n`# Both the old, and new location are accepted by systemd 229 and up, so using the old location\n`# to make them work for either version of systemd.\nStartLimitBurst=3\n```\n`# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.\n`# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make\n`# this option work for either version of systemd.\n```\nStartLimitInterval=60s\n\n```\n`# Having non-zero Limit*s causes performance problems due to accounting overhead\n`# in the kernel. We recommend using cgroups to do container-local accounting.\n```\nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\n\n\n`# Comment TasksMax if your systemd version does not support it.\n`# Only systemd 226 and above support this option.\nTasksMax=infinity\n\n```\n`# set delegate yes so that systemd does not reset the cgroups of docker containers\n```\nDelegate=yes\n\n\n`# kill only the docker process, not all processes in the cgroup\nKillMode=process\nOOMScoreAdjust=-500\n\n[Install]\nWantedBy=multi-user.target\n```\n\n\n### 3、开启docker并将其设置成开机自启动\n```\n`#重新加载配置\nsystemctl daemon-reload\n`#启动docker\nsystemctl start docker\n`#设置开机启动\nsystemctl enable docker\n`#查看docker状态\nsystemctl status docker\n`#启动docker 出现如下输出则标识docker已成功启动。\n[root@localhost docker_rpm]# systemctl status docker\n```\n\n\n### 4、安装完成，查看Docker版本\n``` \n[root@localhost docker_rpm]# docker --version\nDocker version 20.10.1, build 831ebea\n```</p>', NULL, 2, 'Linux，Docker', 1, 0, 82, 0, 0, 0, '1900-01-01 00:00:00', 0, 1002, '2025-11-08 12:56:10', 'zhenglijun', '2025-11-08 16:17:02', 'zhenglijun', 0);
INSERT INTO `blogs_article` VALUES (113020708848888, '微服务容器化之K8S集群（一）', 'Kubernetes（简称 K8s）是一个开源的容器编排平台，旨在自动化容器化应用的部署、扩展和管理。它将组成应用的容器分组为逻辑单元，通过声明式配置实现集群状态的自动维护，解决了大规模容器环境下的资源调度、服务发现、故障恢复等核心问题', '1、K8S集群概念\n \n1.1 背景与起源：\n  Kubernetes的设计思想源自Google内部运行了十余年的Borg系统，后者管理者Google的搜索、Gmail等核心服务的集群，Kubernetes继承了Borg的分布式调度、自愈能力和资源优化经验，并与2014年开源，成为CNCF(云原生计算基金会)的收个托管项目。\n1.2、Kubernetes的基本组成：\n  Kubernetes采用分层架构，分为控制平面(master)和工作节点(Node)两个核心部分：\n  1）、控制平面组件：\n    API Server: 集群操作的统一入口，处理REST请求并存储状态至etcd。\n    Scheduler：基于资源需求和策略调度Pod到节点。\n    Controller Manager：通过控制器(如Deployment、 ReplicaSet)维护系统状态。\n    etcd：分布式键值数据库，存储集群配置和状态。\n  2）、工作节点组件：\n    Kubelet：管理Pod生命周期，确保容器按预期运行。\n    Kube-proxy：实现服务负载均衡与网络规则管理。\n    容器运行时：执行容器操作，如Docker。\n  3）核心资源对象\n    Pod：最小部署单元，包含共享网络、存储的容器组。\n    Service：为Pod提供稳定的访问入口，支持CluserIP，NodePort等类型。\n    Deployment：管理无状态应用的版本控制与滚动更新。 \n1.3 什么是service？\n  1）service与pod是一对多关系，一个service可以用在多个pod上。\n  2）service类似于代理服务，实现对pod的反向代理（类似nginx的角色）。\n1.4 K8S部署的微服务项目的访问流程\n\n1.5、K8S环境要求：  \n  CPU：最低1核心，推荐至少4核心及以上，微服务集群推荐8核心或更高，支持CPU密集型任务。\n  内存：最低1GB，推荐至少16G及以上。\n  存储：最低要求：10GB，推荐配置：100G以上。\n  网络：高带宽，低延迟网络，确保Pod之间数据交换效率。\n  操作系统：推荐Centos7/8 或Ubuntu等Linux发行版，确保版本一致。\n  容器运行时：推荐使用Containerd或CRI-O，轻量且符合OCI标准。\n  \n1.6、K8S学习地址：\n    https://kubernetes.io/zh-cn/docs/tutorials/kubernetes-basics/\n    本章节目的在于快速了解K8S的一些基础概念，并上手搭建一个K8S集群，基于Vmware虚拟机Centos8系统。\n\n2、搭建K8S集群环境\n  K8S中的核心操作组件介绍：在K8S集群中，kubeadm、kubectl、kubelet是三个核心工具，各自承担不同的责任，下面是三个工具的基本介绍：\n  kubeadm：\n    作用：kubeadm是k8s官方提供的集群快速部署工具，用于初始化k8s控制平面（master节点）和将加入集群的worker节点。\n    核心功能包括：初始化控制平面、生成TLS证书和配置文件、提供节点加入和重置命令、支持高可用集群部署。\n  kubectl：\n    作用：Kubectl是k8s的命令行工具，用于与集群交互。\n    核心功能包括：部署应用，查看资源状态，调试和日志查看。\n  kubelet:\n    作用：kubelet是运行在每个节点上的代理程序，负责与APIServer通信并管理节点上的Pod和容器。\n    核心功能包括：注册节点到集群（通过kubeadm join），启动和管理Pod（通过容器运行时），监控节点资源、执行监控检查。\n    \n  以下操作需要主从节点都执行一遍\n\n2.1、Linux环境搭建参考：Centos8主从节点配置\n   \n2.2、创建一个k8s的配置文件，配置桥接网络\n[root@localhost ~]# vi /etc/sysctl.d/k8s.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\n\n \n2.3、安装Docker以及网络\n#安装docker-ce\n[root@localhost ~]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O/etc/yum.repos.d/docker-ce.repo\n# 安装docker-ce及其依赖\n[root@localhost ~]#  sudo dnf install -y docker-ce docker-ce-cli containerd.io\n\n#设置docker开机启动\n[root@localhost ~]# sudo systemctl enable --now docker\n#查看Docker状态，active：running表示运行\n[root@localhost ~]# sudo systemctl status docker\n\n#编辑daemon.json\n[root@masternode ~]# vi /etc/docker/daemon.json\n{\n  \"registry-mirrors\": [\n    \"https://docker.211678.top\",\n    \"https://docker.1panel.live\",\n    \"https://hub.rat.dev\",\n    \"https://docker.m.daocloud.io\",\n    \"https://do.nark.eu.org\",\n    \"https://dockerpull.com\",\n    \"https://dockerproxy.cn\",\n    \"https://docker.awsl9527.cn\"\n  ]\n}\n#重启docker\n[root@localhost ~]# systemctl restart docker\n\n\n2.4、创建K8S配置项\n#添加阿里云k8s源\n[root@localhost ~]# sudo tee /etc/yum.repos.d/kubernetes.repo <<\'EOF\'\n[kubernetes]\nname=Kubernetes\nbaseurl=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/\nenabled=1\ngpgcheck=1\ngpgkey=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/repodata/repomd.xml.key\nrepo_gpgcheck=1\nsslverify=1\nEOF\n\n# 清理缓存\n[root@localhost ~]# sudo dnf clean all\n#建立新的元数据缓存、中途需要输入y继续下一步\n[root@localhost ~]# sudo dnf makecache\n\n\n2.5、安装kubeadm、kubelet、kubectl\n# 安装最新的K8S工具\n[root@localhost ~]# sudo dnf install -y kubectl kubeadm kubelet --disableexcludes=kubernetes\n#查看k8s版本\n[root@localhost ~]# kubectl version\nClient Version: v1.28.15\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?\n\n#启用并启动服务\n[root@localhost ~]# sudo systemctl enable kubeadm\n[root@localhost ~]# sudo systemctl start kubelet\n\n\n2.6、安装使用时间同步插件\n#安装时间插件\n[root@masternode ~]# sudo yum install chrony -y\n# 查看当前时间同步的详细信息，包括时间偏差，同步源\n[root@masternode ~]# chronyc sources -v\n#检查时间同步状态\n[root@masternode ~]# chronyc tracking\n#手动触发时间同步\n[root@masternode ~]# chronyc makestep\n#重启chronyd服务（可选）\n[root@masternode ~]# sudo systemctl restart chronyd\n\n\n2.7、安装 flannel\n  Flannel介绍：Flannel是CoreOS开发的一款用于Kubernetes的网络覆盖工具，旨在帮助每个节点上的Pod都能获得一个唯一的IP地址，并确保跨主机通信。Flannel通过在每个主机上创建一个子网，并将这些子网连接起来形成一个大的虚拟网络来实现这一目标。\n# 安装flannel（在master执行）/\n[root@masternode opt]# mkdir flannel\n[root@masternode opt]# cd flannel\n# 1、在线安装\n[root@masternode flannel]# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n\n# 2、离线安装\n如果kube-flannel.yml无法下载\n手动配置网路地址\nmkdir /run/flannel/\ncat <<EOF> /run/flannel/subnet.env\nFLANNEL_NETWORK=10.244.0.0/16\nFLANNEL_SUBNET=10.244.1.0/24\nFLANNEL_MTU=1450\nFLANNEL_IPMASQ=true\nEOF\n\n# 3、通过镜像打包安装,下载这个镜像\n#创建flannel目录\n[root@masternode /]# mkdir /opt/flannel\n[root@masternode /]# cd /opt/flannel/\n# 3.1、下载镜像\n[root@masternode /]#  ocker pull quay.io/coreos/flannel:v0.14.0\n# 3.2、 保存为离线包\n[root@masternode /]# docker save quay.io/coreos/flannel:v0.14.0 > flannel.tar\n# 3.3、 传输到目标机器并加载\n[root@masternode /]# docker load flannel.tar\n# 3.4、 使用本地配置文件安装\n[root@masternode /]#  kubectl apply -f kube-flannel.yml\n\n# 安装完flannel，将配置拷到node节点\nscp -r /etc/cni root@192.168.72.131:/etc\n\n# 拷贝flannel\nscp -r /run/flannel/ root@192.168.72.131:/run\n\n# 从节点/root/目录下创建.kube目录\n[root@node01 run]# cd /root/\n[root@node01 ~]# mkdir .kube\n#在主节点执行，将flannel配置文件拷贝到从节点\n[root@masternode ~]# scp /etc/kubernetes/admin.conf root@node01:~/.kube/config\n#从节点执行、查看能否获取到集群节点\n[root@node01 ~]# kubectl get nodes\nNAME         STATUS   ROLES           AGE   VERSION\nmasternode   Ready    control-plane   28h   v1.28.15\nnode01       Ready    <none>          23h   v1.28.15\n\n#查看节点详细信息\n[root@masternode deployment]# kubectl get node -o wide\nNAME         STATUS   ROLES           AGE    VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE         KERNEL-VERSION              CONTAINER-RUNTIME\nmasternode   Ready    control-plane   6d6h   v1.28.15   192.168.72.140   <none>        CentOS Linux 8   4.18.0-348.7.1.el8_5.x86_64   docker://26.1.3\nnode01       Ready    <none>          6d1h   v1.28.15   192.168.72.131   <none>        CentOS Linux 8   4.18.0-348.7.1.el8_5.x86_64   docker://26.1.3\n\n\n2.8、创建K8S集群\n# 执行k8s初始化脚本，将IP替换成自己的master节点的IP(注意斜杆右侧不要有空格）\n[root@localhost ~]# sudo kubeadm init \\\n --kubernetes-version=1.28.15 \\\n --apiserver-advertise-address=192.168.72.140 \\\n --image-repository registry.aliyuncs.com/google_containers \\\n --service-cidr=10.1.0.0/16 \\\n --pod-network-cidr=10.244.0.0/16 \\\n --ignore-preflight-errors=all\n\n#基础主节点初始化成功后会生成一段K8S脚本，用于从节点执行，主动加入集群,查看join语句\n[root@masternode ~]# kubeadm token create --print-join-command\nkubeadm join masternode:6443 --token mpxtyb.29b966n9o6xi5ng1 --discovery-token-ca-cert-hash sha256:5afa3edbb6d20943ea73e0bf23eba3b96840c25e24bafccf6008e6db01c2eb38\n\n\n2.9、如果在初始化后发现异常、需要清理初始化的缓存，再一一解决\n# 重置 kubeadm（清理基础配置）\n[root@localhost ~]# sudo kubeadm reset -f\n# 删除残留配置文件\n[root@localhost ~]# sudo rm -rf /etc/kubernetes/ /var/lib/etcd /etc/cni/net.d ~/.kube/\n# 清理 iptables 规则\n[root@localhost ~]# sudo iptables -F && sudo iptables -t nat -F && sudo iptables -t mangle -F && sudo iptables -X\n# 删除所有 Docker容器（可选，谨慎操作）\n[root@localhost ~]# sudo docker rm -f $(sudo docker ps -aq)\n# 删除所有 Docker 镜像\n[root@localhost ~]# sudo docker rmi -f $(sudo docker images -q)\n\n\n2.10、初始化遇到container错误，在从节点执行：\n# 生成默认配置\n [root@node01 ~]# sudo containerd config default | sudo tee /etc/containerd/config.toml\n\n# 启用 CRI 插件（确保以下字段存在）\n [root@node01 ~]# sudo sed -i \'s/disabled_plugins = \\[\"cri\"\\]/# disabled_plugins = [\"cri\"]/g\' /etc/containerd/config.toml\n\n# 重启 containerdsudo \n [root@node01 ~]# systemctl restart containerd\n\n# 配置防火墙端口开放，在主节点和从节点上打开6443端口和10250端口\n[root@masternode ~]# firewall-cmd --add-port=6443/tcp --permanent\nsuccess\n[root@masternode ~]# firewall-cmd --add-port=10250/tcp --permanent\n[root@masternode ~]# firewall-cmd --reload\n# 当看到输出6443端口则表示已经开放\n[root@masternode ~]# firewall-cmd --list-ports\n6443/tcp\n安装telnet，检查从节点与主节点的联通状态\n[root@masternode opt]# dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\n安装 telnet 客户端\n[root@masternode opt]# dnf install -y telnet\n#使用telnet 查看IP和端口的连通性\n[root@masternode ~]# telnet 192.168.72.131 10250\n#执行完成后再次重试加入集群\n[root@node01 ~]# kubeadm join 192.168.72.140:6443 --token ijgrdz.0oh1o6vh0ub4mvfa         --discovery-token-ca-cert-hash sha256:2363949ac4aa0bd8aad960fed35595506c2f2ac24e465179c9c5e6e3c22ad1eb\n\n\n2.11、查看集群状态\n#如果遇到连接错误\n[root@masternode opt]# kubectl get nodes\nE0513 19:56:27.560060   25021 memcache.go:265] couldn\'t get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\n\n#检查配置文件 确保配置文件存在\n[root@masternode opt]# ls -l /etc/kubernetes/admin.conf\n# 复制到用户目录（关键步骤！）\n[root@masternode opt]# mkdir -p ~/.kube\n[root@masternode opt]# sudo cp -i /etc/kubernetes/admin.conf ~/.kube/config\n[root@masternode opt]# sudo chown $(id -u):$(id -g) ~/.kube/config\n#验证配置内容\n[root@masternode opt]# kubectl config view\n#如果输出如下则表示正常\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: DATA+OMITTED\n    server: https://192.168.72.140:6443\n  name: kubernetes\ncontexts:\n- context:\n    cluster: kubernetes\n    user: kubernetes-admin\n  name: kubernetes-admin@kubernetes\ncurrent-context: kubernetes-admin@kubernetes\nkind: Config\npreferences: {}\nusers:\n- name: kubernetes-admin\n  user:\n    client-certificate-data: DATA+OMITTED\n    client-key-data: DATA+OMITTED\n\n# 查看集群状态\n[root@masternode opt]# kubectl get nodes\nNAME         STATUS     ROLES           AGE   VERSION\nmasternode   NotReady   control-plane   66m   v1.28.15\nnode01       NotReady   <none>          11m   v1.28.15\n\n#处理节点状态NotReady问题（主从节点都需要配置）\n1）确保flannel正确安装，\n2）确保CNI插件安装，检查flannel.conf配置是否存在，主从节点都需要配置\n[root@masternode net.d]# cat /etc/cni/net.d/10-flannel.conf\n{\n  \"cniVersion\": \"0.3.1\",\n  \"name\": \"flannel\",\n  \"type\": \"flannel\",\n  \"delegate\": {\n    \"isDefaultGateway\": true\n  }\n}\n\n3）重启K8S\n[root@masternode net.d]# sudo systemctl restart kubelet\n\n4）查看集群状态\n[root@masternode ~]# kubectl get node\nNAME         STATUS   ROLES    AGE   VERSION\nmasternode   Ready    master   21d   v1.18.0\nnode01       Ready    <none>   21d   v1.18.0\n\n\n3、K8S之Pod\n3.1、Pod的概念：\n  3.1.1、Pod的定义\n    Pod是K8S中最小的调度单元，包含了一个根容器和其他用户业务容器。\n    Pod包含一个或多个相对紧密耦合的容器，处于同一个Pod中的容器共享同样的资源。\n  3.1.2、Pod的组成：\n    1）Pause容器：\n    每个Pod默认包含一个隐藏的pause容器，用于维护Pod的网络和存储命名空间。\n  用户容器通过共享pause容器的命名空间实现通信和存储访问。\n  2）用户容器：\n  实际运行应用的容器。\n  3）共享资源：网络命名空间、IP地址、存储卷。\n      存储卷：管理Pod的网络和存储共享。\n3.1.3、Pod的常见状态：\n状态名称\n说明\nPending\nPod 已被 API Server 接受，但尚未调度到节点或资源未就绪。\nContainerCreating\nPod 已被调度到节点，正在创建容器（如拉取镜像、挂载存储卷等）。\nRunning\nPod 已绑定到节点，所有容器已创建且至少有一个容器正在运行。\nSucceeded\nPod 中所有容器正常退出（退出码为 0），且不会重启。\nFailed\nPod 中至少一个容器非正常退出（退出码非 0）。\nCrashLoopBackOff\n容器反复崩溃，Kubernetes 正在尝试重启（崩溃间隔逐渐增加）。\nImagePullBackOff\n无法拉取镜像（如镜像不存在、权限不足或网络问题）。\nTerminating\nPod 正在被删除（等待资源释放或优雅终止）。\nUnknown\n无法获取 Pod 状态（通常是与节点通信失败）。\n3.2 创建Pod，启动Docker容器\n  前置条件：\n    打包一个webapi的本地包，上传到服务器并生成镜像，参考【Dockerfile构建webapi】\n3.2.1、简单运行\n#直接创建，基于abpvnextdemo镜像，策略IfNotPresent表示本地存在则不拉取镜像\n[root@masternode ~]# kubectl run mydynamicapi --image=demo_dynamicapi --port=80 --image-pull-policy=IfNotPresent\n输出状态：pod/mydynamicapi created\n\n#直接创建nginx pod\n[root@masternode ~]# kubectl run mynginx --image=mynginx --port=80 --image-pull-policy=IfNotPresent\n\n  \n3.2.2、配置文件运行\n# 创建一个yaml文件\n[root@masternode pod]# cd /opt/k8s/pod/\n[root@masternode pod]# touch webapi-pod.yaml\n[root@masternode pod]# vi webapi-pod.yaml\n[root@masternode pod]# chmod 755 webapi-pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: mydynamicapi\n  labels:\n    app: mydynamicapi\nspec:\n  containers:\n  - name: mydynamicapi\n    image: demo_dynamicapi:latest\n    imagePullPolicy: Never\n    ports:\n    - containerPort: 8080\n\n#参数说明：\n  name: mydynamicapi pod的名称\n  app: mydynamicapi  #这个标签用于Service中关联的name\n  containerPort: 8080 #对应镜像中应用暴露的端口\n\n# 执行yaml文件，创建pod\n[root@masternode pod]# kubectl apply -f webapi-pod.yaml\n#通过yaml配置创建nginx pod\n[root@masternode pod]# vi nginx-pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:latest\n    imagePullPolicy: IfNotPresent\n    ports:\n    - containerPort: 80\n# --port=80  pod端口，和镜像保持一致\n# --image-pull-policy=IfNotPresent  镜像获取策略：如果本地有镜像直接使用，没有镜像远程获取\n\n# 批量创建Pod，指定执行目录即可\n[root@masternode k8s]# kubectl apply -f pod/\npod/nginx created\npod/mydynamicapi created\n\n\n3.3 查看Pod（只查看当前命名空间下的Pod）\n# 查看Pod列表\n[root@masternode ~]# kubectl get pod\nNAME           READY   STATUS    RESTARTS        AGE\nmydynamicapi   1/1     Running   1 (94m ago)     113m\nnginx          1/1     Running   3 (4h16m ago)   13h\n\n# 查看Pod列表详细信息 \n[root@masternode ~]# kubectl get pod -o wide\nNAME           READY   STATUS    RESTARTS        AGE    IP            NODE         NOMINATED NODE   READINESS GATES\nmydynamicapi   1/1     Running   1 (94m ago)     113m   10.244.0.5    masternode   <none>           <none>\nnginx          1/1     Running   3 (4h17m ago)   13h    10.244.1.32   node01       <none>           <none>\n\n# kubectl get pods -o wide   此命令会列出所有pod， 并提供更详细的信息，包括每个pod所在的节点以及运行命名空间等。\n# kubectl get pod -o wide 此目录也会列出所有pod，比如pod的名称、命名空间、状态等。\n\n# 查看Pod详细信息\n[root@masternode pod]# \\kubectl describe pod mydynamicapi\nName:             mydynamicapi\nNamespace:        default\nPriority:         0\nService Account:  default\nNode:             node01/192.168.72.131\nStart Time:       Sun, 18 May 2025 19:04:50 -0400\nLabels:           app=mydynamicapi\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.1.38\nIPs:\n  IP:  10.244.1.38\nContainers:\n  mydynamicapi:\n    Container ID:   docker://74dc8b5957255be4a4d3371e829f8a4fd1305d4ced228c239e7206dafa6a2875\n    Image:          demo_dynamicapi:latest\n    Image ID:       docker://sha256:a351712b509fc6cd3bec2968b685547078445eaa0f216d6758c71a47151f8b7b\n    Port:           8080/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sun, 18 May 2025 19:04:51 -0400\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4hhn2 (ro)\nConditions:\n  Type              Status\n  Initialized       True\n  Ready             True\n  ContainersReady   True\n  PodScheduled      True\nVolumes:\n  kube-api-access-4hhn2:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  41m   default-scheduler  Successfully assigned default/mydynamicapi to node01\n  Normal  Pulled     41m   kubelet            Container image \"demo_dynamicapi:latest\" already present on machine\n  Normal  Created    41m   kubelet            Created container mydynamicapi\n  Normal  Started    41m   kubelet            Started container mydynamicapi\n\n    \n3.4 Pod详细说明\n  1）基本信息\n字段\n说明\nName\nPod 名称（mydynamicapi）\nNamespace\nPod 所属的命名空间（默认 default）\nPriority\nPod 的调度优先级（若设置）\nNode\nPod 运行在哪个节点（如 node01/192.168.1.100）\nStart Time\nPod 创建时间\n  2）状态信息\n字段\n说明\nStatus\nPod 状态（Running/Pending/Failed/CrashLoopBackOff）\nIP\nPod 分配的集群内部 IP（如 10.244.1.33）\nControlled By\n管理该 Pod 的控制器（如 ReplicaSet/nginx-7c6cf994f6）\n  3）容器状态\n字段\n说明\nContainers\nPod 中的容器列表（名称、镜像、端口等）\nState\n容器状态（Running/Waiting/Terminated）\nReady\n是否通过健康检查（True/False）\nRestart Count\n容器重启次数（异常时需关注）\nImage\n容器使用的镜像（如 demo_dynamicapi:latest）\nImage ID\n镜像的哈希值（唯一标识）\nPort\n容器暴露的端口（如 80/TCP）\n  4）其他信息\n字段\n说明\nLabels\nPod 的标签（用于 Service 选择器匹配）\nAnnotations\n注解信息（如版本、配置哈希等）\nVolumes\n挂载的存储卷（如 ConfigMap、PVC）\nQoS Class\n服务质量等级（Guaranteed/Burstable/BestEffort）\nTolerations\n容忍的节点污点（影响调度）\n3.5 删除Pod\n  删除pod，同时删除与该pod相关的资源。如果该Pod是部署（deployment）或者状态集（statefulset）的一部分，那么这个命令也会删除那些资源，如果该pod创建了其他依赖项（如volumes，configmaps等），也会被删除。\n[root@masternode ~]# kubectl delete pod mydynamicapi --cascade\n返回信息 pod \"mydynamicapi\" deleted\n\n# 删除Pod，如果该Pod是由其他资源管理的（如deployment或者statefulset）管理的，这个命令不会影响到这些资源。\n[root@masternode ~]# kubectl delete pod mydynamicapi\n\n注意：\n    使用--cascade选项命令更强大，风险也更高。\n    删除pod之后，对应的容器也会自动删除。\n\n# 或者删除符合特定标签选择器的所有 \n    kubectl delete pods -l <label-key>=<label-value> \n    如删除 label app=webapi 的所有Pod  kubectl delete pod -l app=webapi\n\n3.6 编辑Pod，一般除了调试不会直接编辑Pod，如果需要操作Pod通过yaml配置文件或者挂着脚本的方式。\n[root@masternode ~]# kubectl edit pod mydynamicapi\n\n\n3.7 查看Pod的日志\n#查看Pod日志\n[root@masternode ~]# kubectl logs pod/mydynamicapi -f\n\n   \n4 容器运行时\n4.1、什么是容器运行时\n  容器运行时是负责管理容器声明周期的核心组件，负责在操作系统上创建、运行、监控和销毁容器，容器运行时是容器技术的基础，直接与操作系统内核交互，利用内核特性实现进程隔离和资源限制。\n     Containerd 是 Kubernetes 的推荐容器运行时，尤其适合生产环境。\n     Docker 的局限性：Docker 作为完整平台，功能冗余，且 Kubernetes 已逐步弃用对其的直接支持\n  迁移建议：新部署的K8s集群应该直接使用Containerd；现有集群可逐步迁移\n4.2、查看当前K8S使用的容器运行时\n[root@masternode publishfile]# kubectl describe node masternode | grep Container\\ Runtime\n  Container Runtime Version:  containerd://1.6.32\n\n  \n4.3、切换容器运行时\n4.3.1、在Centos8中安装Container\n# 更新工具\n[root@masternode publishfile]# yum install -y yum-utils\n# 添加仓库自：https://download.docker.com/linux/centos/docker-ce.repo\n[root@masternode source]# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n# 安装containerd\n[root@masternode source]# yum install -y containerd.io\n\n\n4.3.2、配置Containerd\n[root@masternode source]# mkdir -p /etc/containerd\n[root@masternode source]# containerd config default > /etc/containerd/config.toml\n\n\n4.3.3、启动containerd\n[root@masternode source]# systemctl enable --now containerd\n\n\n4.3.4、配置K8S使用containerd\n[root@masternode source]# echo \"KUBELET_EXTRA_ARGS=--container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock\" > /etc/default/kubelet\nsystemctl restart kubelet\n\n \n5 K8S之Service\n5.1、Service相关概念：\n  K8S的Service是一种抽象资源，用于为一组运行相同功能的Pod提供稳定的网络访问入口。它通过标签选择器关联Pod，并自动处理负载均衡和服务发现。\n  核心作用：\n    1）稳定访问入口：Pod的IP是动态分配的，可能因为重启和扩容发生变化，Service提供固定的虚拟IP和DNS名称。\n    2）负载均衡：Service将流量均匀分配到后端Pod，\n    3）服务发现：集群内其他Pod可以通过Service提供的DNS名称直接访问，无需关注后端Pod的具体IP。\n5.2、镜像、Pod与Service之间的关系\n组件\n角色\n关联方式\n镜像\n应用的静态模板\nPod 通过 spec.containers[*].image 指定镜像。\nPod\n运行容器的实例\nService 通过 selector 匹配 Pod 的标签（如 app: my-app）。\nService\nPod 的访问代理\n不直接关联镜像，而是通过 Pod 间接关联。\n5.3 创建Service（前提需要创建Pod）主节点创建Service，从节点也会自动创建，Service用于访问微服务项目\n# 查看当前可用的Pod\n[root@masternode service]# kubectl get pods\nNAME           READY   STATUS    RESTARTS      AGE\nmydynamicapi   1/1     Running   0             31m\nnginx          1/1     Running   3 (12h ago)   21h\n\n# 暴露端口\n[root@masternode ~]# kubectl expose pod mydynamicapi --port=80 --target-port=80 --name=mydynamicapiservice --type=NodePort\n# 返回结果\nservice/abpvnextdemoservice exposed\n#创建nginx的service\n[root@masternode ~]# kubectl expose pod mynginx --port=80 --target-port=80 --name=mynginxserver --type=NodePort\n\n# 使用yaml文件创建service\n[root@masternode service]# touch webapi-service.yaml\n[root@masternode service]# chmod 755 webapi-service.yaml\n[root@masternode service]# vi webapi-service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: mydynamicapi-service\nspec:\n  selector:\n    app: mydynamicapi  #对应pod的name\n  ports:\n    - protocol: TCP\n      port: 44315 #service的端口\n      targetPort: 80 #对应pod的端口\n\n# 参数说明：\nabpvnextdemo：pod名称\n--port=44315：service端口\n--target-port=80：pod端口\n--name=abpvnextdemoservice： service名称\n\n# 执行yaml文件，创建service\n[root@masternode service]# kubectl apply -f webapi-service.yaml\n\n#查看增加参数--type=NodePort创建的service\n[root@masternode service]# kubectl get service\nNAME                   TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)     AGE\nkubernetes             ClusterIP   10.1.0.1      <none>        443/TCP     4d6h\nmydynamicapi-service   ClusterIP   10.1.44.151   <none>        44315/TCP   7s\n\n#批量创建service，指定yaml目录执行\n[root@masternode k8s]# kubectl apply -f service/\nservice/nginx-service created\nservice/webapiservice created\n\n\n5.4 查看Service\n# 查看创建的service\n[root@masternode service]# kubectl get services\nNAME            TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE\nkubernetes      ClusterIP   10.1.0.1      <none>        443/TCP        4d18h\nnginx-service   NodePort    10.1.182.30   <none>        80:30010/TCP   9h\nwebapiservice   NodePort    10.1.66.93    <none>        80:30015/TCP   4s\n\n注意：\n当TYPE的值是ClusterIP 时，service只能在集群内部访问，不能从外部访问。比如此时的集群有masternode节点和node01节点，这两台可以访问。\n具体有以下限制：\n1、只能从集群内部访问：由于ClusterIP类型的service在集群内部具有一个虚拟IP地址，因此只能从集群内部其他的Pod或Service访问该Service，外部请求无法直接访问该Service。\n2、不支持外部负载均衡：无法使用负载均衡器\n3、不支持外部连接，由于ClusterIP类型的Sservice仅在集群内部可见，所以外部无法直接连接，可以通过在集群外部设置一个网关或代理请求来转发连接请求。\n\n# 查看service详细信息\n[root@masternode service]# kubectl describe service webapiservice\nName:                     webapiservice\nNamespace:                default\nLabels:                   <none>\nAnnotations:              <none>\nSelector:                 app=mydynamicapi   #关联的Pod名称\nType:                     NodePort\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.1.66.93\nIPs:                      10.1.66.93\nPort:                     <unset>  80/TCP\nTargetPort:               8080/TCP 容器内部端口、这个就是打包的应用暴露的端口号\nNodePort:                 <unset>  30015/TCP  #外部访问端口\nEndpoints:                10.244.1.38:8080\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   <none>\n\n\n5.5 编辑service\n#语法\n$ edit (RESOURCE/NAME | -f FILENAME)\n# 编辑service abpvnextdemoservice\n# [root@masternode service]# kubectl edit svc/webapiservice \n\n\n5.6 查看service日志\n#查看日志，-f表示实时查看\n[root@masternode service]# kubectl logs service/webapiservice -f\ninfo: Microsoft.Hosting.Lifetime[14]\n      Now listening on: http://[::]:8080\ninfo: Microsoft.Hosting.Lifetime[0]\n      Application started. Press Ctrl+C to shut down.\ninfo: Microsoft.Hosting.Lifetime[0]\n      Hosting environment: Production\ninfo: Microsoft.Hosting.Lifetime[0]\n      Content root path: /publish\n\n参数说明：\n-f 实时查看\n\n\n5.7 删除Service，删除成功，从节点也会对应删除。\n# 删除service\n[root@masternode ~]# kubectl delete service webapiservice\nservice \"webapiservice\" deleted\n\n\n5.8 访问swagger，通过IP+端口30015\n  master节点和node01节点都能访问到swagger则说明K8S配置成功', NULL, 1, 'K8S，DevOps', 1, 0, 0, 0, 0, 0, '1900-01-01 00:00:00', 0, 1, '2025-10-22 12:21:29', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (130754880472312, '11', '22', '1111', NULL, 1, '33', 1, 0, 0, 0, 0, 0, '1900-01-01 00:00:00', 0, 2, '2025-10-22 12:56:44', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (131051023500536, '汉密尔顿与F1的故事', '汉密尔顿七冠王', '# 技术文档示例\n\n## 简介\n\n这是一篇技术文章的示例模板，展示了 **Markdown** 的常用语法和排版效果。您可以参考这个模板来编写自己的文章。\n\n### 文本格式\n\n- **加粗文本**：使用 `**文本**`\n- *斜体文本*：使用 `*文本*`\n- <u>下划线</u>：使用 `<u>文本</u>`\n- ~~删除线~~：使用 `~~文本~~`\n\n### 列表\n\n**无序列表：**\n- 第一项\n- 第二项\n  - 子项 1\n  - 子项 2\n- 第三项\n\n**有序列表：**\n1. 第一步\n2. 第二步\n3. 第三步\n\n## 代码示例\n\n### JavaScript 代码块\n\n```javascript\n// React 函数组件示例\nfunction HelloWorld({ name }) {\n  const [count, setCount] = useState(0);\n  \n  return (\n    <div className=\"hello\">\n      <h1>Hello, {name}!</h1>\n      <button onClick={() => setCount(count + 1)}>\n        Clicked {count} times\n      </button>\n    </div>\n  );\n}\n```\n\n### Python 代码块\n\n```python\ndef fibonacci(n):\n    \"\"\"计算斐波那契数列\"\"\"\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\n# 输出前 10 个数\nfor i in range(10):\n    print(f\"F({i}) = {fibonacci(i)}\")\n```\n\n### 行内代码\n\n在文本中使用 `const x = 10;` 这样的行内代码。\n\n## 图片展示\n\n![React Logo](https://upload.wikimedia.org/wikipedia/commons/a/a7/React-icon.svg)\n\n*图片说明：React 官方 Logo*\n\n## 链接\n\n- [React 官方文档](https://react.dev)\n- [MDN Web Docs](https://developer.mozilla.org)\n- [GitHub](https://github.com)\n\n## 表格\n\n| 特性 | React | Vue | Svelte |\n|------|-------|-----|--------|\n| 虚拟DOM | ✓ | ✓ | ✗ |\n| TypeScript | ✓ | ✓ | ✓ |\n| 生态系统 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ |\n| 学习曲线 | 中 | 低 | 低 |\n\n## 引用\n\n> “代码质量不仅仅是关于功能，更是关于可读性和可维护性。”\n> \n> —— Robert C. Martin\n\n## 注意事项\n\n⚠️ **重要：**请确保代码的安全性和性能。\n\n✅ **提示：**使用 ESLint 和 Prettier 保持代码风格统一。\n\n## 总结\n\n本文展示了 Markdown 的常用语法，包括：\n\n1. 标题和段落\n2. 文本格式化\n3. 列表和代码块\n4. 图片和链接\n5. 表格和引用\n\n希望这个示例能帮助您快速上手 Markdown 编写！', NULL, 1, '111', 1, 0, 14, 0, 0, 0, '1900-01-01 00:00:00', 0, 3, '2025-10-22 12:57:19', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_article` VALUES (200138500080888, '测试', '1111', '# 技术文档示例\n\n## 简介\n\n这是一篇技术文章的示例模板，展示了 **Markdown** 的常用语法和排版效果。您可以参考这个模板来编写自己的文章。\n\n### 文本格式\n\n- **加粗文本**：使用 `**文本**`\n- *斜体文本*：使用 `*文本*`\n- <u>下划线</u>：使用 `<u>文本</u>`\n- ~~删除线~~：使用 `~~文本~~`\n\n### 列表\n\n**无序列表：**\n- 第一项\n- 第二项\n  - 子项 1\n  - 子项 2\n- 第三项\n\n\n1. 标题和段落\n2. 文本格式化\n3. 列表和代码块\n4. 图片和链接\n5. 表格和引用\n\n希望这个示例能帮助您快速上手 Markdown 编写！', NULL, 1, '测试，test', 1, 0, 2, 0, 0, 0, '1900-01-01 00:00:00', 0, 2, '2025-10-22 15:14:36', 'zlj', NULL, NULL, 0);

-- ----------------------------
-- Table structure for blogs_category
-- ----------------------------
DROP TABLE IF EXISTS `blogs_category`;
CREATE TABLE `blogs_category`  (
  `Id` bigint(20) NOT NULL AUTO_INCREMENT,
  `Name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `BusType` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '1' COMMENT '模块类型：1分类，2板块',
  `Description` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Slug` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Sort` int(11) NOT NULL,
  `CreatedAt` datetime NOT NULL,
  `CreatedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1009 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blogs_category
-- ----------------------------
INSERT INTO `blogs_category` VALUES (1, 'C#', '1', '后端开发-C#', '1111', 1, '2025-10-10 22:00:13', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_category` VALUES (2, 'JAVA', '1', '后端开发-JAVA', '11', 1, '2025-10-01 22:00:49', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_category` VALUES (3, '大模型', '1', 'Python开发', '11', 1, '2025-10-12 07:42:14', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_category` VALUES (4, 'Vue', '1', 'vue', '11', 1, '2025-10-12 07:42:14', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_category` VALUES (1001, '后端开发', '2', '研究.net、java、python等主流技术', '1', 1, '2025-10-12 07:42:14', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_category` VALUES (1002, '微服务', '2', '主要研究微服务项目部署、通信、中间件、消息队列、高并发技术', '1', 1, '2025-10-12 07:42:14', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_category` VALUES (1003, '前端开发', '2', '研究当下AI工具的使用', '1', 1, '2025-10-12 07:42:14', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_category` VALUES (1004, '数据库', '2', '研究数据库优化、NoSql、缓存、报表等', '1111', 1, '2025-10-12 07:42:14', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_category` VALUES (1005, 'AI大模型', '2', '研究数据库优化、NoSql、缓存、报表等', '1111', 1, '2025-10-12 07:42:14', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_category` VALUES (1006, '感悟', '2', '研究数据库优化、NoSql、缓存、报表等', '1111', 1, '2025-10-12 07:42:14', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_category` VALUES (1007, 'AAA', NULL, '1111', NULL, 0, '2025-11-03 12:14:55', 'admin', '2025-11-03 12:15:17', 'admin', 1);
INSERT INTO `blogs_category` VALUES (1008, '11111111', NULL, '111', NULL, 0, '2025-11-07 02:14:58', 'admin', '2025-11-07 02:17:57', 'admin', 1);

-- ----------------------------
-- Table structure for blogs_comment
-- ----------------------------
DROP TABLE IF EXISTS `blogs_comment`;
CREATE TABLE `blogs_comment`  (
  `Id` bigint(20) NOT NULL AUTO_INCREMENT,
  `ParentId` bigint(20) NULL DEFAULT NULL,
  `Content` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `Status` int(11) NOT NULL,
  `LikeCount` int(11) NOT NULL,
  `ArticleId` bigint(20) NOT NULL,
  `AuthorId` bigint(20) NOT NULL,
  `ReplyToUserId` bigint(20) NULL DEFAULT NULL,
  `CreatedAt` datetime NOT NULL,
  `CreatedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 18 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blogs_comment
-- ----------------------------
INSERT INTO `blogs_comment` VALUES (1, 0, '1111', 1, 0, 1, 1001, 1002, '2025-10-21 15:13:04', 'aa', '2025-11-03 14:07:40', 'admin', 1);
INSERT INTO `blogs_comment` VALUES (2, 0, '1111111111111111111', 0, 0, 29247929175568, 0, 0, '2025-10-23 22:36:44', 'zlj01', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (3, 0, '444444445555555555555', 0, 0, 29247929175568, 0, 0, '2025-10-23 22:40:14', 'zlj01', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (4, 2, '5555555555555555555555555555555555555555555555555555555555', 0, 0, 29247929175568, 0, 0, '2025-10-23 22:57:13', 'zlj01', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (5, 0, '哦i哦i哦i哦i哦好久好久好久好久合计合计合计合计合计', 0, 0, 29251842130960, 0, 0, '2025-10-23 23:28:44', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (6, 0, '9900哦哦啪啪啪', 0, 0, 29251842130960, 0, 0, '2025-10-23 23:28:58', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (7, 0, '写得很用心，很细致。期待下一步的文章~！！★', 0, 0, 29246433072656, 0, 0, '2025-10-23 23:35:46', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (8, 7, '已经验证过，该方案可行~', 0, 0, 29246433072656, 0, 0, '2025-10-23 23:39:45', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (9, 0, '汉密尔顿是黑人？', 0, 0, 131051023500536, 0, 0, '2025-10-23 23:51:16', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (10, 9, '好像是吧', 0, 0, 131051023500536, 0, 0, '2025-10-23 23:51:24', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (11, 0, '汉密尔顿七冠王？', 0, 0, 131051023500536, 0, 0, '2025-10-23 23:51:33', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (12, 9, '还真是', 0, 0, 131051023500536, 0, 0, '2025-10-23 23:51:43', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (13, 11, '是的吧', 0, 0, 131051023500536, 0, 0, '2025-10-23 23:51:55', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (14, 0, '1111111111111111', 0, 0, 29251842130960, 0, 0, '2025-10-24 22:42:02', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (15, 0, '写得很好，学到了新知识', 0, 0, 29528043178000, 0, 0, '2025-10-29 20:00:18', 'zhenglijun', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (16, 0, '学到了~！', 0, 0, 29528043178000, 0, 0, '2025-10-29 20:08:22', 'zlj01', NULL, NULL, 0);
INSERT INTO `blogs_comment` VALUES (17, 0, '写得很详细、期待完整的代码案例~', 0, 0, 29713320001040, 0, 0, '2025-11-03 00:34:27', 'zhenglijun', '2025-11-03 14:13:16', 'admin', 1);

-- ----------------------------
-- Table structure for blogs_file_record
-- ----------------------------
DROP TABLE IF EXISTS `blogs_file_record`;
CREATE TABLE `blogs_file_record`  (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `OriginalFileName` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `StoredFileName` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `FilePath` varchar(500) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `FileSize` bigint(20) NOT NULL,
  `ContentType` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `FileExtension` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `BusinessType` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `BusinessId` bigint(20) NULL DEFAULT NULL,
  `UploadTime` datetime NOT NULL,
  `UploadUserId` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Description` varchar(1000) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Md5Hash` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `idx_business_type`(`BusinessType`) USING BTREE,
  INDEX `idx_upload_time`(`UploadTime`) USING BTREE,
  INDEX `idx_md5_hash`(`Md5Hash`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 26 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blogs_file_record
-- ----------------------------
INSERT INTO `blogs_file_record` VALUES (1, '7bf30e4e65432ff7791f2b6345e1afe5.jpg', '7bf30e4e65432ff7791f2b6345e1afe5_20250930164540520_136ccacbea264f58b67d29007cc1fc5f.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\7bf30e4e65432ff7791f2b6345e1afe5_20250930164540520_136ccacbea264f58b67d29007cc1fc5f.jpg', 420560, 'image/jpeg', '.jpg', 'photo', NULL, '2025-09-30 16:46:07', 'anonymous', '1.1111111111111111e+21', '7bf30e4e65432ff7791f2b6345e1afe5');
INSERT INTO `blogs_file_record` VALUES (2, '【哲风壁纸】山川-草木.png', '_哲风壁纸_山川-草木_20250930173406215_28ea32f62e904c7c98560ebf627ce207.png', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\_哲风壁纸_山川-草木_20250930173406215_28ea32f62e904c7c98560ebf627ce207.png', 8916992, 'image/png', '.png', 'photo', 0, '2025-09-30 17:34:25', 'anonymous', '111111111111111100', '2a458236b538042aa1d19130fb7214e8');
INSERT INTO `blogs_file_record` VALUES (3, '30xodv2pa4f.jpg', '30xodv2pa4f_20250930205506405_3634efc3451d46f7801dc02141ddccc0.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\30xodv2pa4f_20250930205506405_3634efc3451d46f7801dc02141ddccc0.jpg', 98373, 'image/jpeg', '.jpg', 'photo', 0, '2025-09-30 20:55:06', '100001', '222222222222', '77ee0b992aaa94c9507b456271740d45');
INSERT INTO `blogs_file_record` VALUES (4, '微信图片_20251019202231_859_2.jpg', '微信图片_20251019202231_859_2_20251023002006904_5fce76a6362740a08689e41883f6111b.jpg', 'D:\\\\Workspace\\\\DotNet\\\\ZLJ.BlogSingleApplication\\\\master\\\\5_WebApi\\\\Blogs.WebApi\\\\Uploads\\微信图片_20251019202231_859_2_20251023002006904_5fce76a6362740a08689e41883f6111b.jpg', 7843979, 'image/jpeg', '.jpg', 'ArticleFiles', 0, '2025-10-23 00:20:24', '355143408420088', '111', 'cf9b390475ffc63c952539c8a149e0ec');
INSERT INTO `blogs_file_record` VALUES (5, '2b5c63cdd501ec51c1d30a1bfd987e4f.jpg', '2b5c63cdd501ec51c1d30a1bfd987e4f_20251023004555628_9f7920eaead1420ab183d84ce420ca48.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\UserPhoto\\2b5c63cdd501ec51c1d30a1bfd987e4f_20251023004555628_9f7920eaead1420ab183d84ce420ca48.jpg', 237746, 'image/jpeg', '.jpg', 'UserPhoto', 0, '2025-10-23 00:46:06', '29219840909840', '111', '7fa7d061ef48d9a6ec752e7c43520140');
INSERT INTO `blogs_file_record` VALUES (6, '【哲风壁纸】山-草地.png', '_哲风壁纸_山-草地_20251023005450785.png', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\_哲风壁纸_山-草地_20251023005450785.png', 3240088, 'image/png', '.png', 'ArticleFiles', 0, '2025-10-23 00:54:57', '29219840909840', '111', 'd118bcabe9d95587ddcaacce2d6a4c3a');
INSERT INTO `blogs_file_record` VALUES (7, '30xodv2pa4f.jpg', '30xodv2pa4f_20251023010446217.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\UserPhoto\\30xodv2pa4f_20251023010446217.jpg', 98373, 'image/jpeg', '.jpg', 'UserPhoto', 0, '2025-10-23 01:04:46', '29219840909840', '111', '77ee0b992aaa94c9507b456271740d45');
INSERT INTO `blogs_file_record` VALUES (8, '【哲风壁纸】山-草地.png', '_哲风壁纸_山-草地_20251023075221459.png', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\UserPhoto\\_哲风壁纸_山-草地_20251023075221459.png', 3240088, 'image/png', '.png', 'UserPhoto', 0, '2025-10-23 07:52:24', '29219840909840', '', 'd118bcabe9d95587ddcaacce2d6a4c3a');
INSERT INTO `blogs_file_record` VALUES (9, '30xodv2pa4f.jpg', '30xodv2pa4f_20251023080200617.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\WebsiteImage\\30xodv2pa4f_20251023080200617.jpg', 98373, 'image/jpeg', '.jpg', 'WebsiteImage', 0, '2025-10-23 08:02:01', '29219840909840', '', '77ee0b992aaa94c9507b456271740d45');
INSERT INTO `blogs_file_record` VALUES (10, '30xodv2pa4f.jpg', '30xodv2pa4f_20251023080957564.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\30xodv2pa4f_20251023080957564.jpg', 98373, 'image/jpeg', '.jpg', 'ArticleFiles', 0, '2025-10-23 08:09:58', '29219840909840', '', '77ee0b992aaa94c9507b456271740d45');
INSERT INTO `blogs_file_record` VALUES (11, '2b5c63cdd501ec51c1d30a1bfd987e4f.jpg', '2b5c63cdd501ec51c1d30a1bfd987e4f_20251023083625071.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\2b5c63cdd501ec51c1d30a1bfd987e4f_20251023083625071.jpg', 237746, 'image/jpeg', '.jpg', 'ArticleFiles', 0, '2025-10-23 08:36:25', '29219840909840', '', '7fa7d061ef48d9a6ec752e7c43520140');
INSERT INTO `blogs_file_record` VALUES (12, '44bcbb2e0be64e7d4e48eee679cdfc22.jpg', '44bcbb2e0be64e7d4e48eee679cdfc22_20251023084735521.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\44bcbb2e0be64e7d4e48eee679cdfc22_20251023084735521.jpg', 174826, 'image/jpeg', '.jpg', 'ArticleFiles', 0, '2025-10-23 08:47:36', '29219840909840', '', '10c5bc726e2a060b8879b8f1eab047af');
INSERT INTO `blogs_file_record` VALUES (13, '5bcc3cda-d646-49db-b168-03a1595f055a.jpg', '5bcc3cda-d646-49db-b168-03a1595f055a_20251023084755728.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\5bcc3cda-d646-49db-b168-03a1595f055a_20251023084755728.jpg', 377048, 'image/jpeg', '.jpg', 'ArticleFiles', 0, '2025-10-23 08:47:56', '29219840909840', '', '8f2b8feecd865a2bbf53760a1a014ce5');
INSERT INTO `blogs_file_record` VALUES (14, '123 (2).jpg', '123__2__20251023085202609.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\123__2__20251023085202609.jpg', 44228, 'image/jpeg', '.jpg', 'ArticleFiles', 0, '2025-10-23 08:52:03', '29219840909840', '', 'd3f29b37df84693813d9a212883c0672');
INSERT INTO `blogs_file_record` VALUES (15, '057a3a04-19ce-4f9e-9979-b686699f5503.jpg', '057a3a04-19ce-4f9e-9979-b686699f5503_20251023085331282.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\057a3a04-19ce-4f9e-9979-b686699f5503_20251023085331282.jpg', 1253062, 'image/jpeg', '.jpg', 'ArticleFiles', 0, '2025-10-23 08:53:31', '29219840909840', '', '9e0a45f23c7d0a1430dac3e71d808266');
INSERT INTO `blogs_file_record` VALUES (16, '2e3e3900-bd9e-4c71-b272-9ed642934486.jpg', '2e3e3900-bd9e-4c71-b272-9ed642934486_20251023085437004.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\2e3e3900-bd9e-4c71-b272-9ed642934486_20251023085437004.jpg', 407585, 'image/jpeg', '.jpg', 'ArticleFiles', 0, '2025-10-23 08:54:37', '29219840909840', '', '239265078db526a64ec563e98e517487');
INSERT INTO `blogs_file_record` VALUES (17, '111.png', '111_20251023102309588.png', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\111_20251023102309588.png', 37174, 'image/png', '.png', 'ArticleFiles', 0, '2025-10-23 10:23:10', '29219840909840', '', 'fa462fa71c1f6c90828d634416a8a241');
INSERT INTO `blogs_file_record` VALUES (18, '383f6768-4271-4007-9006-0c61944fe0d7.png', '383f6768-4271-4007-9006-0c61944fe0d7_20251023102646858.png', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\383f6768-4271-4007-9006-0c61944fe0d7_20251023102646858.png', 60357, 'image/png', '.png', 'ArticleFiles', 0, '2025-10-23 10:26:47', '29219840909840', '', 'c933bd2e5d29c5667a35713439eb08da');
INSERT INTO `blogs_file_record` VALUES (19, 'Image.png', 'Image_20251023103320666.png', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\Image_20251023103320666.png', 68155, 'image/png', '.png', 'ArticleFiles', 0, '2025-10-23 10:33:21', '29219840909840', '', 'ddb7f1ebef0d6bcca066d92c8dd08dd3');
INSERT INTO `blogs_file_record` VALUES (20, 'Image2.png', 'Image2_20251023103649078.png', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\Image2_20251023103649078.png', 40113, 'image/png', '.png', 'ArticleFiles', 0, '2025-10-23 10:36:49', '29219840909840', '', '1b89561fea9fd44a4e25e2c7b3c0f66a');
INSERT INTO `blogs_file_record` VALUES (21, 'Image3.png', 'Image3_20251023103800958.png', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\Image3_20251023103800958.png', 155374, 'image/png', '.png', 'ArticleFiles', 0, '2025-10-23 10:38:01', '29219840909840', '', '28896460589a2077d1e80da8d71f4855');
INSERT INTO `blogs_file_record` VALUES (22, 'Image111.png', 'Image111_20251023105808925.png', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\Image111_20251023105808925.png', 34670, 'image/png', '.png', 'ArticleFiles', 0, '2025-10-23 10:58:09', '29219840909840', '', 'af3e581303375b46246925712ed33ea7');
INSERT INTO `blogs_file_record` VALUES (23, 'Image222.png', 'Image222_20251023105818559.png', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\Image222_20251023105818559.png', 55505, 'image/png', '.png', 'ArticleFiles', 0, '2025-10-23 10:58:19', '29219840909840', '', '6558189615aca902101128a0f0291d96');
INSERT INTO `blogs_file_record` VALUES (24, 'ceaWS5xBNMLhI.jpg', 'ceaWS5xBNMLhI_20251107115642715.jpg', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\ceaWS5xBNMLhI_20251107115642715.jpg', 557582, 'image/jpeg', '.jpg', 'ArticleFiles', 0, '2025-11-07 11:56:43', '29219840909840', '', 'e3dbea33b768a872e78c746904656a38');
INSERT INTO `blogs_file_record` VALUES (25, '111.png', '111_20251108113450604.png', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles\\111_20251108113450604.png', 57717, 'image/png', '.png', 'ArticleFiles', 0, '2025-11-08 11:34:51', '29219840909840', '', '59122f485f6d1fa0b082ae83a4c7deb1');

-- ----------------------------
-- Table structure for blogs_settings
-- ----------------------------
DROP TABLE IF EXISTS `blogs_settings`;
CREATE TABLE `blogs_settings`  (
  `Id` int(11) NOT NULL AUTO_INCREMENT,
  `Title` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Summary` varchar(2000) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Url` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Tags` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `BusType` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Content` longtext CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL,
  `Status` tinyint(4) NULL DEFAULT NULL,
  `CreatedAt` datetime NULL DEFAULT NULL,
  `CreatedBy` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `IsDeleted` int(11) NULL DEFAULT NULL,
  `ModifiedBy` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 14 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blogs_settings
-- ----------------------------
INSERT INTO `blogs_settings` VALUES (1, '对象存储目录', NULL, '/storage/oss/file', '1001', 'FileStorage', '1111111111111111111', 0, '1900-01-01 00:00:00', NULL, NULL, 0, NULL);
INSERT INTO `blogs_settings` VALUES (2, '对象存储目录2', NULL, '/storage/oss/file', '1001', 'FileStorage', '1111111111111111111', 0, '1900-01-01 00:00:00', NULL, NULL, 0, NULL);
INSERT INTO `blogs_settings` VALUES (3, 'Dapr开源项目', 'Dapr 是一个跨平台的微服务运行时', 'http://bing.com', '1001', 'Recommend', '1111111111111111111', 0, '1900-01-01 00:00:00', NULL, NULL, 0, NULL);
INSERT INTO `blogs_settings` VALUES (4, '电商系统001', 'Dapr 是一个跨平台的微服务运行时', 'http://bing.com', '1001', 'OpenSourceProject', '1111111111111111111', 0, '1900-01-01 00:00:00', NULL, NULL, 0, NULL);
INSERT INTO `blogs_settings` VALUES (5, '《代码整洁之道》', '《代码整洁之道》', 'http://bing.com', '1001', 'OpenSourceBook', '1111111111111111111', 0, '1900-01-01 00:00:00', NULL, NULL, 0, NULL);
INSERT INTO `blogs_settings` VALUES (6, '从零开始起一个电商网站', '11从零开始起一个电商网站11111', 'http://bing.com', '1001', 'OpenSourceProject', '1111111111111111111', 0, '1900-01-01 00:00:00', NULL, NULL, 0, NULL);
INSERT INTO `blogs_settings` VALUES (7, '《程序员的自我修养》', '《程序员的自我修养》', '/uploads/images', '1001', 'OpenSourceBook', '1111111111111111111', 0, '1900-01-01 00:00:00', NULL, NULL, 0, NULL);
INSERT INTO `blogs_settings` VALUES (8, '如何搭建一个微服务架构', '22Dapr 是一个跨平台的微服务运行时', 'http://bing.com', '1001', 'Recommend', '1111111111111111111', 0, '1900-01-01 00:00:00', NULL, NULL, 0, NULL);
INSERT INTO `blogs_settings` VALUES (11, 'ArticleFiles', '前端文件存储', '/storage/app/articlefiles', 'ArticleFiles', 'FileStoreDictionary', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\ArticleFiles', 10, '2025-11-17 23:01:39', '10', '2025-12-17 23:01:39', 10, '10');
INSERT INTO `blogs_settings` VALUES (12, 'UserPhoto', '前端文件存储', '/storage/app/userphoto', 'UserPhoto', 'FileStoreDictionary', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\UserPhoto', 10, '2025-11-17 23:01:39', '10', '2025-12-17 23:01:39', 10, '10');
INSERT INTO `blogs_settings` VALUES (13, 'WebsiteImage', '前端文件存储', '/storage/app/websiteimage', 'WebsiteImage', 'FileStoreDictionary', 'D:\\Workspace\\DotNet\\ZLJ.BlogSingleApplication\\master\\5_WebApi\\Blogs.WebApi\\Uploads\\WebsiteImage', 10, '2025-11-17 23:01:39', '10', '2025-12-17 23:01:39', 10, '10');

-- ----------------------------
-- Table structure for blogs_tag
-- ----------------------------
DROP TABLE IF EXISTS `blogs_tag`;
CREATE TABLE `blogs_tag`  (
  `Id` bigint(20) NOT NULL,
  `Name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `LinkUrl` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Color` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsEnabled` tinyint(1) NULL DEFAULT NULL,
  `UsageCount` int(11) NULL DEFAULT NULL,
  `CreatedAt` datetime NULL DEFAULT NULL,
  `CreatedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL DEFAULT 0,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blogs_tag
-- ----------------------------
INSERT INTO `blogs_tag` VALUES (1, 'WebSocket', '1', 'E6E6E6', 1, 0, '2025-10-12 00:47:24', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_tag` VALUES (2, 'Dapr', '', 'RED', 1, 0, '2025-10-12 00:47:24', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_tag` VALUES (3, 'Nacos', '', 'RED', 1, 0, '2025-10-12 00:47:24', 'zlj', NULL, NULL, 0);
INSERT INTO `blogs_tag` VALUES (4, 'K8S', '', 'RED', 1, 0, '2025-10-12 00:47:24', 'zlj', NULL, NULL, 0);

-- ----------------------------
-- Table structure for blogs_user
-- ----------------------------
DROP TABLE IF EXISTS `blogs_user`;
CREATE TABLE `blogs_user`  (
  `Id` bigint(20) NOT NULL,
  `Account` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `Password` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `Email` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `Bio` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Avatar` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Tags` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '个人标签',
  `Website` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `LastLoginIp` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `LastLoginTime` datetime NULL DEFAULT NULL,
  `ArticleCount` int(11) NULL DEFAULT NULL,
  `FollowerCount` int(11) NULL DEFAULT NULL,
  `FollowingCount` int(11) NULL DEFAULT NULL,
  `Description` varchar(2000) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `CreatedAt` datetime NOT NULL,
  `CreatedBy` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL DEFAULT 0,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blogs_user
-- ----------------------------
INSERT INTO `blogs_user` VALUES (29219497415184, 'zlj02', 'BuXb2zLxOlRJt17KU6yenw==', 'zlj01@sing.com', NULL, NULL, NULL, NULL, '127.0.0.1', '2025-10-22 20:35:50', 0, 0, 0, NULL, '2025-10-22 20:35:31', NULL, NULL, NULL, 0);
INSERT INTO `blogs_user` VALUES (29219840909840, 'zhenglijun', 'BuXb2zLxOlRJt17KU6yenw==', 'zhenglijun@sing.com', NULL, NULL, NULL, NULL, '127.0.0.1', '2025-11-10 11:18:36', 0, 0, 0, NULL, '2025-10-22 20:46:42', NULL, NULL, NULL, 0);
INSERT INTO `blogs_user` VALUES (355143408420088, 'zlj01', 'BuXb2zLxOlRJt17KU6yenw==', 'zlj01@sing.com', NULL, NULL, NULL, NULL, '127.0.0.1', '2025-10-29 20:07:50', 0, 0, 0, NULL, '2025-10-22 20:22:33', NULL, NULL, NULL, 0);
INSERT INTO `blogs_user` VALUES (631728610444574720, 'zlj', 'BuXb2zLxOlRJt17KU6yenw==', 'zlj@sing.com', '1', '1', NULL, '1', '127.0.0.1', '2025-11-02 14:19:16', 1, 1, 1, NULL, '2025-10-10 13:45:41', NULL, NULL, NULL, 0);

-- ----------------------------
-- Table structure for sys_buttons
-- ----------------------------
DROP TABLE IF EXISTS `sys_buttons`;
CREATE TABLE `sys_buttons`  (
  `Id` bigint(11) NOT NULL AUTO_INCREMENT COMMENT '自增Id',
  `Code` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '按钮Code',
  `Name` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '按钮名称',
  `Description` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '按钮描述',
  `Icon` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '按钮图标',
  `ButtonType` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT 'ButtonType',
  `Position` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Status` int(11) NULL DEFAULT NULL,
  `SortOrder` int(11) NULL DEFAULT NULL,
  `CreatedAt` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP,
  `CreatedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL DEFAULT 0,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 100010 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sys_buttons
-- ----------------------------
INSERT INTO `sys_buttons` VALUES (10, 'Update', '修改', '111', 'Update', 'default', 'toolbar', 1, 0, '2025-11-02 00:16:13', 'admin', '2025-11-02 00:30:53', 'admin', 0);
INSERT INTO `sys_buttons` VALUES (100001, 'Create', '创建', NULL, NULL, 'default', 'toolbar', 1, 0, '2025-10-31 14:47:40', NULL, '2025-10-31 11:28:28', 'admin', 0);
INSERT INTO `sys_buttons` VALUES (100002, 'Update', '编辑', '编辑数据', 'edit', 'default', 'row', NULL, 2, '2025-10-31 14:47:42', NULL, '2025-10-31 11:13:07', 'admin', 1);
INSERT INTO `sys_buttons` VALUES (100003, 'Delete', '删除', '删除数据', 'delete', 'danger', 'row', NULL, 3, '2025-10-31 14:47:51', NULL, NULL, NULL, 0);
INSERT INTO `sys_buttons` VALUES (100004, 'View', '查看', '查看详情', 'eye', 'default', 'row', NULL, 4, '2025-10-31 14:47:56', NULL, NULL, NULL, 0);
INSERT INTO `sys_buttons` VALUES (100005, 'Export', '导出', '导出数据', 'export', 'default', 'toolbar', NULL, 5, '2025-10-31 14:47:58', NULL, NULL, NULL, 0);
INSERT INTO `sys_buttons` VALUES (100006, 'Import', '导入', '导入数据', 'import', 'default', 'toolbar', NULL, 6, '2025-10-31 14:47:59', NULL, NULL, NULL, 0);
INSERT INTO `sys_buttons` VALUES (100007, 'Audit', '审核', NULL, NULL, 'default', '1', 1, 0, '2025-10-31 14:48:00', 'admin', NULL, NULL, 0);
INSERT INTO `sys_buttons` VALUES (100008, 'BatchDelete', '批量删除', NULL, NULL, 'default', 'toolbar', 1, 0, '2025-10-31 14:48:01', 'admin', NULL, NULL, 0);
INSERT INTO `sys_buttons` VALUES (100009, 'BatchExport', '批量导出', NULL, NULL, 'default', 'toolbar', 1, 0, '2025-10-31 14:48:03', 'admin', NULL, NULL, 0);

-- ----------------------------
-- Table structure for sys_department
-- ----------------------------
DROP TABLE IF EXISTS `sys_department`;
CREATE TABLE `sys_department`  (
  `Id` bigint(20) NOT NULL AUTO_INCREMENT,
  `Name` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ParentId` bigint(20) NOT NULL,
  `Description` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Abbreviation` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Sort` int(11) NULL DEFAULT NULL,
  `CreatedAt` datetime NOT NULL,
  `CreatedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL DEFAULT 0,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 205 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sys_department
-- ----------------------------
INSERT INTO `sys_department` VALUES (1, '销售部', 0, '1121', NULL, NULL, '2025-09-29 23:59:09', 'admin', '2025-09-29 23:59:14', 'admin', 0);
INSERT INTO `sys_department` VALUES (2, '实施部', 0, '1231231', 'ssb', 100, '2025-11-01 00:00:00', 'zlj', '2025-11-01 11:47:51', 'admin', 0);
INSERT INTO `sys_department` VALUES (3, '研发部', 0, '111', NULL, NULL, '2025-10-01 01:34:40', 'admin', '2025-10-01 01:34:46', NULL, 0);
INSERT INTO `sys_department` VALUES (101, '华东销售部1', 1, '1112321312', '111', 1, '2025-10-01 01:34:40', 'admin', '2025-11-01 15:58:32', 'admin', 0);
INSERT INTO `sys_department` VALUES (102, '华南销售部', 1, '111', NULL, NULL, '2025-10-01 01:34:40', 'admin', '2025-10-01 01:34:46', NULL, 0);
INSERT INTO `sys_department` VALUES (103, '广东省销售部', 102, '111', NULL, NULL, '2025-10-01 01:34:40', 'admin', '2025-10-01 01:34:46', NULL, 0);
INSERT INTO `sys_department` VALUES (201, '华南实施部', 2, '111', NULL, NULL, '2025-10-01 01:34:40', 'admin', '2025-10-01 01:34:46', NULL, 0);
INSERT INTO `sys_department` VALUES (203, '运营部', 0, NULL, NULL, NULL, '1900-01-01 00:00:00', NULL, NULL, NULL, 0);
INSERT INTO `sys_department` VALUES (204, '江苏销售部', 101, NULL, NULL, NULL, '1900-01-01 00:00:00', NULL, '2025-11-01 08:07:22', 'admin', 0);

-- ----------------------------
-- Table structure for sys_log
-- ----------------------------
DROP TABLE IF EXISTS `sys_log`;
CREATE TABLE `sys_log`  (
  `Id` bigint(20) NOT NULL,
  `Action` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Operating` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IP` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Message` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `RequestUrl` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `RequestParam` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Result` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ClientInfo` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `CreatedAt` datetime NOT NULL,
  `CreatedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sys_log
-- ----------------------------

-- ----------------------------
-- Table structure for sys_menu
-- ----------------------------
DROP TABLE IF EXISTS `sys_menu`;
CREATE TABLE `sys_menu`  (
  `Id` bigint(20) NOT NULL AUTO_INCREMENT,
  `ParentId` bigint(20) NOT NULL COMMENT '上级菜单',
  `Name` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '菜单名称',
  `ICon` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '图标',
  `Type` int(11) NULL DEFAULT NULL COMMENT '菜单类型:1目录，2:地址，3：外部链接',
  `Url` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '菜单地址',
  `Sort` int(11) NOT NULL COMMENT '排序',
  `Status` int(11) NOT NULL COMMENT '菜单状态',
  `Buttons` varchar(200) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '菜单按钮',
  `CreatedAt` datetime NOT NULL,
  `CreatedBy` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 17 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sys_menu
-- ----------------------------
INSERT INTO `sys_menu` VALUES (1, 0, '首页', 'House', 1, '/home', 0, 1, '[{Code:\"Add\",Name:\"新增\"}]', '2025-10-09 11:38:12', 'admin', NULL, NULL, 0);
INSERT INTO `sys_menu` VALUES (2, 0, '用户管理', 'House', 1, '/users', 111, 1, '', '2025-10-09 11:39:20', 'admin', NULL, NULL, 0);
INSERT INTO `sys_menu` VALUES (3, 2, '用户列表', 'User', 2, '/users', 110, 0, NULL, '1900-01-01 00:00:00', NULL, '2025-11-02 08:05:00', 'admin', 0);
INSERT INTO `sys_menu` VALUES (4, 0, '数据统计1', 'Operation', 1, '/statistics', 8, 0, NULL, '1900-01-01 00:00:00', NULL, '2025-10-31 02:18:41', 'admin', 0);
INSERT INTO `sys_menu` VALUES (5, 0, '权限管理', 'Tools', 1, '1', 7, 1, '[{name:\'新增\',code:\'Create\'},{name:\'修改\',code:\'Update\'},{name:\'删除\',code:\'Delete\'},{name:\'查询\',code:\'Select\'}]', '2025-10-31 02:25:41', 'admin', NULL, NULL, 0);
INSERT INTO `sys_menu` VALUES (6, 5, '管理员列表', 'UserFilled', 2, '/user', 1, 0, '[{name:\'新增\',code:\'Create\'},{name:\'修改\',code:\'Update\'},{name:\'删除\',code:\'Delete\'},{name:\'查询\',code:\'Select\'}]', '1900-01-01 00:00:00', NULL, '2025-10-31 02:26:22', 'admin', 0);
INSERT INTO `sys_menu` VALUES (7, 5, '部门管理', 'Avatar', 2, '/department', 3, 1, '[{name:\'新增\',code:\'Create\'},{name:\'修改\',code:\'Update\'},{name:\'删除\',code:\'Delete\'},{name:\'查询\',code:\'Select\'}]', '2025-10-31 02:27:30', 'admin', NULL, NULL, 0);
INSERT INTO `sys_menu` VALUES (8, 5, '菜单管理1', 'Operation', 1, '/menu', 5, 0, NULL, '1900-01-01 00:00:00', NULL, '2025-10-31 02:28:15', 'admin', 0);
INSERT INTO `sys_menu` VALUES (9, 0, '内容管理', 'Operation', 1, '/', 1, 1, '', '2025-10-31 13:18:17', 'admin', NULL, NULL, 0);
INSERT INTO `sys_menu` VALUES (10, 0, '仪表盘', 'Histogram', 1, '/dashboard', 1888, 0, NULL, '1900-01-01 00:00:00', NULL, '2025-10-31 13:51:31', 'admin', 0);
INSERT INTO `sys_menu` VALUES (11, 5, '角色管理', 'UserFilled', 2, '/permission/role', 0, 0, NULL, '1900-01-01 00:00:00', NULL, '2025-11-01 19:46:57', 'admin', 0);
INSERT INTO `sys_menu` VALUES (12, 2, '创建用户', 'User', 2, '/user/info', 0, 0, NULL, '1900-01-01 00:00:00', NULL, '2025-11-02 14:08:51', 'admin', 0);
INSERT INTO `sys_menu` VALUES (13, 9, '文章列表', 'Notification', 2, '/articlelist', 111, 0, NULL, '1900-01-01 00:00:00', NULL, '2025-11-01 19:47:25', 'admin', 0);
INSERT INTO `sys_menu` VALUES (14, 9, '文章分类', 'comment', 2, '/articletype', 0, 0, NULL, '1900-01-01 00:00:00', NULL, '2025-11-01 19:45:41', 'admin', 0);
INSERT INTO `sys_menu` VALUES (15, 9, '标签管理', 'Discount', 2, '/articletag', 111, 0, NULL, '1900-01-01 00:00:00', NULL, '2025-11-01 19:48:09', 'admin', 0);
INSERT INTO `sys_menu` VALUES (16, 9, '评论管理', 'Comment', 2, '/article-comment', 0, 1, NULL, '2025-11-01 19:45:19', 'admin', NULL, NULL, 0);

-- ----------------------------
-- Table structure for sys_menu_button
-- ----------------------------
DROP TABLE IF EXISTS `sys_menu_button`;
CREATE TABLE `sys_menu_button`  (
  `Id` int(11) NOT NULL AUTO_INCREMENT,
  `MenuId` bigint(20) NULL DEFAULT NULL,
  `ButtonId` int(11) NULL DEFAULT NULL,
  `SortOrder` int(11) NULL DEFAULT NULL,
  `CreatedBy` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `CreatedAt` datetime NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 60 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sys_menu_button
-- ----------------------------
INSERT INTO `sys_menu_button` VALUES (35, 16, 100001, 0, 'admin', '2025-11-01 19:45:19', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (36, 16, 100003, 3, 'admin', '2025-11-01 19:45:19', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (37, 14, 100001, 0, 'admin', '2025-11-01 19:45:44', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (38, 14, 100003, 3, 'admin', '2025-11-01 19:45:44', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (39, 14, 100004, 4, 'admin', '2025-11-01 19:45:44', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (40, 11, 100001, 0, 'admin', '2025-11-01 19:46:57', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (41, 11, 100003, 3, 'admin', '2025-11-01 19:46:57', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (42, 11, 100005, 5, 'admin', '2025-11-01 19:46:57', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (43, 13, 100001, 0, 'admin', '2025-11-01 19:47:25', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (44, 13, 100003, 3, 'admin', '2025-11-01 19:47:25', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (45, 13, 100004, 4, 'admin', '2025-11-01 19:47:25', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (46, 13, 100005, 5, 'admin', '2025-11-01 19:47:25', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (47, 13, 100007, 0, 'admin', '2025-11-01 19:47:25', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (51, 15, 100001, 0, 'admin', '2025-11-01 19:48:09', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (52, 15, 100003, 3, 'admin', '2025-11-01 19:48:09', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (53, 15, 100004, 4, 'admin', '2025-11-01 19:48:09', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (54, 3, 10, 0, 'admin', '2025-11-02 08:05:00', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (55, 3, 100001, 0, 'admin', '2025-11-02 08:05:00', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (56, 3, 100003, 3, 'admin', '2025-11-02 08:05:00', NULL, NULL, 0);
INSERT INTO `sys_menu_button` VALUES (59, 12, 100001, 0, 'admin', '2025-11-02 14:08:51', NULL, NULL, 0);

-- ----------------------------
-- Table structure for sys_role
-- ----------------------------
DROP TABLE IF EXISTS `sys_role`;
CREATE TABLE `sys_role`  (
  `Id` bigint(20) NOT NULL AUTO_INCREMENT,
  `IsSystem` int(11) NOT NULL,
  `ParentId` bigint(20) NOT NULL,
  `Name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Code` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Remark` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Status` int(11) NOT NULL,
  `CreatedAt` datetime NOT NULL,
  `CreatedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 7 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sys_role
-- ----------------------------
INSERT INTO `sys_role` VALUES (1, 1, 0, '系统管理员', 'sysadmin', NULL, 1, '2025-10-08 09:07:33', 'admin', NULL, NULL, 0);
INSERT INTO `sys_role` VALUES (2, 0, 0, '部门经理', 'publish', NULL, 1, '2025-10-09 12:40:15', 'admin', NULL, NULL, 0);
INSERT INTO `sys_role` VALUES (3, 0, 0, '部门主管', 'verify', NULL, 1, '2025-10-09 12:40:31', 'admin', NULL, NULL, 0);
INSERT INTO `sys_role` VALUES (4, 0, 0, '产品经理', 'primary', '2222', 1, '1900-01-01 00:00:00', NULL, '2025-10-30 11:49:32', 'admin', 0);
INSERT INTO `sys_role` VALUES (5, 0, 0, '开发负责人', 'Sales', '111', 1, '2025-10-30 23:53:09', 'admin', '2025-10-30 23:56:03', 'admin', 0);
INSERT INTO `sys_role` VALUES (6, 0, 0, '开发人员', 'Sybus', NULL, 1, '2025-10-31 00:10:04', 'admin', NULL, NULL, 0);

-- ----------------------------
-- Table structure for sys_rolemenu_auth
-- ----------------------------
DROP TABLE IF EXISTS `sys_rolemenu_auth`;
CREATE TABLE `sys_rolemenu_auth`  (
  `Id` bigint(20) NOT NULL AUTO_INCREMENT,
  `RoleId` bigint(20) NOT NULL,
  `MenuId` bigint(20) NOT NULL,
  `ButtonPermissions` varchar(2000) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `CreatedAt` datetime NOT NULL,
  `CreatedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 59 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sys_rolemenu_auth
-- ----------------------------
INSERT INTO `sys_rolemenu_auth` VALUES (32, 2, 3, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"}]', '2025-11-02 09:43:17', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (33, 3, 5, '[]', '2025-11-02 12:28:38', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (34, 3, 11, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"},{\"Id\":100005,\"Code\":\"Export\",\"Name\":\"导出\"}]', '2025-11-02 12:28:44', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (42, 6, 5, '[]', '2025-11-02 13:06:02', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (43, 6, 9, '[]', '2025-11-02 13:06:02', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (44, 6, 11, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"},{\"Id\":100005,\"Code\":\"Export\",\"Name\":\"导出\"}]', '2025-11-02 13:06:02', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (45, 6, 13, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"},{\"Id\":100004,\"Code\":\"View\",\"Name\":\"查看\"},{\"Id\":100005,\"Code\":\"Export\",\"Name\":\"导出\"},{\"Id\":100007,\"Code\":\"Audit\",\"Name\":\"审核\"}]', '2025-11-02 13:06:02', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (46, 6, 14, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"},{\"Id\":100004,\"Code\":\"View\",\"Name\":\"查看\"}]', '2025-11-02 13:06:02', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (47, 6, 15, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"},{\"Id\":100004,\"Code\":\"View\",\"Name\":\"查看\"}]', '2025-11-02 13:06:02', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (48, 6, 16, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"}]', '2025-11-02 13:06:02', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (49, 5, 2, '[]', '2025-11-02 14:06:57', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (50, 5, 3, '[{\"Id\":10,\"Code\":\"Update\",\"Name\":\"修改\"},{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"}]', '2025-11-02 14:06:57', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (51, 5, 5, '[]', '2025-11-02 14:06:57', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (52, 5, 9, '[]', '2025-11-02 14:06:57', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (53, 5, 11, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"},{\"Id\":100005,\"Code\":\"Export\",\"Name\":\"导出\"}]', '2025-11-02 14:06:57', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (54, 5, 12, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"}]', '2025-11-02 14:06:57', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (55, 5, 13, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"},{\"Id\":100004,\"Code\":\"View\",\"Name\":\"查看\"},{\"Id\":100005,\"Code\":\"Export\",\"Name\":\"导出\"},{\"Id\":100007,\"Code\":\"Audit\",\"Name\":\"审核\"}]', '2025-11-02 14:06:57', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (56, 5, 14, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"},{\"Id\":100004,\"Code\":\"View\",\"Name\":\"查看\"}]', '2025-11-02 14:06:57', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (57, 5, 15, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"},{\"Id\":100004,\"Code\":\"View\",\"Name\":\"查看\"}]', '2025-11-02 14:06:57', 'admin', NULL, NULL, 0);
INSERT INTO `sys_rolemenu_auth` VALUES (58, 5, 16, '[{\"Id\":100001,\"Code\":\"Create\",\"Name\":\"创建\"},{\"Id\":100003,\"Code\":\"Delete\",\"Name\":\"删除\"}]', '2025-11-02 14:06:57', 'admin', NULL, NULL, 0);

-- ----------------------------
-- Table structure for sys_user
-- ----------------------------
DROP TABLE IF EXISTS `sys_user`;
CREATE TABLE `sys_user`  (
  `Id` bigint(20) NOT NULL,
  `UserName` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Email` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `PhoneNumber` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `AccessFailedCount` int(11) NOT NULL,
  `Password` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `HeadPic` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `RealName` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `Sex` int(11) NULL DEFAULT 1,
  `DepartmentId` bigint(20) NULL DEFAULT NULL,
  `Status` int(11) NULL DEFAULT NULL,
  `Description` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `LastLoginTime` datetime NULL DEFAULT NULL,
  `CreatedAt` datetime NOT NULL,
  `CreatedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ModifiedAt` datetime NULL DEFAULT NULL,
  `ModifiedBy` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `IsDeleted` tinyint(1) NOT NULL,
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sys_user
-- ----------------------------
INSERT INTO `sys_user` VALUES (100001, 'admin', 'admin@sing.com', '15816814415', 0, 'BuXb2zLxOlRJt17KU6yenw==', NULL, 'admin', 1, 101, 1, '1', '2025-11-08 16:14:52', '2025-09-11 19:47:17', NULL, '2025-09-29 16:24:44', 'admin', 0);
INSERT INTO `sys_user` VALUES (100002, 'admin1', 'admin1@sing.com', '15816818878', 0, NULL, NULL, 'admin1', 1, 1, 1, '来来来', NULL, '1900-01-01 00:00:00', NULL, '2025-10-01 07:46:30', 'admin', 0);
INSERT INTO `sys_user` VALUES (100003, 'zlj2', 'zlj2@sing.com', '15816818823', 0, NULL, NULL, 'zlj2', 1, 2, 1, '1111111111111', NULL, '1900-01-01 00:00:00', NULL, '2025-09-29 13:50:12', 'admin', 0);
INSERT INTO `sys_user` VALUES (100004, 'zlj3', 'zlj3@sing.com', '15816817715', 0, 'BuXb2zLxOlRJt17KU6yenw==', NULL, 'zlj3', 1, 3, 1, 'mmmmmmmmmmmmmmm', NULL, '1900-01-01 00:00:00', NULL, '2025-09-29 19:34:49', 'admin', 0);
INSERT INTO `sys_user` VALUES (100005, 'zlj', 'zlj@sing.com', '13580353320', 0, 'BuXb2zLxOlRJt17KU6yenw==', NULL, 'zlj', 1, 102, 1, '000', '2025-10-31 21:21:23', '1900-01-01 00:00:00', NULL, '2025-09-29 16:27:20', 'admin', 0);
INSERT INTO `sys_user` VALUES (100006, 'zlj01', 'zlj01@sing.com', '15816819911', 0, 'BuXb2zLxOlRJt17KU6yenw==', NULL, 'zlj01', 1, 101, 1, '11', '2025-11-01 00:20:32', '1900-01-01 00:00:00', NULL, '2025-09-29 16:51:58', 'admin', 0);
INSERT INTO `sys_user` VALUES (100007, 'zhenglijun', 'zhenglijun@sing.com', '15816818890', 0, 'BuXb2zLxOlRJt17KU6yenw==', NULL, 'zhenglijun', 1, 101, 1, '', '2025-11-02 14:59:10', '2025-10-25 07:57:58', 'admin', '2025-10-25 08:04:36', 'admin', 0);
INSERT INTO `sys_user` VALUES (100008, 'admin2', 'admin@sing.com', NULL, 0, 'BuXb2zLxOlRJt17KU6yenw==', NULL, 'admin', 0, 3, 1, '', NULL, '2025-10-29 13:30:11', 'zlj01', NULL, NULL, 0);
INSERT INTO `sys_user` VALUES (100009, 'admin3', 'admin3@sing.com', NULL, 0, 'BuXb2zLxOlRJt17KU6yenw==', NULL, '郑总', 0, 2, 1, '111', '2025-10-29 19:20:14', '2025-10-29 14:14:37', 'admin', '2025-10-30 00:28:51', 'admin', 0);
INSERT INTO `sys_user` VALUES (100010, 'admin4', 'admin4@asx.com', NULL, 0, 'F8wYHt6dIIo7SCbAkuKakw==', NULL, '艾德明4', 0, NULL, 0, '111111111111111111', NULL, '2025-10-29 20:10:29', 'admin', '2025-10-30 07:20:12', 'admin', 0);
INSERT INTO `sys_user` VALUES (100011, 'admin5', 'admin5@sing.com', NULL, 0, 'BuXb2zLxOlRJt17KU6yenw==', NULL, 'admin5', 0, NULL, 0, '11111111111111111111111111', NULL, '2025-10-29 20:36:29', 'admin', '2025-10-30 00:30:04', 'admin', 0);
INSERT INTO `sys_user` VALUES (100012, 'zhenglijun1', 'zhengljiun1@sing.com', '15816818891', 0, '7vYkbXvkjPRp8LGFoUK7sA==', NULL, 'zhenglijun', 2, 1, 1, '11111111111222222222223333333333555555555555555555', '2025-11-04 08:08:57', '2025-10-29 21:26:09', 'admin', '2025-11-04 08:08:39', 'admin', 0);
INSERT INTO `sys_user` VALUES (100013, 'zhenglijun3', 'zhengljiun8@sing.com', '15816818891', 0, 'BuXb2zLxOlRJt17KU6yenw==', NULL, 'zhenglijun', 1, 1, 0, '11111111111', NULL, '2025-10-29 21:46:29', 'admin', '2025-10-30 06:59:31', 'admin', 0);
INSERT INTO `sys_user` VALUES (100014, 'zhenglijun4', 'zhengljiun1@sing.com', '15816818891', 0, 'BuXb2zLxOlRJt17KU6yenw==', NULL, 'zhenglijun', 0, 1, 0, '11111111111', NULL, '2025-10-29 21:49:23', 'admin', '2025-10-30 06:59:31', 'admin', 0);
INSERT INTO `sys_user` VALUES (29531664585744, 'zhenglijun5', 'zhengljiun5@sing.com', '15816818891', 0, 'DG0SQz6STABUP73bg7Y/og==', NULL, 'zhenglijun5', 1, 1, 1, 'zhenglijun5###################################', '2025-10-29 23:09:32', '1900-01-01 00:00:00', 'admin', '2025-10-29 23:09:18', 'admin', 0);

-- ----------------------------
-- Table structure for sys_userrole_relation
-- ----------------------------
DROP TABLE IF EXISTS `sys_userrole_relation`;
CREATE TABLE `sys_userrole_relation`  (
  `Id` int(11) NOT NULL AUTO_INCREMENT,
  `RoleId` bigint(20) NULL DEFAULT NULL COMMENT '角色Id',
  `UserId` bigint(20) NULL DEFAULT NULL COMMENT '用户Id',
  PRIMARY KEY (`Id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 15 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sys_userrole_relation
-- ----------------------------
INSERT INTO `sys_userrole_relation` VALUES (1, 1, 100001);
INSERT INTO `sys_userrole_relation` VALUES (2, 1, 100009);
INSERT INTO `sys_userrole_relation` VALUES (3, 2, 100009);
INSERT INTO `sys_userrole_relation` VALUES (4, 1, 29531422416912);
INSERT INTO `sys_userrole_relation` VALUES (7, 1, 29531664585744);
INSERT INTO `sys_userrole_relation` VALUES (8, 1, 0);
INSERT INTO `sys_userrole_relation` VALUES (9, 1, 100014);
INSERT INTO `sys_userrole_relation` VALUES (10, 1, 100013);
INSERT INTO `sys_userrole_relation` VALUES (13, 2, 100012);
INSERT INTO `sys_userrole_relation` VALUES (14, 1, 100011);

SET FOREIGN_KEY_CHECKS = 1;
